<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Channels Practice - Go Concurrency Course</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:opsz,wght@8..60,400;8..60,500;8..60,600;8..60,700&family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" class="hljs-theme" data-theme="light">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" class="hljs-theme" data-theme="dark" disabled>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/marked/12.0.0/marked.min.js"></script>
<link rel="stylesheet" href="../style.css">
</head>
<body>

<header class="header">
  <button class="menu-toggle" onclick="toggleMobile()">&#9776;</button>
  <div class="header-brand">
    <div class="header-logo">Go</div>
    <span class="header-title">Go Concurrency</span>
    <div class="header-sep"></div>
    <span class="header-part-title" id="headerPart">Select a section to begin</span>
  </div>
  <div class="section-nav" id="sectionNav" style="display:none">
    <button class="nav-btn" id="prevSection" onclick="prevSlide()">&#8249;</button>
    <span class="section-indicator" id="sectionIndicator">1 / 1</span>
    <button class="nav-btn" id="nextSection" onclick="nextSlide()">&#8250;</button>
  </div>
  <div class="header-right">
    <button class="nav-btn font-btn" onclick="changeFontSize(-1)" title="Decrease font size">A&#8722;</button>
    <button class="nav-btn font-btn" onclick="changeFontSize(1)" title="Increase font size">A+</button>
    <button class="nav-btn" id="darkToggle" onclick="toggleDark()" title="Toggle dark mode"><span id="darkIcon">&#9789;</span></button>
    <button class="nav-btn" title="Toggle sidebar" onclick="toggleSidebar()" style="font-size:14px">&#9776;</button>
  </div>
</header>

<div class="layout">
  <nav class="sidebar" id="sidebar">
    <div id="sidebarContent">
      <div class="loading"><div class="spinner"></div><div class="loading-text">Loading...</div></div>
    </div>
  </nav>

  <div class="main" id="mainArea">
    <div class="sections-container" id="sectionsContainer">
      <div class="welcome" id="welcomeScreen">
        <div class="welcome-icon">Go</div>
        <h1>Go Concurrency Mastery</h1>
        <p>A hands-on course to master concurrent programming in Go. Navigate sections horizontally with arrow keys or buttons.</p>
        <button class="welcome-btn" onclick="loadFirst()">Start Reading</button>
        <a class="welcome-btn resume-btn" id="resumeBtn" style="display:none" href="#">Continue Reading</a>
        <div class="welcome-hint">Use &#8592; &#8594; arrow keys to navigate sections</div>
      </div>
    </div>
    <div class="section-dots" id="sectionDots"></div>
  </div>
</div>

<script>
var __BASE_PATH__ = "..";
var __PAGE_ID__ = "chapter-01/PART4-1CHANNELS_PRACTICE.md";
var __PAGE_CONTENT__ = "# Channels Practice\n\n\u003e **How to use this section**: This is a pure practice section. No new theory — all theory is in Part 4. Here we build muscle memory through progressively harder problems, guided exercises, and real-world walkthroughs. Every section has something to run, something to fix, and something to think about.\n\n### What's Inside\n\n- **Level 1 — Directional Channels**: Compile-time safety with `chan\u003c-` and `\u003c-chan`, quizzes, exercises\n- **Level 2 — Beginner Problems**: Done channel, quit channel, timeout pattern\n- **Level 3 — Intermediate Patterns**: Producer-consumer, pipelines, fan-out, fan-in\n- **Level 4 — Advanced Patterns**: Worker pool, semaphore, nil channel trick, or-done, tee, bridge\n- **Level 5 — Expert Problems**: Fix 5 goroutine leaks, rate limiter, heartbeat pattern\n- **Level 6 — Real-World Deep Dives**: Docker goroutine leaks, Kubernetes watch, etcd raft, NSQ internals\n- **Level 7 — Pitfalls \u0026 Gotchas**: Loop variable capture, never-closed channels, double-close, select priority\n- **Level 8 — Interview Prep**: 8 common interview questions with model answers, axiom table\n\n---\n\n## Before We Start: Your Channel Cheat Sheet\n\n```\nRULE 1: Only the SENDER should close a channel\nRULE 2: Sending to a closed channel → PANIC\nRULE 3: Receiving from a closed channel → zero value, ok=false\nRULE 4: Sending/receiving from a nil channel → blocks forever\nRULE 5: Closing a nil channel → PANIC\nRULE 6: Never start a goroutine without knowing how it will stop\n```\n\nKeep this in sight while you practice.\n\n---\n\n## Level 1: Directional Channels — Compile-Time Safety\n\n### What Are Directional Channels?\n\nYou already know `chan int` is a two-way channel. But Go lets you **restrict** a channel to one direction:\n\n```\nchan int ← bidirectional (send AND receive)\nchan\u003c- int ← send-only (can ONLY send into it)\n\u003c-chan int ← receive-only (can ONLY receive from it)\n```\n\nThe arrow `\u003c-` points toward the channel for send-only, and away from the channel for receive-only. Think of it as: \"the arrow shows which way data flows relative to the channel.\"\n\n**Why does this matter?**\n\nLook at this function signature:\n\n```go\nfunc producer(out chan int) { // Bad\n    out \u003c- 42\n}\n```\n\nNothing stops the caller from accidentally passing in a channel they're reading from and having the producer do something unexpected. But:\n\n```go\nfunc producer(out chan\u003c- int) { // Good\n    out \u003c- 42\n    // out \u003c- 42 allowed\n    // v := \u003c-out compile error: receive from send-only type\n    // close(out) allowed (only sender should close anyway!)\n}\n```\n\nThe compiler now **enforces** correct usage. You can't receive from a send-only. You can't send to a receive-only. Bugs caught at compile time, not runtime!\n\n**Conversion rules:**\n\n```\nbidirectional ──────────────→ send-only implicit, no cast needed\nbidirectional ──────────────→ receive-only implicit, no cast needed\nsend-only ──────────────→ bidirectional COMPILE ERROR\nreceive-only ──────────────→ bidirectional COMPILE ERROR\nsend-only ──────────────→ receive-only COMPILE ERROR\n```\n\nOnce a channel is restricted, it stays restricted!\n\n**The standard pattern:**\n\n```go\nfunc main() {\n    ch := make(chan int, 5) // Created as bidirectional (only place!)\n\n    go producer(ch) // Implicitly converts to chan\u003c- int\n    go consumer(ch) // Implicitly converts to \u003c-chan int\n}\n\nfunc producer(out chan\u003c- int) { // send-only\n    for i := 0; i \u003c 5; i++ {\n        out \u003c- i\n    }\n    close(out) // producer closes - this is correct!\n}\n\nfunc consumer(in \u003c-chan int) { // receive-only\n    for v := range in {\n        fmt.Println(v)\n    }\n}\n```\n\n---\n\n### Quiz 1.1: Direction Detection\n\n**Look at each signature. What does each function do and what's allowed?**\n\n```go\n// Function A\nfunc process(data \u003c-chan string, results chan\u003c- string) {}\n\n// Function B\nfunc fanOut(source \u003c-chan int, workers []chan\u003c- int) {}\n\n// Function C\nfunc merge(ch1, ch2 \u003c-chan int) \u003c-chan int { return nil }\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Function A**: Receives strings from `data`, sends processed results to `results`. A classic pipeline stage. It cannot send to `data` or receive from `results`.\n\n**Function B**: Takes a read-only source and a slice of send-only worker channels. It distributes (fans out) work from source to workers. Cannot send to `source` or receive from any `workers` element.\n\n**Function C**: Takes TWO receive-only channels and RETURNS a receive-only channel. This is the fan-in (merge) pattern signature! Callers can only read from the result — the merge function controls writing.\n\nThe function return type `\u003c-chan int` is a common real-world pattern — it tells the caller \"here is a stream you can read, but you don't own or control it.\"\n\n\u003c/details\u003e\n\n---\n\n### Exercise 1.1: Fix the Direction Bug\n\nThis code has a compile error. Find and fix it without changing the core logic:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc generate(out chan\u003c- int) {\n    for i := 0; i \u003c 5; i++ {\n        out \u003c- i\n    }\n    close(out)\n}\n\nfunc double(in chan\u003c- int, out chan\u003c- int) { // BUG IS HERE\n    for v := range in {\n        out \u003c- v * 2\n    }\n    close(out)\n}\n\nfunc print(in chan\u003c- int) { // BUG IS HERE\n    for v := range in {\n        fmt.Println(v)\n    }\n}\n\nfunc main() {\n    nums := make(chan int, 5)\n    doubled := make(chan int, 5)\n\n    go generate(nums)\n    go double(nums, doubled)\n    print(doubled)\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n`double`'s first parameter should be `\u003c-chan int` (receive from it, not send to it).\n`print`'s parameter should be `\u003c-chan int` (receive only).\n\nFixed:\n```go\nfunc double(in \u003c-chan int, out chan\u003c- int) { // in is receive-only\n    for v := range in {\n        out \u003c- v * 2\n    }\n    close(out)\n}\n\nfunc print(in \u003c-chan int) { // receive-only\n    for v := range in {\n        fmt.Println(v)\n    }\n}\n```\n\nThe key rule: **if a function reads from a channel, the parameter type is `\u003c-chan T`. If it writes to a channel, the parameter type is `chan\u003c- T`.** Only `main` (or the orchestrator) holds the bidirectional `chan T`.\n\n\u003c/details\u003e\n\n---\n\n### Real-World: How the Standard Library Uses Directional Channels\n\nThe Go standard library consistently uses receive-only returns:\n\n```go\n// time package - you can only READ the time, not send to it\nfunc After(d Duration) \u003c-chan Time\n\n// context package - you can only READ the done signal\nfunc (c *cancelCtx) Done() \u003c-chan struct{}\n\n// os/signal package - you can only WRITE signals to it (via Notify)\nfunc Notify(c chan\u003c- os.Signal, sig ...os.Signal)\n```\n\nNotice `os/signal.Notify` takes a `chan\u003c- os.Signal` — the ONLY send-only parameter in the entire Go standard library's public API. This enforces that the user creates the channel (so they control the buffer size), but the signal package can only write to it.\n\nThe real usage pattern everyone uses:\n```go\nsigCh := make(chan os.Signal, 1) // user creates bidirectional\nsignal.Notify(sigCh, syscall.SIGINT) // implicitly becomes chan\u003c- os.Signal inside\nsig := \u003c-sigCh // user reads from it\n```\n\n---\n\n## Level 2: Beginner Problems\n\n### Problem 2.1: The Done Channel (Signal Completion)\n\n**Problem**: Write a function `doWork` that does some work in a goroutine. The `main` function should wait for the work to complete before exiting. No sleep allowed!\n\nThis is the most fundamental channel pattern. Before `sync.WaitGroup` existed, this is how Go programs coordinated.\n\n**Starter code:**\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc doWork(done chan\u003c- struct{}) {\n    // TODO: simulate some work, then signal done\n}\n\nfunc main() {\n    done := make(chan struct{})\n\n    go doWork(done)\n\n    // TODO: wait for work to finish\n\n    fmt.Println(\"All done!\")\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eStep-by-step solution\u003c/summary\u003e\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc doWork(done chan\u003c- struct{}) {\n    fmt.Println(\"Working...\")\n    time.Sleep(500 * time.Millisecond) // simulate work\n    fmt.Println(\"Work complete!\")\n    done \u003c- struct{}{} // signal completion\n    // OR: close(done) -- even better for broadcasting to MULTIPLE waiters!\n}\n\nfunc main() {\n    done := make(chan struct{})\n\n    go doWork(done)\n\n    \u003c-done // block until signal received\n\n    fmt.Println(\"All done!\")\n}\n```\n\n**Why `struct{}{}`?** Zero memory usage. We don't care about the value — just the signal.\n\n**Why not `bool`?** A `chan bool` works, but what does `true` mean vs `false`? `struct{}` is unambiguous: the signal is the act of sending/closing.\n\n**The critical difference between send and close:**\n\n```\ndone \u003c- struct{}{} → unblocks ONE waiter\nclose(done) → unblocks ALL waiters (broadcast!)\n```\n\nFor a single goroutine, either works. For multiple goroutines waiting on the same `done` channel, **always use `close(done)`** to wake them all simultaneously.\n\n\u003c/details\u003e\n\n---\n\n### Quiz 2.1: What Happens Here?\n\n**Predict the output. Then run it to verify.**\n\n```go\ndone := make(chan struct{})\n\ngo func() {\n    close(done)\n}()\n\n\u003c-done\n\u003c-done\n\u003c-done\nfmt.Println(\"received 3 times from closed channel\")\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nThis prints `\"received 3 times from closed channel\"` without panicking!\n\nReceiving from a **closed** channel returns immediately with the zero value and `ok=false`. So after the goroutine closes `done`, all three `\u003c-done` operations return immediately. This is why `close` is the broadcast mechanism — any number of receivers unblock immediately.\n\nThis is exactly how `context.Done()` works! When a context is cancelled, `close()` is called on the done channel, and ALL goroutines `select`ing on `ctx.Done()` unblock simultaneously.\n\n\u003c/details\u003e\n\n---\n\n### Problem 2.2: The Quit Channel (Graceful Shutdown)\n\n**Problem**: Build a number generator that can be stopped by the caller. Without a stop mechanism, the goroutine will leak forever!\n\n**The broken version (goroutine leak!):**\n\n```go\nfunc brokenGenerator() \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        for i := 0; ; i++ {\n            out \u003c- i // blocks forever if nobody reads!\n        }\n    }()\n    return out\n}\n\nfunc main() {\n    gen := brokenGenerator()\n\n    fmt.Println(\u003c-gen) // 0\n    fmt.Println(\u003c-gen) // 1\n    fmt.Println(\u003c-gen) // 2\n    // main exits, goroutine is LEAKED - stuck on out \u003c- i with no reader!\n}\n```\n\n**Your task**: Fix it with a quit channel.\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution with explanation\u003c/summary\u003e\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc generator(quit \u003c-chan struct{}) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out) // always clean up the output channel\n        for i := 0; ; i++ {\n            select {\n            case out \u003c- i:\n                // successfully sent\n            case \u003c-quit:\n                fmt.Println(\"generator: received quit signal, stopping\")\n                return\n            }\n        }\n    }()\n    return out\n}\n\nfunc main() {\n    quit := make(chan struct{})\n    gen := generator(quit)\n\n    fmt.Println(\u003c-gen) // 0\n    fmt.Println(\u003c-gen) // 1\n    fmt.Println(\u003c-gen) // 2\n\n    close(quit) // signal generator to stop\n\n    // Safe to range over - generator closed out after quit\n    for v := range gen {\n        fmt.Println(\"remaining:\", v) // drains any buffered values\n    }\n}\n```\n\n**How the select works:**\n\n```\nEach iteration:\n  select {\n    case out \u003c- i: ← if caller is ready to receive, send the number\n    case \u003c-quit: ← if quit signal received, stop immediately\n  }\n```\n\nThe `select` races between two operations. If neither is ready, it blocks. When either becomes ready, that case executes. This is Go's way of doing non-blocking multi-channel coordination.\n\n**Dave Cheney's rule**: \"Never start a goroutine without knowing how it will stop.\"\nSource: `dave.cheney.net/2016/12/22/never-start-a-goroutine-without-knowing-how-it-will-stop`\n\nThe quit channel IS how this goroutine will stop.\n\n\u003c/details\u003e\n\n---\n\n### Problem 2.3: The Timeout Pattern\n\n**Problem**: You're calling an external service. It sometimes hangs. Implement a function that calls it with a 1-second timeout. If the service responds in time, return the result. If it times out, return an error.\n\n```go\npackage main\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"time\"\n)\n\nfunc callSlowService() string {\n    time.Sleep(2 * time.Second) // simulate slow service\n    return \"result from service\"\n}\n\nfunc callWithTimeout(timeout time.Duration) (string, error) {\n    // TODO: implement timeout\n}\n\nfunc main() {\n    result, err := callWithTimeout(1 * time.Second)\n    if err != nil {\n        fmt.Println(\"Error:\", err)\n    } else {\n        fmt.Println(\"Result:\", result)\n    }\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution with detailed explanation\u003c/summary\u003e\n\n```go\nfunc callWithTimeout(timeout time.Duration) (string, error) {\n    // CRITICAL: buffer size 1 prevents goroutine leak!\n    resultCh := make(chan string, 1)\n\n    go func() {\n        result := callSlowService() // blocks here\n        resultCh \u003c- result // sends result when ready\n    }()\n\n    select {\n    case result := \u003c-resultCh:\n        return result, nil\n    case \u003c-time.After(timeout):\n        return \"\", errors.New(\"timeout: service took too long\")\n    }\n}\n```\n\n**Why buffer size 1 is critical:**\n\n```\nWITHOUT BUFFER (common mistake):\n  resultCh := make(chan string) // unbuffered\n\n  Scenario: timeout fires first\n    → select returns from time.After case\n    → function returns error\n    → goroutine is still running callSlowService()\n    → callSlowService() finally returns\n    → goroutine tries: resultCh \u003c- result\n    → NOBODY IS RECEIVING (main returned!)\n    → goroutine LEAKS FOREVER\n\nWITH BUFFER of 1:\n  resultCh := make(chan string, 1) // buffered\n\n  Scenario: timeout fires first\n    → select returns from time.After case\n    → function returns error\n    → goroutine is still running callSlowService()\n    → callSlowService() finally returns\n    → goroutine sends result: resultCh \u003c- result\n    → buffer absorbs it (no receiver needed!)\n    → goroutine exits cleanly\n    → resultCh gets garbage collected\n```\n\nThis is the **\"forgotten sender\" goroutine leak** documented by Ardan Labs. Always buffer result channels with capacity 1 in fire-and-forget timeout patterns.\n\n\u003c/details\u003e\n\n---\n\n### Quiz 2.3: The time.After Gotcha\n\n**What's wrong with this code? Will it cause a problem?**\n\n```go\nfunc processMessages(messages \u003c-chan string) {\n    for {\n        select {\n        case msg := \u003c-messages:\n            fmt.Println(\"Got:\", msg)\n        case \u003c-time.After(30 * time.Second):\n            fmt.Println(\"No message for 30 seconds, giving up\")\n            return\n        }\n    }\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nBefore Go 1.23: **memory leak!**\n\n`time.After(30 * time.Second)` creates a new `*time.Timer` every loop iteration. Before Go 1.23, that timer couldn't be garbage collected until it fired (30 seconds later). If `messages` receives frequently (like 100/second), you're creating 100 timers per second that each live for 30 seconds = **3,000 live timers at any time**. At 30 messages/sec over hours? Millions of stuck timers consuming RAM.\n\n**The fix (works on all Go versions):**\n\n```go\nfunc processMessages(messages \u003c-chan string) {\n    timer := time.NewTimer(30 * time.Second)\n    defer timer.Stop()\n\n    for {\n        // Reset the timer each loop (reuse, don't recreate)\n        if !timer.Stop() {\n            select {\n            case \u003c-timer.C:\n            default:\n            }\n        }\n        timer.Reset(30 * time.Second)\n\n        select {\n        case msg := \u003c-messages:\n            fmt.Println(\"Got:\", msg)\n        case \u003c-timer.C:\n            fmt.Println(\"No message for 30 seconds, giving up\")\n            return\n        }\n    }\n}\n```\n\n**Good news**: Go 1.23 fixed this! Unreferenced timers created by `time.After` can now be garbage collected. But understanding WHY it leaked is still essential knowledge for any Go engineer working on pre-1.23 codebases.\n\n\u003c/details\u003e\n\n---\n\n## Level 3: Intermediate Patterns\n\n### Pattern 3.1: Producer-Consumer\n\n**Concept:**\n\n```\nProducer goroutines → [channel buffer] → Consumer goroutines\n```\n\nOne or more producers put work in. One or more consumers take work out. The channel acts as a safe queue between them.\n\n**Problem**: Build a URL scraper system. Multiple producers discover URLs. Multiple consumers download them. Use channels to decouple them.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n    \"math/rand\"\n)\n\nfunc discover(id int, urls chan\u003c- string, done \u003c-chan struct{}) {\n    for {\n        select {\n        case \u003c-done:\n            fmt.Printf(\"Discoverer %d stopping\\n\", id)\n            return\n        case urls \u003c- fmt.Sprintf(\"https://example.com/page/%d\", rand.Intn(1000)):\n            time.Sleep(100 * time.Millisecond)\n        }\n    }\n}\n\nfunc download(id int, urls \u003c-chan string, results chan\u003c- string) {\n    for url := range urls {\n        // Simulate download\n        time.Sleep(time.Duration(rand.Intn(300)) * time.Millisecond)\n        results \u003c- fmt.Sprintf(\"Downloaded: %s (by worker %d)\", url, id)\n    }\n    fmt.Printf(\"Downloader %d: no more URLs\\n\", id)\n}\n\nfunc main() {\n    urls := make(chan string, 10) // buffer absorbs bursts\n    results := make(chan string, 10)\n    done := make(chan struct{})\n\n    // 2 producers\n    for i := 1; i \u003c= 2; i++ {\n        go discover(i, urls, done)\n    }\n\n    // 3 consumers\n    for i := 1; i \u003c= 3; i++ {\n        go download(i, urls, results)\n    }\n\n    // Collect 10 results\n    for i := 0; i \u003c 10; i++ {\n        fmt.Println(\u003c-results)\n    }\n\n    // Stop producers\n    close(done)\n\n    // Give consumers time to finish in-flight work\n    // (In production, use sync.WaitGroup)\n    time.Sleep(500 * time.Millisecond)\n}\n```\n\n**Key design decisions:**\n\n```\nurls buffer=10 → absorbs bursts from 2 producers, consumers drain it\nresults buffer=10 → consumers don't block on results, main drains it\ndone unbuffered → close() broadcasts to ALL producers simultaneously\n```\n\n---\n\n### Pattern 3.2: Pipeline — The Go Blog's Canonical Pattern\n\nThis pattern comes directly from Sameer Ajmani's 2014 Go Blog post \"Go Concurrency Patterns: Pipelines and cancellation\" (`go.dev/blog/pipelines`).\n\n**Concept:**\n\n```\nstage1() → [chan] → stage2() → [chan] → stage3() → [chan] → main\n```\n\nEach stage: receives from upstream channel, processes, sends to downstream channel. Each stage runs in its own goroutine.\n\n**Problem**: Build an image processing pipeline: generate filenames → read files → resize → encode → save.\n\nWe'll simulate with integers: generate numbers → square them → filter evens → print.\n\n```go\npackage main\n\nimport \"fmt\"\n\n// Stage 1: Generator - produces numbers\nfunc generate(nums ...int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for _, n := range nums {\n            out \u003c- n\n        }\n    }()\n    return out\n}\n\n// Stage 2: Square - receives numbers, sends squares\nfunc square(in \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for n := range in {\n            out \u003c- n * n\n        }\n    }()\n    return out\n}\n\n// Stage 3: Filter - only passes values matching predicate\nfunc filter(in \u003c-chan int, pred func(int) bool) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for n := range in {\n            if pred(n) {\n                out \u003c- n\n            }\n        }\n    }()\n    return out\n}\n\nfunc main() {\n    // Build the pipeline\n    nums := generate(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n    squared := square(nums)\n    evens := filter(squared, func(n int) bool { return n%2 == 0 })\n\n    // Consume the pipeline\n    for v := range evens {\n        fmt.Println(v) // 4, 16, 36, 64, 100\n    }\n}\n```\n\n**Why each stage returns `\u003c-chan int` (receive-only):**\n\nThe caller can ONLY read from the pipeline output — they cannot send to it or close it. The pipeline function owns the channel lifecycle.\n\n**The pipeline anatomy:**\n\n```\ngenerate(1..10)\n    │ goroutine: sends 1,2,...,10 then closes\n    │\n    ▼ chan int (closed when generate is done)\n\nsquare(nums)\n    │ goroutine: ranges over nums, sends n*n, then closes\n    │\n    ▼ chan int (closed when square is done)\n\nfilter(squared, isEven)\n    │ goroutine: ranges over squared, sends if even, then closes\n    │\n    ▼ chan int (closed when filter is done)\n\nmain: ranges over evens, prints values\n```\n\n**This is a real pattern**: Docker's image processing (pull → decompress → validate → write layers) uses exactly this pipeline structure internally.\n\n---\n\n### Quiz 3.2: Pipeline Ordering\n\n**Question**: In the pipeline above, is the output guaranteed to be in order (4, 16, 36, 64, 100)?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Yes, in this specific case** — because each stage is a **single goroutine**. A single goroutine processes values sequentially: it receives 1, squares to 1, passes it through the filter (1 is odd, dropped). Receives 2, squares to 4, passes it (4 is even, emits 4). And so on.\n\nThe ordering would break if we added **fan-out** (multiple goroutines doing the squaring). Then goroutine A might pick up 4 and goroutine B might pick up 9, and either could finish first. For ordered fan-out, you'd need to assign work to goroutines by index, not first-come-first-serve.\n\nSingle-goroutine pipeline stages = ordered. Multi-goroutine stages = potentially unordered.\n\n\u003c/details\u003e\n\n---\n\n### Pattern 3.3: Fan-Out (Distribute Work)\n\n**Concept:**\n\n```\n         ┌── worker 1 ──┐\nsource → ├── worker 2 ──┤ → results\n         └── worker 3 ──┘\n```\n\nOne source channel, multiple goroutines reading from it. Go's channel receive is already concurrent-safe — multiple goroutines can all call `\u003c-jobs` and each gets a different job. No manual partitioning needed!\n\n**Problem**: Process 100 images. Use N workers to do it in parallel.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \"math/rand\"\n)\n\ntype Job struct {\n    ID int\n    Image string\n}\n\ntype Result struct {\n    JobID int\n    Processed string\n    WorkerID int\n}\n\nfunc processImage(job Job, workerID int) Result {\n    // Simulate variable processing time\n    time.Sleep(time.Duration(rand.Intn(50)) * time.Millisecond)\n    return Result{\n        JobID: job.ID,\n        Processed: fmt.Sprintf(\"processed_%s\", job.Image),\n        WorkerID: workerID,\n    }\n}\n\n// Worker: reads jobs until jobs channel closes\nfunc worker(id int, jobs \u003c-chan Job, results chan\u003c- Result, wg *sync.WaitGroup) {\n    defer wg.Done()\n    for job := range jobs {\n        results \u003c- processImage(job, id)\n    }\n    fmt.Printf(\"Worker %d: no more jobs, exiting\\n\", id)\n}\n\nfunc main() {\n    const numJobs = 20\n    const numWorkers = 5\n\n    jobs := make(chan Job, numJobs) // buffer all jobs upfront\n    results := make(chan Result, numJobs)\n\n    var wg sync.WaitGroup\n\n    // Start workers (fan-out)\n    for i := 1; i \u003c= numWorkers; i++ {\n        wg.Add(1)\n        go worker(i, jobs, results, \u0026wg)\n    }\n\n    // Send all jobs\n    for i := 1; i \u003c= numJobs; i++ {\n        jobs \u003c- Job{ID: i, Image: fmt.Sprintf(\"image_%d.jpg\", i)}\n    }\n    close(jobs) // CRITICAL: signal workers there are no more jobs\n\n    // Close results when all workers are done\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    // Collect all results\n    for result := range results {\n        fmt.Printf(\"Job %d processed by worker %d: %s\\n\",\n            result.JobID, result.WorkerID, result.Processed)\n    }\n}\n```\n\n**The flow:**\n\n```\nmain: sends 20 jobs into buffered channel, then closes jobs channel\nworkers: all range over jobs channel, each gets different jobs\n         when jobs is closed, all workers' range loops exit\n         each worker calls wg.Done() via defer\ncloser: wg.Wait() blocks until all 5 workers done, then closes results\nmain: ranges over results until results is closed\n```\n\n**The `close(jobs)` is the key!** Without it, workers would block on `range jobs` forever after all jobs are consumed. Always close the input to signal \"no more work.\"\n\n---\n\n### Quiz 3.3: Fan-Out Race\n\n**Is there a race condition in this fan-out pattern?**\n\n```go\n// Multiple goroutines all doing:\nfor job := range jobs {\n    results \u003c- processImage(job, id)\n}\n```\n\nTwo goroutines are both reading from `jobs`. Isn't that a race?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**No race condition!** Go channels are safe for concurrent use. The hchan struct has an internal mutex protecting all operations. When multiple goroutines call `\u003c-jobs`, only one at a time gets the value — the others block until the lock is acquired. This is guaranteed by the Go memory model.\n\nThis is why channels are powerful: you get concurrent-safe job distribution with zero user-space locking code. The channel IS the lock.\n\nThe race detector (`go run -race`) will confirm: no races.\n\n\u003c/details\u003e\n\n---\n\n### Pattern 3.4: Fan-In (Merge Multiple Channels)\n\n**Concept:**\n\n```\nworker 1 ──┐\nworker 2 ──┼── merge ──→ single output channel\nworker 3 ──┘\n```\n\nMultiple goroutines produce results on separate channels. We want ONE channel with all results combined. This is the inverse of fan-out.\n\n**The canonical merge function (from Go Blog 2014):**\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\n// merge combines multiple input channels into one output channel\nfunc merge(channels ...\u003c-chan int) \u003c-chan int {\n    var wg sync.WaitGroup\n    merged := make(chan int, 10)\n\n    // forward: goroutine that forwards one channel to merged\n    forward := func(ch \u003c-chan int) {\n        defer wg.Done()\n        for v := range ch {\n            merged \u003c- v\n        }\n    }\n\n    // Start a forwarding goroutine for each input channel\n    wg.Add(len(channels))\n    for _, ch := range channels {\n        go forward(ch)\n    }\n\n    // Close merged when all input channels are exhausted\n    go func() {\n        wg.Wait()\n        close(merged)\n    }()\n\n    return merged\n}\n\nfunc producer(values ...int) \u003c-chan int {\n    out := make(chan int, len(values))\n    for _, v := range values {\n        out \u003c- v\n    }\n    close(out)\n    return out\n}\n\nfunc main() {\n    // Three independent producers\n    ch1 := producer(1, 2, 3)\n    ch2 := producer(10, 20, 30)\n    ch3 := producer(100, 200, 300)\n\n    // Merge all into one\n    for v := range merge(ch1, ch2, ch3) {\n        fmt.Println(v)\n        // Output: 9 values in UNDEFINED ORDER\n        // (values from different channels interleave)\n    }\n}\n```\n\n**What does `sync.WaitGroup` do here?**\n\n```\nwg.Add(3) ← \"expecting 3 goroutines\"\n  goroutine 1 ranges ch1, calls wg.Done() when ch1 closes\n  goroutine 2 ranges ch2, calls wg.Done() when ch2 closes\n  goroutine 3 ranges ch3, calls wg.Done() when ch3 closes\nwg.Wait() ← blocks until all 3 goroutines called Done()\nclose(merged) ← THEN close the output\n```\n\nWithout the WaitGroup, how would we know when to close `merged`? We'd close too early (before all goroutines finish forwarding) and get panics.\n\n---\n\n### Exercise 3.4: Complete the Fan-Out + Fan-In Pipeline\n\nBuild a parallel word counter. Given a list of sentences, use fan-out to count words in parallel across N workers, then fan-in to merge results.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"strings\"\n    \"sync\"\n)\n\ntype WordCount struct {\n    Sentence string\n    Count int\n}\n\nfunc countWords(in \u003c-chan string, wg *sync.WaitGroup) \u003c-chan WordCount {\n    out := make(chan WordCount)\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        defer close(out)\n        // TODO: range over in, count words in each sentence, send WordCount\n    }()\n    return out\n}\n\nfunc fanIn(wg *sync.WaitGroup, channels ...\u003c-chan WordCount) \u003c-chan WordCount {\n    merged := make(chan WordCount, 10)\n    // TODO: start a goroutine per channel to forward to merged\n    // TODO: close merged when all channels done (use a separate goroutine with wg.Wait)\n    return merged\n}\n\nfunc main() {\n    sentences := []string{\n        \"the quick brown fox\",\n        \"jumps over the lazy dog\",\n        \"go channels are awesome\",\n        \"practice makes perfect\",\n    }\n\n    jobs := make(chan string, len(sentences))\n    for _, s := range sentences {\n        jobs \u003c- s\n    }\n    close(jobs)\n\n    var wg sync.WaitGroup\n\n    // Fan-out: 3 workers\n    workers := make([]\u003c-chan WordCount, 3)\n    for i := range workers {\n        workers[i] = countWords(jobs, \u0026wg)\n    }\n\n    // Fan-in results\n    for result := range fanIn(\u0026wg, workers...) {\n        fmt.Printf(\"%q → %d words\\n\", result.Sentence, result.Count)\n    }\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eFull solution\u003c/summary\u003e\n\n```go\nfunc countWords(in \u003c-chan string, wg *sync.WaitGroup) \u003c-chan WordCount {\n    out := make(chan WordCount)\n    wg.Add(1)\n    go func() {\n        defer wg.Done()\n        defer close(out)\n        for sentence := range in {\n            count := len(strings.Fields(sentence))\n            out \u003c- WordCount{Sentence: sentence, Count: count}\n        }\n    }()\n    return out\n}\n\nfunc fanIn(wg *sync.WaitGroup, channels ...\u003c-chan WordCount) \u003c-chan WordCount {\n    merged := make(chan WordCount, 10)\n\n    for _, ch := range channels {\n        ch := ch // capture loop variable!\n        go func() {\n            for v := range ch {\n                merged \u003c- v\n            }\n        }()\n    }\n\n    go func() {\n        wg.Wait() // wait for all workers done\n        close(merged) // then close merged\n    }()\n\n    return merged\n}\n```\n\nNote `ch := ch` inside the loop — without this, all goroutines close over the same `ch` variable (the last iteration's value). This is the classic Go loop variable capture bug!\n\n\u003c/details\u003e\n\n---\n\n## Level 4: Advanced Patterns\n\n### Pattern 4.1: Worker Pool\n\nThe Worker Pool is the most common concurrent pattern in production Go code. It's a controlled version of fan-out where the number of goroutines is **fixed** (unlike unbounded goroutine spawning).\n\n**When to use it**: CPU-intensive work (image resizing, JSON parsing, compression) where spawning a goroutine per item would be too expensive.\n\n**Real-world usage**: Prometheus uses this for concurrent metric collection. Docker uses it for concurrent layer pulls.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \"math/rand\"\n)\n\ntype Pool struct {\n    jobs chan func()\n    wg sync.WaitGroup\n    once sync.Once\n    quit chan struct{}\n}\n\nfunc NewPool(workers int) *Pool {\n    p := \u0026Pool{\n        jobs: make(chan func(), workers*2), // buffer for burst\n        quit: make(chan struct{}),\n    }\n\n    for i := 0; i \u003c workers; i++ {\n        p.wg.Add(1)\n        go p.worker(i)\n    }\n\n    return p\n}\n\nfunc (p *Pool) worker(id int) {\n    defer p.wg.Done()\n    for {\n        select {\n        case job, ok := \u003c-p.jobs:\n            if !ok {\n                fmt.Printf(\"Worker %d: jobs channel closed, exiting\\n\", id)\n                return\n            }\n            job()\n        case \u003c-p.quit:\n            fmt.Printf(\"Worker %d: quit signal received\\n\", id)\n            return\n        }\n    }\n}\n\nfunc (p *Pool) Submit(job func()) {\n    select {\n    case p.jobs \u003c- job:\n    case \u003c-p.quit:\n        // pool is shutting down, drop the job\n    }\n}\n\nfunc (p *Pool) Stop() {\n    p.once.Do(func() {\n        close(p.quit) // signal all workers to stop (broadcast)\n    })\n    p.wg.Wait()\n}\n\nfunc main() {\n    pool := NewPool(3)\n\n    var mu sync.Mutex\n    var results []string\n\n    for i := 0; i \u003c 10; i++ {\n        i := i // capture loop variable\n        pool.Submit(func() {\n            delay := time.Duration(rand.Intn(100)) * time.Millisecond\n            time.Sleep(delay)\n            result := fmt.Sprintf(\"job %d completed\", i)\n\n            mu.Lock()\n            results = append(results, result)\n            mu.Unlock()\n        })\n    }\n\n    // Allow work to complete (in production, use a WaitGroup per batch)\n    time.Sleep(500 * time.Millisecond)\n    pool.Stop()\n\n    for _, r := range results {\n        fmt.Println(r)\n    }\n}\n```\n\n**Why `sync.Once` for `Stop()`?**\n\nWithout it, calling `Stop()` twice would `close(quit)` twice → panic! `sync.Once` guarantees the close happens exactly once, no matter how many times `Stop()` is called.\n\n---\n\n### Quiz 4.1: Pool Sizing\n\n**Your pool has 4 workers and `jobs` channel buffer = 8. You submit 20 jobs. What happens?**\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n1. Buffer fills immediately: 8 jobs in buffer, 4 workers each pick one = 12 jobs submitted before blocking\n2. `Submit()` (call 13) blocks on `p.jobs \u003c- job`\n3. As workers complete jobs and pick new ones from the buffer, `Submit()` unblocks\n4. All 20 jobs eventually complete\n\nThe buffer exists to absorb bursts so producers don't have to wait for exactly a worker to be free. Rule of thumb: buffer = numWorkers * 2 or numWorkers * 10 depending on job submission rate vs completion rate.\n\nIf you need `Submit()` to never block, use `select { case p.jobs \u003c- job: default: /* drop or return error */ }`.\n\n\u003c/details\u003e\n\n---\n\n### Pattern 4.2: Semaphore via Buffered Channel\n\nSometimes you don't want a fixed pool of goroutines. You want unlimited goroutines, but at most N running at once. Buffered channels solve this elegantly.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\nfunc main() {\n    const maxConcurrent = 3\n\n    // Semaphore: at most maxConcurrent goroutines can hold a slot\n    sem := make(chan struct{}, maxConcurrent)\n\n    var wg sync.WaitGroup\n\n    for i := 1; i \u003c= 10; i++ {\n        i := i\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n\n            sem \u003c- struct{}{} // acquire slot (blocks if all slots taken)\n            defer func() { \u003c-sem }() // release slot when done\n\n            // Critical section - at most 3 goroutines here at once\n            fmt.Printf(\"Processing %d (slots used: %d/%d)\\n\", i, len(sem), cap(sem))\n            time.Sleep(100 * time.Millisecond)\n        }()\n    }\n\n    wg.Wait()\n    fmt.Println(\"All done\")\n}\n```\n\n**How it works:**\n\n```\nsem = make(chan struct{}, 3)\n        ┌───┬───┬───┐\n        │ │ │ │ ← 3 slots\n        └───┴───┴───┘\n\nGoroutine wants to start:\n  sem \u003c- struct{}{} → fills one slot\n\n  If buffer has space → goroutine runs immediately\n  If buffer is FULL (3 goroutines running) → goroutine BLOCKS\n\nGoroutine finishes:\n  \u003c-sem → frees one slot\n  → a waiting goroutine unblocks\n```\n\n**Real-world usage**: CockroachDB uses semaphore channels (`pkg/util/stop/stopper.go`) to limit concurrent background operations per node.\n\nFor weighted semaphores (different operations need different numbers of \"slots\"): use `golang.org/x/sync/semaphore.NewWeighted()`.\n\n---\n\n### Pattern 4.3: The Nil Channel Trick\n\nThis is one of the most counterintuitive but powerful channel patterns. It comes from Francesc Campoy's JustForFunc series (Episode 26) and Dave Cheney's \"Curious Channels\" post.\n\n**The problem**: Merging two channels. When one closes, you want to stop reading from it but continue reading from the other.\n\n**Without the nil channel trick (busy loop bug):**\n\n```go\n// BROKEN: infinite loop after ch1 closes!\nfunc merge(ch1, ch2 \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for ch1 != nil || ch2 != nil {\n            select {\n            case v, ok := \u003c-ch1:\n                if !ok {\n                    ch1 = nil // mark as \"done\"... but nil receive still selected!\n                    continue\n                }\n                out \u003c- v\n            case v, ok := \u003c-ch2:\n                if !ok {\n                    ch2 = nil\n                    continue\n                }\n                out \u003c- v\n            }\n        }\n    }()\n    return out\n}\n```\n\nWait — actually the nil assignment IS the fix! A nil channel case in `select` is **never selected**. This is the trick!\n\n**The nil channel trick — fully explained:**\n\n```go\nfunc merge(ch1, ch2 \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n\n        for ch1 != nil || ch2 != nil {\n            select {\n            case v, ok := \u003c-ch1:\n                if !ok {\n                    ch1 = nil // ← THE TRICK: nil channel case is NEVER selected\n                    continue // so this case is effectively removed from select!\n                }\n                out \u003c- v\n            case v, ok := \u003c-ch2:\n                if !ok {\n                    ch2 = nil // ← same for ch2\n                    continue\n                }\n                out \u003c- v\n            }\n        }\n    }()\n    return out\n}\n```\n\n**What happens step by step:**\n\n```\nIteration 1: ch1=open, ch2=open\n  select: either case can fire\n\nch1 closes:\n  case v, ok := \u003c-ch1: fires with ok=false\n  ch1 = nil ← now ch1 is nil\n\nIteration 2: ch1=nil, ch2=open\n  select sees:\n    case \u003c-nil: ← nil channel, NEVER selected (skipped!)\n    case \u003c-ch2: ← only this can fire\n  select only picks from ch2 now!\n\nch2 closes:\n  ch2 = nil\n  Loop condition: ch1 != nil || ch2 != nil → false\n  Loop exits, goroutine returns, close(out)\n```\n\n**Dave Cheney's Channel Axioms** (from `dave.cheney.net/2014/03/19/channel-axioms`):\n\n```\nA send to a nil channel blocks forever\nA receive from a nil channel blocks forever\n```\n\nBut in `select`, \"blocks forever\" means \"is never chosen\" — making nil channels perfect for dynamically disabling select cases!\n\n---\n\n### Quiz 4.3: Nil Behavior\n\n**What does each operation do? Predict the behavior.**\n\n```go\nvar ch chan int // zero value = nil\n\n// A:\nch \u003c- 42\n\n// B:\nv := \u003c-ch\n\n// C:\nclose(ch)\n\n// D:\nselect {\ncase v := \u003c-ch: // ch is nil\n    fmt.Println(v)\ndefault:\n    fmt.Println(\"no value\")\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**A**: Blocks forever. The goroutine parks and never unblocks (unless something else assigns ch).\n\n**B**: Blocks forever. Same as A.\n\n**C**: `panic: close of nil channel`\n\n**D**: `\"no value\"` — The `default` case fires! When all non-default cases would block (which a nil channel always does), `select` falls through to `default`. This is how you do a non-blocking receive from a potentially-nil channel.\n\nThis is why you sometimes see:\n```go\nselect {\ncase \u003c-ctx.Done():\n    return\ndefault:\n}\n```\nat the top of goroutine loops — if ctx is a non-cancelable background context, `ctx.Done()` returns a nil channel, and this select is a no-op.\n\n\u003c/details\u003e\n\n---\n\n### Pattern 4.4: Or-Done Channel\n\nFrom Katherine Cox-Buday's \"Concurrency in Go\" (O'Reilly, 2017). Wraps channel reads with done-channel checking in a reusable helper.\n\n**The problem**: Every goroutine loop that ranges over a channel needs to also check for cancellation:\n\n```go\n// Without or-done: duplicated select boilerplate everywhere\nfor {\n    select {\n    case v, ok := \u003c-myChan:\n        if !ok {\n            return\n        }\n        // process v\n    case \u003c-done:\n        return\n    }\n}\n```\n\n**The or-done pattern**: Extract this into a helper:\n\n```go\n// orDone wraps ch so ranging over it also respects the done channel\nfunc orDone(done \u003c-chan struct{}, ch \u003c-chan interface{}) \u003c-chan interface{} {\n    out := make(chan interface{})\n    go func() {\n        defer close(out)\n        for {\n            select {\n            case \u003c-done:\n                return\n            case v, ok := \u003c-ch:\n                if !ok {\n                    return\n                }\n                select {\n                case out \u003c- v:\n                case \u003c-done:\n                    return\n                }\n            }\n        }\n    }()\n    return out\n}\n```\n\n**Usage - now clean!**\n\n```go\n// Pipeline stage that respects cancellation\nfunc process(done \u003c-chan struct{}, in \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for v := range orDone(done, in) { // ← clean!\n            // process v\n            out \u003c- v * 2\n        }\n    }()\n    return out\n}\n```\n\nThe `for range orDone(...)` pattern hides all the `select` boilerplate while still correctly handling both channel closure and cancellation.\n\n---\n\n### Pattern 4.5: Tee Channel — Splitting Output\n\nNamed after the Unix `tee` command. Sends each value to TWO output channels. Useful for logging, metrics, or feeding two different consumers.\n\n```go\nfunc tee(done \u003c-chan struct{}, in \u003c-chan int) (\u003c-chan int, \u003c-chan int) {\n    out1 := make(chan int)\n    out2 := make(chan int)\n\n    go func() {\n        defer close(out1)\n        defer close(out2)\n\n        for val := range orDone(done, in) {\n            // Use local variables to hold the channels\n            // so we can nil them after each send\n            var out1Ch, out2Ch = out1, out2\n\n            // Send to BOTH - must send to both before reading next value\n            for i := 0; i \u003c 2; i++ {\n                select {\n                case out1Ch \u003c- val:\n                    out1Ch = nil // sent to out1, don't send again\n                case out2Ch \u003c- val:\n                    out2Ch = nil // sent to out2, don't send again\n                case \u003c-done:\n                    return\n                }\n            }\n        }\n    }()\n\n    return out1, out2\n}\n```\n\n**The nil channel trick again!** After sending to `out1`, we nil `out1Ch` so the next loop iteration can only send to `out2Ch`. After both sends, we move to the next value. Both consumers must receive before the next value is sent (backpressure propagates).\n\n---\n\n### Pattern 4.6: Bridge Channel — Channel of Channels\n\nAlso from Cox-Buday. Flattens a `\u003c-chan \u003c-chan T` into a `\u003c-chan T`. Useful for reconnection scenarios where each new connection yields a new channel.\n\n```go\nfunc bridge(done \u003c-chan struct{}, chanStream \u003c-chan \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for {\n            var stream \u003c-chan int\n            select {\n            case maybeStream, ok := \u003c-chanStream:\n                if !ok {\n                    return // no more streams\n                }\n                stream = maybeStream\n            case \u003c-done:\n                return\n            }\n            // Forward from this stream until it closes\n            for val := range orDone(done, stream) {\n                select {\n                case out \u003c- val:\n                case \u003c-done:\n                    return\n                }\n            }\n        }\n    }()\n    return out\n}\n```\n\n**Real-world application**: etcd's raft node uses a `chan chan Status` (channel of channels) pattern for serialized status requests. The caller sends a response channel, the node loop writes the status into it, and the caller reads the answer — all without locks.\n\n---\n\n## Level 5: Expert Problems\n\n### Problem 5.1: Fix Five Goroutine Leaks\n\nEach snippet has a goroutine leak. Identify and fix each one.\n\n**Leak 1: The Forgotten Sender**\n\n```go\nfunc getFirst(urls []string) (string, error) {\n    resultCh := make(chan string) // BUG!\n\n    for _, url := range urls {\n        url := url\n        go func() {\n            // Simulate HTTP fetch\n            time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)\n            resultCh \u003c- url + \" response\"\n        }()\n    }\n\n    select {\n    case result := \u003c-resultCh:\n        return result, nil\n    case \u003c-time.After(50 * time.Millisecond):\n        return \"\", errors.New(\"timeout\")\n    }\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eFix 1\u003c/summary\u003e\n\n```go\nfunc getFirst(urls []string) (string, error) {\n    resultCh := make(chan string, len(urls)) // buffer = number of goroutines\n\n    for _, url := range urls {\n        url := url\n        go func() {\n            time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond)\n            resultCh \u003c- url + \" response\"\n        }()\n    }\n\n    select {\n    case result := \u003c-resultCh:\n        return result, nil\n    case \u003c-time.After(50 * time.Millisecond):\n        return \"\", errors.New(\"timeout\")\n    }\n    // Goroutines still running? They send to buffered channel and exit!\n}\n```\n\nWith a buffered channel of size `len(urls)`, all goroutines can send their results and exit, even if nobody is reading. The results just sit in the buffer until GC'd.\n\n\u003c/details\u003e\n\n**Leak 2: The Abandoned Receiver**\n\n```go\nfunc streamNumbers(n int) \u003c-chan int {\n    ch := make(chan int)\n    go func() {\n        for i := 0; i \u003c n; i++ {\n            ch \u003c- i\n        }\n        // BUG: never close(ch)!\n    }()\n    return ch\n}\n\nfunc main() {\n    for v := range streamNumbers(10) { // range never exits!\n        fmt.Println(v)\n    }\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eFix 2\u003c/summary\u003e\n\n```go\nfunc streamNumbers(n int) \u003c-chan int {\n    ch := make(chan int)\n    go func() {\n        defer close(ch) // ← close tells range to stop\n        for i := 0; i \u003c n; i++ {\n            ch \u003c- i\n        }\n    }()\n    return ch\n}\n```\n\n`defer close(ch)` is the fix. The `range` over a channel only exits when the channel is closed. Without close, `range` blocks forever waiting for more values.\n\n\u003c/details\u003e\n\n**Leak 3: The Early Return**\n\n```go\nfunc process(jobs []string) []string {\n    results := make(chan string, len(jobs))\n\n    for _, job := range jobs {\n        job := job\n        go func() {\n            if job == \"skip\" {\n                return // BUG: goroutine exits without sending!\n            }\n            results \u003c- processJob(job)\n        }()\n    }\n\n    // collect results\n    var out []string\n    for range jobs { // expects exactly len(jobs) results!\n        out = append(out, \u003c-results) // blocks forever if any goroutine didn't send\n    }\n    return out\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eFix 3\u003c/summary\u003e\n\n```go\nfunc process(jobs []string) []string {\n    type result struct {\n        value string\n        skip bool\n    }\n    results := make(chan result, len(jobs))\n\n    for _, job := range jobs {\n        job := job\n        go func() {\n            if job == \"skip\" {\n                results \u003c- result{skip: true} // always send!\n                return\n            }\n            results \u003c- result{value: processJob(job)}\n        }()\n    }\n\n    var out []string\n    for range jobs {\n        r := \u003c-results\n        if !r.skip {\n            out = append(out, r.value)\n        }\n    }\n    return out\n}\n```\n\nEvery goroutine must send exactly one value. If early return is needed, send a sentinel value indicating \"nothing to contribute.\"\n\n\u003c/details\u003e\n\n**Leak 4: The time.After in a Loop (Pre-1.23)**\n\n```go\nfunc watchForActivity(ch \u003c-chan Event) {\n    for {\n        select {\n        case e := \u003c-ch:\n            handleEvent(e)\n        case \u003c-time.After(5 * time.Minute): // BUG: memory leak!\n            log.Println(\"no activity for 5 minutes\")\n        }\n    }\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eFix 4\u003c/summary\u003e\n\n```go\nfunc watchForActivity(ch \u003c-chan Event) {\n    timer := time.NewTimer(5 * time.Minute)\n    defer timer.Stop()\n\n    for {\n        select {\n        case e := \u003c-ch:\n            handleEvent(e)\n            // Reset timer after each event\n            if !timer.Stop() {\n                select {\n                case \u003c-timer.C:\n                default:\n                }\n            }\n            timer.Reset(5 * time.Minute)\n        case \u003c-timer.C:\n            log.Println(\"no activity for 5 minutes\")\n            timer.Reset(5 * time.Minute)\n        }\n    }\n}\n```\n\nReuse one timer. Never create new timers in loops (on Go versions before 1.23).\n\n\u003c/details\u003e\n\n**Leak 5: The Double Close**\n\n```go\nfunc broadcast(messages \u003c-chan string, subscribers []chan string) {\n    go func() {\n        for msg := range messages {\n            for _, sub := range subscribers {\n                sub \u003c- msg\n            }\n        }\n        // Close all subscriber channels when done\n        for _, sub := range subscribers {\n            close(sub) // BUG: what if called twice? or sub already closed?\n        }\n    }()\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eFix 5\u003c/summary\u003e\n\n```go\nfunc broadcast(messages \u003c-chan string, subscribers []chan string) {\n    var closeOnce sync.Once\n\n    closeAll := func() {\n        for _, sub := range subscribers {\n            close(sub)\n        }\n    }\n\n    go func() {\n        defer closeOnce.Do(closeAll) // guaranteed exactly once\n        for msg := range messages {\n            for _, sub := range subscribers {\n                select {\n                case sub \u003c- msg:\n                default:\n                    // subscriber full/slow, drop or handle\n                }\n            }\n        }\n    }()\n}\n```\n\n`sync.Once` guarantees `closeAll` runs exactly once no matter what. The `select` with `default` prevents blocking if a subscriber is slow (non-blocking send).\n\n\u003c/details\u003e\n\n---\n\n### Problem 5.2: Build a Rate Limiter\n\n**Real requirement**: Allow at most 5 requests per second. Implement a simple rate limiter using `time.Ticker`.\n\nThis is the pattern the Go Wiki uses at `go.dev/wiki/RateLimiting`:\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\ntype RateLimiter struct {\n    ticker *time.Ticker\n    done chan struct{}\n}\n\nfunc NewRateLimiter(rps int) *RateLimiter {\n    interval := time.Second / time.Duration(rps)\n    return \u0026RateLimiter{\n        ticker: time.NewTicker(interval),\n        done: make(chan struct{}),\n    }\n}\n\n// Wait blocks until the next allowed request slot\nfunc (rl *RateLimiter) Wait() {\n    \u003c-rl.ticker.C\n}\n\n// Stop shuts down the rate limiter\nfunc (rl *RateLimiter) Stop() {\n    rl.ticker.Stop()\n}\n\nfunc main() {\n    limiter := NewRateLimiter(5) // 5 requests per second\n    defer limiter.Stop()\n\n    for i := 1; i \u003c= 10; i++ {\n        limiter.Wait() // blocks until our turn\n        fmt.Printf(\"Request %d at %s\\n\", i, time.Now().Format(\"15:04:05.000\"))\n        // In real code: go makeRequest(i)\n    }\n}\n```\n\n**Add burst support** (5 req/s but allow initial burst of 3):\n\n```go\ntype BurstLimiter struct {\n    tokens chan struct{}\n    ticker *time.Ticker\n}\n\nfunc NewBurstLimiter(rps, burst int) *BurstLimiter {\n    bl := \u0026BurstLimiter{\n        tokens: make(chan struct{}, burst),\n        ticker: time.NewTicker(time.Second / time.Duration(rps)),\n    }\n\n    // Pre-fill with burst tokens\n    for i := 0; i \u003c burst; i++ {\n        bl.tokens \u003c- struct{}{}\n    }\n\n    // Refill one token per tick\n    go func() {\n        for range bl.ticker.C {\n            select {\n            case bl.tokens \u003c- struct{}{}: // add token if room\n            default: // drop if full (already at max burst)\n            }\n        }\n    }()\n\n    return bl\n}\n\nfunc (bl *BurstLimiter) Wait() {\n    \u003c-bl.tokens // blocks when no tokens available\n}\n```\n\n---\n\n### Problem 5.3: Implement the Heartbeat Pattern\n\nFrom Katherine Cox-Buday's \"Concurrency in Go\" — heartbeats help test concurrent code deterministically.\n\n**Problem**: You have a long-running goroutine. How do you test that it's still alive and processing work? Use a heartbeat channel.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc longRunningWork(done \u003c-chan struct{}, pulse time.Duration) (\u003c-chan struct{}, \u003c-chan int) {\n    heartbeat := make(chan struct{}, 1)\n    results := make(chan int)\n\n    go func() {\n        defer close(results)\n\n        ticker := time.NewTicker(pulse)\n        defer ticker.Stop()\n\n        n := 0\n        for {\n            select {\n            case \u003c-done:\n                return\n\n            case \u003c-ticker.C: // send heartbeat periodically\n                select {\n                case heartbeat \u003c- struct{}{}: // non-blocking!\n                default: // drop if nobody listening\n                }\n\n            default:\n                // Do actual work\n                time.Sleep(1 * time.Millisecond)\n                n++\n                if n%10 == 0 {\n                    select {\n                    case results \u003c- n:\n                    case \u003c-done:\n                        return\n                    }\n                }\n            }\n        }\n    }()\n\n    return heartbeat, results\n}\n\nfunc monitorWork(done \u003c-chan struct{}, heartbeat \u003c-chan struct{}, timeout time.Duration) {\n    timeoutCh := time.After(timeout)\n\n    for {\n        select {\n        case \u003c-heartbeat:\n            fmt.Println(\" heartbeat received - worker is alive\")\n        case \u003c-timeoutCh:\n            fmt.Println(\" no heartbeat - worker may be stuck!\")\n            return\n        case \u003c-done:\n            return\n        }\n    }\n}\n\nfunc main() {\n    done := make(chan struct{})\n\n    heartbeat, results := longRunningWork(done, 100*time.Millisecond)\n\n    go monitorWork(done, heartbeat, 500*time.Millisecond)\n\n    for r := range results {\n        fmt.Println(\"result:\", r)\n        if r \u003e= 50 {\n            break\n        }\n    }\n\n    close(done)\n    time.Sleep(200 * time.Millisecond)\n}\n```\n\n**Why non-blocking heartbeat send?**\n\n```go\nselect {\ncase heartbeat \u003c- struct{}{}: // send if receiver is waiting\ndefault: // drop if nobody listening (don't block the worker!)\n}\n```\n\nThe heartbeat MUST NOT block the worker goroutine. If the monitor is slow, we just skip that heartbeat tick. The worker's job is to DO WORK, not to wait for monitoring.\n\n---\n\n## Level 6: Real-World Deep Dives\n\n### Deep Dive 1: How Docker Got Burned by Goroutine Leaks\n\nDocker (Moby) has an extensive history of goroutine leak bugs documented in their GitHub issues. Understanding them makes you a better engineer.\n\n**Issue #13014: `docker logs --follow` leaked goroutines**\n\nEvery call to `docker logs --follow` started goroutines to stream container logs. If the user pressed Ctrl+C, the HTTP connection closed — but the goroutines streaming to that connection didn't know. They'd block trying to write to a closed connection, leaking.\n\n**The pattern that caused it (simplified):**\n\n```go\n// Broken Docker-style attach (simplified)\nfunc attach(containerID string, out io.Writer) error {\n    logCh := make(chan []byte)\n\n    go readContainerLogs(containerID, logCh) // goroutine A\n\n    for log := range logCh {\n        if _, err := out.Write(log); err != nil {\n            return err // ← caller returns! goroutine A is still running!\n        }\n    }\n    return nil\n}\n```\n\n**Issue #9797: Container start failure leaked 6 goroutines**\n\nIf a container failed to start, the goroutines waiting for attach streams had nobody to receive from them. They'd wait forever.\n\n**Fix pattern (the done channel):**\n\n```go\n// Fixed: always have a cancellation path\nfunc attach(containerID string, out io.Writer, ctx context.Context) error {\n    logCh := make(chan []byte, 10)\n\n    go func() {\n        defer close(logCh)\n        readContainerLogs(ctx, containerID, logCh) // ctx propagates cancellation!\n    }()\n\n    for {\n        select {\n        case log, ok := \u003c-logCh:\n            if !ok {\n                return nil\n            }\n            if _, err := out.Write(log); err != nil {\n                return err // when we return, ctx cancellation cleans up goroutine\n            }\n        case \u003c-ctx.Done():\n            return ctx.Err()\n        }\n    }\n}\n```\n\n**How Uber measured this at scale:**\n\nUber wrote and open-sourced `uber-go/goleak` after discovering goroutine leaks in production. From their LeakProf blog post, they found that even 10 leaked goroutines per request at 1000 req/sec = **10,000 leaked goroutines accumulating per second**. At that rate, memory exhausts within minutes.\n\nTest your code for leaks:\n```go\nimport \"go.uber.org/goleak\"\n\nfunc TestMyFunction(t *testing.T) {\n    defer goleak.VerifyNone(t) // fails if goroutines leaked\n\n    // ... test code\n}\n```\n\n---\n\n### Deep Dive 2: Kubernetes Watch — A Channel-Based Event System\n\nKubernetes controllers watch for changes to objects (Pods, Services, etc.). The watch system is built entirely on channels.\n\nThe core interface (from `k8s.io/apimachinery/pkg/watch`):\n\n```go\ntype Interface interface {\n    Stop()\n    ResultChan() \u003c-chan Event // receive-only!\n}\n```\n\nThe `StreamWatcher` implementation shows real production channel patterns:\n\n```go\n// (Simplified from kubernetes/apimachinery/pkg/watch/streamwatcher.go)\ntype StreamWatcher struct {\n    result chan Event\n    done chan struct{}\n    // ...\n}\n\nfunc (sw *StreamWatcher) ResultChan() \u003c-chan Event {\n    return sw.result // returns receive-only view\n}\n\nfunc (sw *StreamWatcher) Stop() {\n    // Safe double-close using the nil channel trick:\n    select {\n    case \u003c-sw.done:\n        // already closed\n    default:\n        close(sw.done) // only close once\n    }\n}\n\nfunc (sw *StreamWatcher) receive() {\n    defer close(sw.result) // when streaming stops, close result\n    defer sw.Stop()\n\n    for {\n        event, err := sw.source.Decode()\n        if err != nil {\n            // handle error\n            return\n        }\n        select {\n        case sw.result \u003c- event:\n        case \u003c-sw.done:\n            return // Stop() was called\n        }\n    }\n}\n```\n\n**What Kubernetes taught us:**\n\nThe `Broadcaster` (which fans out to multiple watchers) has a `FullChannelBehavior` option: block or drop. They chose **drop for slow consumers** (`DropIfChannelFull`) to prevent one slow watcher from backpressuring the entire control plane. This is a real production decision: sometimes dropping events (triggering a re-list) is better than blocking the broadcaster.\n\n---\n\n### Deep Dive 3: etcd's Raft — 10 Channels, One Goroutine\n\netcd's Raft consensus algorithm is driven by a **single goroutine** selecting over 10 channels. No locks needed because all state access goes through the channel-based event loop.\n\n```\nThe raft node's run() loop (simplified):\n\n    select {\n    case pm := \u003c-r.propc: ← proposals from app layer\n        r.step(pm)\n    case m := \u003c-r.recvc: ← messages from peers\n        r.step(m)\n    case \u003c-r.tickc: ← clock tick for election timeout\n        r.tick()\n    case readyc \u003c- rd: ← send ready state to app layer\n        r.advance()\n    case \u003c-r.advancec: ← app layer says \"I processed the batch\"\n        r.advance()\n    case c := \u003c-r.status: ← channel of channels! (status query)\n        c \u003c- r.Status()\n    case \u003c-r.stop: ← shutdown\n        return\n    }\n```\n\n**The status query pattern** (`chan chan Status`) is architectural genius. Instead of locking the raft state to query it:\n\n```go\n// Caller:\nstatusCh := make(chan Status, 1)\nnode.status \u003c- statusCh // send a response channel\nstatus := \u003c-statusCh // wait for raft goroutine to fill it\n\n// Raft goroutine:\ncase c := \u003c-r.status:\n    c \u003c- r.Status() // writes current state into caller's channel\n```\n\nNo lock. The raft goroutine is the only one that ever reads internal state. All queries go through a channel, naturally serialized.\n\n---\n\n### Deep Dive 4: NSQ — Channels As The Core Data Structure\n\nNSQ (`nsqio/nsq`) is a real-time distributed messaging platform written in Go. Its entire message queue IS a Go buffered channel.\n\nFrom NSQ's internals documentation (`nsq.io/overview/internals.html`):\n\n\u003e \"Go's channels are a natural way to express queues, thus an NSQ topic/channel, at its core, is just a buffered go-chan of Message pointers.\"\n\nThe `Channel` struct in `nsqd/channel.go`:\n\n```go\ntype Channel struct {\n    memoryMsgChan chan *Message // ← THE QUEUE IS A GO CHANNEL\n    // ...\n}\n```\n\nBuffer size = `--mem-queue-size` config option (default 10,000). When the channel fills, messages overflow transparently to a disk-backed queue. Consumers simply `\u003c-memoryMsgChan`.\n\n**What this teaches us**: Go channels ARE queues. When your problem is literally \"I need a thread-safe FIFO queue of N items,\" a buffered channel is the idiomatic solution — not implementing a queue with a slice + mutex.\n\n---\n\n## Level 7: Pitfalls and Gotchas Reference\n\n### Gotcha 1: The Loop Variable Capture Trap\n\n```go\n// BUG: all goroutines send the same URL (last value of url)\nfor _, url := range urls {\n    go func() {\n        results \u003c- fetch(url) // url closes over the loop variable!\n    }()\n}\n\n// FIX: capture the current value\nfor _, url := range urls {\n    url := url // shadows the loop variable with a new local copy\n    go func() {\n        results \u003c- fetch(url) // url is now this goroutine's own copy\n    }()\n}\n\n// Also valid: pass as parameter\nfor _, url := range urls {\n    go func(u string) {\n        results \u003c- fetch(u)\n    }(url) // passed by value at the time of goroutine creation\n}\n```\n\n\u003e **Note**: In **Go 1.22+**, loop variables are re-declared per iteration automatically. The bug no longer exists with `GOEXPERIMENT=loopvar` (enabled by default in 1.22+). But you'll still see the fix pattern in older code and it's good to understand why.\n\n---\n\n### Gotcha 2: Ranging Over a Never-Closed Channel\n\n```go\n// BUG: this goroutine never exits\ngo func() {\n    for v := range ch { // blocks forever waiting for more values\n        process(v)\n    }\n}()\n\n// If nobody ever calls close(ch), this goroutine leaks!\n```\n\n**Rule**: If you return a channel from a function, you MUST document who closes it and when. If it's a `range` loop, the sender MUST close.\n\n---\n\n### Gotcha 3: Panic From Double-Close or Send-to-Closed\n\n```go\nvar once sync.Once\n\n// Safe close: guaranteed exactly once\nsafeClose := func() {\n    once.Do(func() { close(ch) })\n}\n\n// Safe send: check before sending\nsafeSend := func(v int) (closed bool) {\n    defer func() {\n        if recover() != nil {\n            closed = true\n        }\n    }()\n    ch \u003c- v\n    return false\n}\n```\n\nBoth patterns are in production code. The `sync.Once` close is idiomatic. The recover-based send is defensive and should be avoided if you can design away the need for it.\n\n---\n\n### Gotcha 4: Select Is Not Ordered (Priority)\n\n```go\n// You might expect done to be checked before data\n// But select is RANDOM when multiple cases are ready\nselect {\ncase \u003c-done:\n    return\ncase v := \u003c-data:\n    process(v)\n}\n\n// If both done AND data are ready simultaneously,\n// either case can fire! The done check is NOT guaranteed first!\n\n// For TRUE priority (done always wins):\nselect {\ncase \u003c-done:\n    return\ndefault:\n}\n// Only get here if done is NOT ready\nselect {\ncase \u003c-done:\n    return\ncase v := \u003c-data:\n    process(v)\n}\n```\n\nThe double-select (non-blocking done check first) ensures `done` is always processed first. The Go spec guarantees: \"If one or more of the communications can proceed, a single one that can proceed is chosen via a **uniform pseudo-random selection**.\"\n\n---\n\n### Gotcha 5: Sending to a Full Buffered Channel = Deadlock\n\n```go\nch := make(chan int, 3)\n\n// These are fine:\nch \u003c- 1 // buffer: [1]\nch \u003c- 2 // buffer: [1, 2]\nch \u003c- 3 // buffer: [1, 2, 3]\n\nch \u003c- 4 // DEADLOCK! buffer is full, no goroutine to receive\n         // (if in main goroutine with no other goroutines)\n```\n\n**Test with the race detector**: `go run -race` and `go test -race` catch many channel issues.\n\n---\n\n### The Channel Operation Quick Reference\n\n```\nOPERATION OPEN CHANNEL CLOSED CHANNEL NIL CHANNEL\n──────────────────────────────────────────────────────────────────────\nSend (ch \u003c- v) blocks if full PANIC blocks forever\nReceive (\u003c-ch) blocks if empty zero + ok=false blocks forever\nClose (close(ch)) closes it PANIC PANIC\nRange (for range) iterates drains + exits blocks forever\nSelect case ready if data always ready never selected\n```\n\n---\n\n## Level 8: Interview Preparation\n\n### The Questions Every Go Interview Asks\n\n**Q1: Explain the difference between buffered and unbuffered channels.**\n\n\u003e **What they're looking for**: Not just \"buffered has a buffer\" — they want you to explain the synchronization guarantee and when to use each.\n\n**Answer framework:**\n\nUnbuffered channels (`make(chan T)`) provide **synchronous handoff** — the send blocks until a receiver is ready, and the receive blocks until a sender is ready. Both goroutines meet at the point of communication. This is the Go equivalent of a rendezvous point.\n\nBuffered channels (`make(chan T, N)`) decouple sender and receiver. The send only blocks when the buffer is full; the receive only blocks when the buffer is empty. This allows the sender to proceed without waiting, up to N sends ahead.\n\n**Choose unbuffered when**: you need to know the receiver has gotten the value (guaranteed handoff). **Choose buffered when**: you want to reduce blocking (producer/consumer decoupling), or when you need N-capacity flow control.\n\nThe internal difference: unbuffered send always uses the fast-path (direct goroutine-to-goroutine copy) when a receiver is waiting, while buffered channels go through the ring buffer (two copies) unless the fast path applies.\n\n---\n\n**Q2: What happens when you receive from a closed channel?**\n\n\u003e **What they're looking for**: The `v, ok` idiom, zero values, buffered channel draining behavior.\n\n**Answer**: Receiving from a closed channel immediately returns the zero value of the channel's element type, with `ok = false`. For a buffered channel, any values remaining in the buffer are returned first (with `ok = true`). Only after the buffer is drained does it return zero values with `ok = false`.\n\n```go\nch := make(chan int, 3)\nch \u003c- 1\nch \u003c- 2\nclose(ch)\n\nv, ok := \u003c-ch // v=1, ok=true (from buffer)\nv, ok = \u003c-ch // v=2, ok=true (from buffer)\nv, ok = \u003c-ch // v=0, ok=false (channel closed, buffer empty)\nv, ok = \u003c-ch // v=0, ok=false (still ok, no panic)\n```\n\n---\n\n**Q3: Why does closing a nil channel panic?**\n\n\u003e **What they're looking for**: Understanding the design rationale, not just memorizing the behavior.\n\n**Answer**: A nil channel is one that has never been initialized — it points to no underlying `hchan` struct. Closing it would have nothing to operate on. The Go team chose panic (rather than a no-op or error) because closing nil almost certainly indicates a programmer bug: you forgot to initialize the channel. The panic makes this bug loud and immediate rather than silently wrong.\n\nThe same logic applies to sending to a closed channel: the sender thinks the channel is still active and is delivering data. If close silently discarded it, you'd lose data with no indication. The panic enforces the invariant that data sent to a channel will eventually be received.\n\n---\n\n**Q4: How would you implement a timeout for a channel operation?**\n\n\u003e **What they're looking for**: `time.After` in a `select`, and knowledge of the goroutine leak issue.\n\n**Answer**:\n\n```go\nselect {\ncase v := \u003c-ch:\n    // use v\ncase \u003c-time.After(5 * time.Second):\n    // timeout\n}\n```\n\nThen mention the nuance: **if this is in a loop**, using `time.After` creates a new timer every iteration. Before Go 1.23, those timers leaked until they fired. The production-safe approach reuses `time.NewTimer` and calls `Reset()`. In Go 1.23+, the GC can collect unreferenced `time.After` timers.\n\nAlso mention: if you're doing this in a one-shot context (not a loop), always buffer the result channel with capacity 1 to prevent goroutine leaks when the timeout fires before the operation completes.\n\n---\n\n**Q5: What is a goroutine leak and how do you detect it?**\n\n\u003e **What they're looking for**: Real production knowledge, not just theoretical.\n\n**Answer**: A goroutine leak occurs when a goroutine starts but never terminates because it's permanently blocked on a channel operation (send or receive). Unlike memory, the Go runtime never GCs goroutines.\n\nCommon causes: sending to an unbuffered channel with no receiver, ranging over a channel that's never closed, or selecting on channels where none will ever become ready.\n\nDetection tools: `runtime.NumGoroutine()` tracked over time, `net/http/pprof` at `/debug/pprof/goroutine`, or in tests: `uber-go/goleak` with `defer goleak.VerifyNone(t)`.\n\nUber built a production-level tool called LeakProf that discovered leaks even in live traffic by sampling goroutine stack traces and flagging goroutines blocked at the same location across samples — a sign they're stuck.\n\n---\n\n**Q6: Implement a concurrent merge of N channels.**\n\n\u003e **Classic coding challenge. Shows you understand WaitGroup + goroutines + channel closure.**\n\n```go\nfunc merge(channels ...\u003c-chan int) \u003c-chan int {\n    var wg sync.WaitGroup\n    out := make(chan int, 10)\n\n    forward := func(ch \u003c-chan int) {\n        defer wg.Done()\n        for v := range ch {\n            out \u003c- v\n        }\n    }\n\n    wg.Add(len(channels))\n    for _, ch := range channels {\n        go forward(ch)\n    }\n\n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n\n    return out\n}\n```\n\n**Follow-up they'll ask**: \"What if you also need cancellation?\" — Add a `done \u003c-chan struct{}` parameter and use it in a select inside `forward`.\n\n---\n\n**Q7: What is the select statement's behavior when multiple cases are ready?**\n\n\u003e **What they're looking for**: The randomness guarantee from the Go spec.\n\n**Answer**: The Go specification states that if multiple `select` cases can proceed simultaneously, **one is chosen at random (uniform pseudo-random)**. This is NOT like a `switch` statement where the first matching case wins. This design prevents starvation — no single case can monopolize the select. However, it means you cannot rely on case ordering for priority. If you need true priority (e.g., always check `done` before processing data), use a double-select pattern: a non-blocking select for the priority case first, then a regular select.\n\n---\n\n**Q8: When would you choose a mutex over a channel?**\n\n\u003e **What they're looking for**: Real judgment about the right tool, not dogmatism.**\n\n**Answer**: Use a mutex when you're protecting access to shared STATE, especially when multiple goroutines need to read AND write a shared variable or data structure. Classic examples: protecting a map, a counter, or any struct with multiple fields that need consistent reads.\n\nUse channels when you're COMMUNICATING data between goroutines — transferring ownership of data, signaling events, or distributing work.\n\nPerformance matters too: an uncontended mutex is ~15-20ns, while a channel send+receive is ~200-300ns. For high-frequency operations on simple shared state, a mutex is 10-15x faster.\n\nThe official guidance (from `go.dev/wiki/MutexOrChannel`) and Rob Pike's 2012 talk: channels are for \"communicating, not just sharing.\" And from Pike: \"Don't overdo it. But sometimes all you need is a reference counter.\"\n\nA concrete signal that you should use a mutex: if your channel usage looks like `lock-operate-unlock` but with channels instead of a mutex, use an actual mutex.\n\n---\n\n### The Axiom Table (Memorize This)\n\n```\nOperation Nil Channel Open Channel Closed Channel\n─────────────────────────────────────────────────────────────\nSend blocks forever ok / blocks PANIC\nReceive blocks forever value / blocks zero value (ok=false)\nClose PANIC closes it PANIC\n─────────────────────────────────────────────────────────────\nIn select: never chosen if ready always chosen (drains buffer then zeros)\n```\n\nEvery Go channel interview question traces back to this table. Know it cold.\n\n---\n\n## Final Practice Quiz: What's the Output?\n\n**Quiz 8.1:**\n```go\nch := make(chan int, 2)\nch \u003c- 1\nch \u003c- 2\nclose(ch)\nfmt.Println(\u003c-ch)\nfmt.Println(\u003c-ch)\nfmt.Println(\u003c-ch)\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nOutput:\n```\n1\n2\n0\n```\n\nClosed buffered channel drains buffered values first (1, 2), then returns zero value (0) indefinitely. No panic. No block.\n\n\u003c/details\u003e\n\n**Quiz 8.2:**\n```go\nvar ch chan int\n\nselect {\ncase v := \u003c-ch: // ch is nil\n    fmt.Println(\"received:\", v)\ndefault:\n    fmt.Println(\"no value\")\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nOutput: `no value`\n\nA nil channel case in select is never selected. `default` fires immediately since the nil case would block forever.\n\n\u003c/details\u003e\n\n**Quiz 8.3:**\n```go\nch := make(chan int, 1)\nclose(ch)\nch \u003c- 1\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n`panic: send on closed channel`\n\nYou can never send to a closed channel. Even if it has buffer space.\n\n\u003c/details\u003e\n\n**Quiz 8.4:**\n```go\ndone := make(chan struct{})\nch := make(chan int)\n\ngo func() {\n    close(done)\n}()\n\nselect {\ncase v := \u003c-ch:\n    fmt.Println(\"received:\", v)\ncase \u003c-done:\n    fmt.Println(\"done!\")\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nOutput: `done!`\n\n`ch` has no sender, so it blocks. `done` gets closed by the goroutine, making `\u003c-done` ready immediately. Select picks `done`.\n\nBut: if both cases were ready simultaneously, it would be random! If you ran this 1 million times and somehow both became ready at exactly the same instant, you'd get both outputs with roughly 50% probability each.\n\n\u003c/details\u003e\n\n**Quiz 8.5:**\n```go\nfunc f() \u003c-chan int {\n    ch := make(chan int)\n    go func() {\n        ch \u003c- 42\n    }()\n    return ch\n}\n\nfunc main() {\n    v := \u003c-f()\n    fmt.Println(v)\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nOutput: `42`\n\nNo goroutine leak! The goroutine sends 42 and exits. The receiver in `main` receives it. Both parties meet. Clean.\n\nThis is the generator pattern: `f()` spawns a goroutine, passes data via channel, and returns a receive-only view of the channel.\n\n\u003c/details\u003e\n\n---\n\n## Summary: Channels in One Mental Model\n\nThink of a Go channel as a **guarded handoff point** between goroutines:\n\n- **Unbuffered**: Two people shaking hands — both must show up at the same time.\n- **Buffered**: A locker at a train station — sender leaves a package, receiver picks it up later. But there are only N lockers.\n- **Closed**: \"This counter is closed.\" — receivers still get whatever was in the buffer, then see a sign saying \"closed.\"\n- **Nil**: \"This counter doesn't exist.\" — everyone waits and waits...\n- **Done/quit channel**: The fire alarm — when you close it, everyone in the building hears it simultaneously and exits.\n- **Worker pool**: N cashiers, one queue — close the queue when no more customers.\n- **Fan-out**: One manager, multiple workers — the queue routes work to whoever is free.\n- **Fan-in**: Multiple workers, one output tray — merge all results into one place.\n- **Pipeline**: Assembly line — each station takes parts in, transforms them, passes them on.\n\n**Dave Cheney's golden rule**: \"Never start a goroutine without knowing how it will stop.\"\n\n**Rob Pike's reminder**: \"Channels are a big idea. But sometimes all you need is a reference counter.\"\n\n---\n\n*Next up: Part 5 — Mutexes: When You Need to Protect State, Not Communicate*\n";
var __STRUCTURE__ = {"title":"Go Concurrency Mastery","overview":[{"id":"COMPLETE_COURSE_CURRICULUM","title":"Go Concurrency Mastery: Complete Course Curriculum","filename":"COMPLETE_COURSE_CURRICULUM.md"}],"chapters":[{"id":"chapter-01","title":"Chapter 01: The Race Condition Crisis","dir":"chapter-01","parts":[{"id":"PART0_INTRODUCTION","title":"Chapter 1, Part 0: Introduction and Setup","filename":"PART0_INTRODUCTION.md"},{"id":"PART1_SEQUENTIAL_BASELINE","title":"Chapter 1, Part 1: The Sequential Baseline","filename":"PART1_SEQUENTIAL_BASELINE.md"},{"id":"PART3_RACE_CONDITIONS_DEEP_DIVE","title":"Chapter 1, Part 3: What IS a Race Condition? - Deep Dive","filename":"PART3_RACE_CONDITIONS_DEEP_DIVE.md"},{"id":"PART4_SOLUTION_CHANNELS","title":"Chapter 1, Part 4: Solution #1 - Channels","filename":"PART4_SOLUTION_CHANNELS.md"},{"id":"PART4-1CHANNELS_PRACTICE","title":"Channels Practice","filename":"PART4-1CHANNELS_PRACTICE.md"}]}]};
</script>
<script src="../app.js"></script>
</body>
</html>