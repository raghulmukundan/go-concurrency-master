<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Chapter 1, Part 4: Solution #1 - Channels - Go Concurrency Course</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:opsz,wght@8..60,400;8..60,500;8..60,600;8..60,700&family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" class="hljs-theme" data-theme="light">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark.min.css" class="hljs-theme" data-theme="dark" disabled>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/go.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/languages/bash.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/marked/12.0.0/marked.min.js"></script>
<link rel="stylesheet" href="../style.css">
</head>
<body>

<header class="header">
  <button class="menu-toggle" onclick="toggleMobile()">&#9776;</button>
  <div class="header-brand">
    <div class="header-logo">Go</div>
    <span class="header-title">Go Concurrency</span>
    <div class="header-sep"></div>
    <span class="header-part-title" id="headerPart">Select a section to begin</span>
  </div>
  <div class="section-nav" id="sectionNav" style="display:none">
    <button class="nav-btn" id="prevSection" onclick="prevSlide()">&#8249;</button>
    <span class="section-indicator" id="sectionIndicator">1 / 1</span>
    <button class="nav-btn" id="nextSection" onclick="nextSlide()">&#8250;</button>
  </div>
  <div class="header-right">
    <button class="nav-btn font-btn" onclick="changeFontSize(-1)" title="Decrease font size">A&#8722;</button>
    <button class="nav-btn font-btn" onclick="changeFontSize(1)" title="Increase font size">A+</button>
    <button class="nav-btn" id="darkToggle" onclick="toggleDark()" title="Toggle dark mode"><span id="darkIcon">&#9789;</span></button>
    <button class="nav-btn" title="Toggle sidebar" onclick="toggleSidebar()" style="font-size:14px">&#9776;</button>
  </div>
</header>

<div class="layout">
  <nav class="sidebar" id="sidebar">
    <div id="sidebarContent">
      <div class="loading"><div class="spinner"></div><div class="loading-text">Loading...</div></div>
    </div>
  </nav>

  <div class="main" id="mainArea">
    <div class="sections-container" id="sectionsContainer">
      <div class="welcome" id="welcomeScreen">
        <div class="welcome-icon">Go</div>
        <h1>Go Concurrency Mastery</h1>
        <p>A hands-on course to master concurrent programming in Go. Navigate sections horizontally with arrow keys or buttons.</p>
        <button class="welcome-btn" onclick="loadFirst()">Start Reading</button>
        <a class="welcome-btn resume-btn" id="resumeBtn" style="display:none" href="#">Continue Reading</a>
        <div class="welcome-hint">Use &#8592; &#8594; arrow keys to navigate sections</div>
      </div>
    </div>
    <div class="section-dots" id="sectionDots"></div>
  </div>
</div>

<script>
var __BASE_PATH__ = "..";
var __PAGE_ID__ = "chapter-01/PART4_SOLUTION_CHANNELS.md";
var __PAGE_CONTENT__ = "# Chapter 1, Part 4: Solution #1 - Channels\n\n**Time to complete**: 120 minutes\n**What you'll learn**: How to fix race conditions using Go channels - from zero to mastery\n\n---\n\n## Section 4.1: What IS a Channel? (Conceptual)\n\n### Where We Are\n\n**Part 2**: You wrote concurrent code with goroutines. It broke spectacularly.\n**Part 3**: You learned WHY it broke (races, memory visibility, read-modify-write).\n**Part 4 (NOW)**: Time to FIX it!\n\n### The Problem We're Solving\n\nRemember our broken counter from Part 2?\n\n```go\nvar counter int\n\nfor i := 0; i \u003c 1000; i++ {\n    go func() {\n        counter++ // RACE! Multiple goroutines, no sync\n    }()\n}\n\n// Result: counter = 847, 923, 891... never 1000!\n```\n\n**The three conditions for a race** (from Part 3):\n1. Multiple goroutines access `counter`\n2. At least one writes (all of them write!)\n3. No synchronization\n\n**We need to break condition #3**: Add synchronization!\n\n**Today's solution: Channels**\n\n### What IS a Channel?\n\n**Don't think of channels as data structures.** Think of them as **signaling mechanisms**.\n\nA channel allows one goroutine to **signal** another goroutine about an event, optionally passing data with that signal.\n\n**The Magic Pipe Analogy**:\n\nImagine John wants to send a gift to Emma through a magic pipe:\n```\nJohn Emma\n  ---\u003e [====PIPE====] ---\u003e\n```\n\n**The magic rule**: Both must be at the pipe at the same time for the transfer to work!\n\n- John puts the gift in one end\n- Emma takes it out the other end\n- If John arrives first → he waits for Emma\n- If Emma arrives first → she waits for John\n- When both are ready → instant transfer!\n\n**This is an unbuffered channel!**\n\n### Why Go Has Channels\n\nMost languages give you shared memory + locks:\n```\ngoroutine A ----\\\n                 ---\u003e [Shared Counter] \u003c--- Need locks!\ngoroutine B ----/\n```\n\nGo gives you channels:\n```\ngoroutine A ---\u003e [CHANNEL] ---\u003e goroutine B (owns counter)\n```\n\n**The Go Philosophy**:\n\u003e \"Don't communicate by sharing memory; share memory by communicating.\"\n\u003e — Rob Pike\n\n**Translation**: Instead of multiple goroutines touching the same data (sharing memory), have ONE goroutine own the data and others send messages to it (communicating).\n\n### Your First Mental Model\n\nThink of a channel as:\n- A **pipe** where goroutines can send/receive data\n- A **synchronization point** where goroutines coordinate\n- A **safe way** to transfer ownership of data\n\n**The key insight**: Only one goroutine \"owns\" the data at any time. Channels transfer ownership safely.\n\n### Quiz 4.1: Understanding the Concept\n\n**Question 1**: What's the main purpose of channels?\n\nA) Store lots of data like an array\nB) Signal and coordinate between goroutines\nC) Make code run faster\nD) Replace all variables\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**B) Signal and coordinate between goroutines**\n\nChannels are primarily about **synchronization and communication**, not storage or speed. They help goroutines work together safely.\n\n\u003c/details\u003e\n\n**Question 2**: In the \"magic pipe\" analogy, what happens if John arrives before Emma?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**John waits!** He can't complete the send until Emma is ready to receive. Both must be present for the transfer. This is called \"blocking\" - we'll learn more soon!\n\n\u003c/details\u003e\n\n**Question 3**: What's wrong with this approach?\n\n```go\n// Multiple goroutines all touching counter\nvar counter int\ngo func() { counter++ }()\ngo func() { counter++ }()\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Race condition!** Multiple goroutines share memory (counter) without synchronization. This is the problem channels solve - instead of sharing memory, we'll communicate through channels.\n\n\u003c/details\u003e\n\n---\n\n## Section 4.2: Your First Channel\n\n### Creating a Channel\n\n```go\nch := make(chan int) // Channel that carries integers\n```\n\n**Syntax breakdown**:\n- `chan` = keyword for channel\n- `int` = type of data the channel carries\n- `make()` = allocates the channel (like maps/slices)\n\n**Examples**:\n```go\nmessages := make(chan string) // Carries strings\nnumbers := make(chan int) // Carries integers\nresults := make(chan bool) // Carries booleans\ndata := make(chan []byte) // Carries byte slices\n\n// You can even send structs!\ntype Result struct {\n    Value int\n    Error error\n}\nresultChan := make(chan Result)\n```\n\n### The Two Operations\n\n**1. Send** (put data INTO the channel):\n```go\nch \u003c- 42 // Send the value 42 into ch\n```\n\nThe arrow `\u003c-` points FROM the value TO the channel.\n\n**2. Receive** (get data OUT OF the channel):\n```go\nvalue := \u003c-ch // Receive from ch, store in value\n```\n\nThe arrow `\u003c-` points FROM the channel TO the variable.\n\n**Mnemonic**: The arrow shows data flow!\n- `ch \u003c- value` → value flows INTO channel\n- `value := \u003c-ch` → value flows OUT OF channel\n\n### The Simplest Possible Example\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    messages := make(chan string)\n\n    // Send in a goroutine\n    go func() {\n        messages \u003c- \"ping\"\n    }()\n\n    // Receive in main\n    msg := \u003c-messages\n    fmt.Println(msg) // Prints: ping\n}\n```\n\n**What happens?**\n1. Create channel `messages`\n2. Start goroutine that sends \"ping\"\n3. Main goroutine receives (blocks until \"ping\" arrives)\n4. Print \"ping\"\n\n### Why the Goroutine?\n\n**Try this** (remove the `go`):\n\n```go\nfunc main() {\n    messages := make(chan string)\n\n    // NO goroutine - send directly in main\n    messages \u003c- \"ping\" // DEADLOCK!\n\n    msg := \u003c-messages\n    fmt.Println(msg)\n}\n```\n\n**Run it**:\n```\nfatal error: all goroutines are asleep - deadlock!\n```\n\n**Why?**\n\nSending on an unbuffered channel **blocks** until someone receives. But we're trying to send in main, and the receive is also in main (next line). Main can't do both at once!\n\n```\nMain: Tries to send \"ping\"\n  ↓ BLOCKS waiting for receiver\n  ↓ But the receiver is the next line!\n  ↓ Which can never run because we're blocked!\n  ↓ DEADLOCK!\n```\n\n**Solution**: Put the send in a goroutine so main can proceed to the receive.\n\n### Exercise 4.1: Your First Channel\n\nCreate a channel that sends your name from one goroutine to another.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    // TODO: Create a channel for strings\n\n    // TODO: Start a goroutine that sends your name\n\n    // TODO: Receive your name and print it\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    names := make(chan string)\n\n    go func() {\n        names \u003c- \"Alice\" // Send your name\n    }()\n\n    name := \u003c-names\n    fmt.Println(\"Hello,\", name)\n}\n```\n\n\u003c/details\u003e\n\n### A Slightly More Complex Example\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc sendData(ch chan int) {\n    fmt.Println(\"Sending 100\")\n    ch \u003c- 100\n    fmt.Println(\"Sent 100!\")\n}\n\nfunc main() {\n    ch := make(chan int)\n\n    go sendData(ch)\n\n    fmt.Println(\"Waiting to receive...\")\n    value := \u003c-ch\n    fmt.Println(\"Received:\", value)\n}\n```\n\n**Possible output** (order varies!):\n```\nWaiting to receive...\nSending 100\nSent 100!\nReceived: 100\n```\n\nOr:\n```\nSending 100\nWaiting to receive...\nReceived: 100\nSent 100!\n```\n\nOr other combinations!\n\n**What's happening?**\n\n1. Both goroutines approach the channel\n2. One arrives first and **blocks** waiting for the other\n3. When both are ready, the **handshake** happens - data transfers\n4. **Both goroutines unblock** and continue executing\n5. Now it's a race - which goroutine's print statement runs first?\n\n**What IS guaranteed:**\n- The send blocks until a receiver arrives\n- The receive blocks until a sender arrives\n- Both block until the handshake completes\n- Data transfers safely\n\n**What is NOT guaranteed:**\n- Which print statement executes first (before or after the channel operation)\n- Which goroutine continues first after the handshake\n\nThe order depends on **goroutine scheduling**, which is non-deterministic!\n\n---\n\n## Section 4.3: Channels Block!\n\n### The Most Important Thing About Channels\n\n**Unbuffered channels BLOCK!**\n\n**Send blocks** until someone receives.\n**Receive blocks** until someone sends.\n\nThis is **BY DESIGN** - it's how channels provide synchronization!\n\n### Visual Timeline: Send Blocks\n\n```go\nch := make(chan int)\n\ngo func() {\n    fmt.Println(\"About to send\")\n    ch \u003c- 42 // BLOCKS HERE\n    fmt.Println(\"Sent!\")\n}()\n\ntime.Sleep(2 * time.Second) // Goroutine waits here!\nfmt.Println(\"About to receive\")\nvalue := \u003c-ch // Goroutine unblocks!\nfmt.Println(\"Received:\", value)\n```\n\n**Timeline**:\n```\nTime Goroutine Main\n---- --------- ----\nt0 \"About to send\"\nt1 ch \u003c- 42 [BLOCKED]\nt2 (sleeping...)\nt3 (sleeping...)\nt4 \"About to receive\"\nt5 [UNBLOCKS] value := \u003c-ch\nt6 \"Sent!\" \"Received: 42\"\n```\n\n### Visual Timeline: Receive Blocks\n\n```go\nch := make(chan int)\n\ngo func() {\n    time.Sleep(2 * time.Second)\n    fmt.Println(\"About to send\")\n    ch \u003c- 42\n}()\n\nfmt.Println(\"About to receive\")\nvalue := \u003c-ch // BLOCKS HERE\nfmt.Println(\"Received:\", value)\n```\n\n**Timeline**:\n```\nTime Main Goroutine\n---- ---- ---------\nt0 \"About to receive\"\nt1 value := \u003c-ch [BLOCKED]\nt2 (sleeping...)\nt3 (sleeping...)\nt4 \"About to send\"\nt5 [UNBLOCKS] ch \u003c- 42\nt6 \"Received: 42\"\n```\n\n### The Handshake Concept\n\nUnbuffered channels enforce a **rendezvous** - both parties must meet:\n\n```\nSender: -----\u003e [ ] \u003c----- Receiver\n                   CHANNEL\n            Both must be present!\n```\n\n**It's like a handshake**:\n- You extend your hand (send)\n- You wait for the other person (block)\n- They shake your hand (receive)\n- Handshake complete! (both continue)\n\n### Exercise 4.2: Observe Blocking\n\n**Task**: Add print statements to see blocking in action.\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    ch := make(chan string)\n\n    go func() {\n        fmt.Println(\"[Goroutine] Before send\")\n        ch \u003c- \"Hello\"\n        fmt.Println(\"[Goroutine] After send\")\n    }()\n\n    time.Sleep(2 * time.Second)\n\n    fmt.Println(\"[Main] Before receive\")\n    msg := \u003c-ch\n    fmt.Println(\"[Main] After receive:\", msg)\n}\n```\n\n**Run it and observe**:\n- Which prints first?\n- How long does the goroutine wait?\n- When does \"After send\" print?\n\n\u003cdetails\u003e\n\u003csummary\u003eExplanation\u003c/summary\u003e\n\n**Output**:\n```\n[Goroutine] Before send\n(2 second pause - goroutine is BLOCKED at ch \u003c- \"Hello\")\n[Main] Before receive\n[Main] After receive: Hello\n[Goroutine] After send\n```\n\nThe goroutine blocks for 2 seconds waiting for main to receive!\n\n\u003c/details\u003e\n\n### Quiz 4.3: Understanding Blocking\n\n**Question 1**: What happens here?\n\n```go\nch := make(chan int)\nch \u003c- 42\nfmt.Println(\"Done\")\n```\n\nA) Prints \"Done\"\nB) Deadlock\nC) Panic\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**B) Deadlock**\n\nThe send `ch \u003c- 42` blocks forever because:\n- No goroutine is receiving\n- Main is the only goroutine\n- Main can't continue to receive because it's blocked on send\n- Deadlock!\n\n\u003c/details\u003e\n\n**Question 2**: Why does this work?\n\n```go\nch := make(chan int)\ngo func() { ch \u003c- 42 }()\nvalue := \u003c-ch\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Because the send is in a separate goroutine!**\n\n- Goroutine executes `ch \u003c- 42` (blocks waiting for receiver)\n- Main continues to `value := \u003c-ch` (receives from goroutine)\n- Both unblock simultaneously - handshake complete!\n\n\u003c/details\u003e\n\n**Question 3**: Can a receive happen before the send?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Yes!** Whichever arrives first waits for the other.\n\n```go\ngo func() {\n    time.Sleep(2 * time.Second)\n    ch \u003c- 42 // Sends after 2 seconds\n}()\n\nvalue := \u003c-ch // Main receives immediately, BLOCKS for 2 seconds\n```\n\nReceive can arrive first and block waiting for send!\n\n\u003c/details\u003e\n\n---\n\n## Section 4.4: Buffered Channels\n\n### The Limitation of Unbuffered\n\nUnbuffered channels require **perfect timing** - sender and receiver must meet.\n\nSometimes you want:\n- Send without waiting (if possible)\n- Decouple sender and receiver\n- Handle bursts of data\n\n**Solution: Buffered Channels!**\n\n### Creating Buffered Channels\n\n```go\nch := make(chan int, 3) // Buffer capacity of 3\n```\n\nThe second argument is the **buffer size**.\n\n```\nUnbuffered: [ ] ← No storage\nBuffered: [_|_|_] ← Can hold 3 items\n```\n\n### How Buffering Changes Blocking\n\n**Send blocks** only when buffer is **full**.\n**Receive blocks** only when buffer is **empty**.\n\n### Example: Buffered Channel\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch := make(chan int, 2) // Buffer size 2\n\n    // Send WITHOUT goroutines!\n    ch \u003c- 1 // Doesn't block (buffer has space)\n    ch \u003c- 2 // Doesn't block (buffer has space)\n    // ch \u003c- 3 // Would BLOCK (buffer full)\n\n    fmt.Println(\u003c-ch) // Prints: 1\n    fmt.Println(\u003c-ch) // Prints: 2\n}\n```\n\n**This works!** No goroutines needed because sends don't block while buffer has space.\n\n### The Conveyor Belt Analogy\n\nThink of a buffered channel as a **conveyor belt**:\n\n```\nProducer → [item|item|____] → Consumer\n           ↑ Buffer ↑\n        3 slots total\n```\n\n- Producer can place items on the belt (send)\n- Consumer takes items off the belt (receive)\n- Belt holds up to 3 items\n- If belt is full → producer waits\n- If belt is empty → consumer waits\n\n### Visual: Buffer States\n\n```\nEmpty: [_|_|_] ← Send: OK, Receive: BLOCKS\nPartial: [X|_|_] ← Send: OK, Receive: OK\nPartial: [X|X|_] ← Send: OK, Receive: OK\nFull: [X|X|X] ← Send: BLOCKS, Receive: OK\n```\n\n### Exercise 4.3: Experiment with Buffer Size\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch := make(chan int, 2) // Try changing this to 1, 3, etc.\n\n    ch \u003c- 1\n    ch \u003c- 2\n    // ch \u003c- 3 // Uncomment and see what happens!\n\n    fmt.Println(\u003c-ch)\n    fmt.Println(\u003c-ch)\n    // fmt.Println(\u003c-ch) // Uncomment and see what happens!\n}\n```\n\n**Tasks**:\n1. Run as-is (works!)\n2. Uncomment `ch \u003c- 3` (deadlock! buffer full)\n3. Change buffer to 3 (works again!)\n4. Remove all sends, uncomment receive (deadlock! buffer empty)\n\n\u003cdetails\u003e\n\u003csummary\u003eExplanation\u003c/summary\u003e\n\n**With `ch \u003c- 3` uncommented and buffer=2**:\n```\nch \u003c- 1 // Buffer: [1|_]\nch \u003c- 2 // Buffer: [1|2]\nch \u003c- 3 // Buffer full, BLOCKS forever - deadlock!\n```\n\n**With buffer=3**:\n```\nch \u003c- 1 // Buffer: [1|_|_]\nch \u003c- 2 // Buffer: [1|2|_]\nch \u003c- 3 // Buffer: [1|2|3] ← Fits!\n```\n\n\u003c/details\u003e\n\n### When to Use Buffered Channels\n\n**Use buffered when**:\n- You know the maximum burst size\n- Sender and receiver run at different speeds\n- Want to decouple goroutines\n- Need to handle temporary traffic spikes\n\n**Use unbuffered when**:\n- Need guaranteed synchronization (handshake)\n- Want to know send succeeded (receiver processed it)\n- Simpler reasoning (no state to track)\n\n**Rule of thumb**: Start unbuffered. Add buffer only if you have a specific reason!\n\n### Quiz 4.4: Buffered Channels\n\n**Question 1**: What's the buffer capacity here?\n\n```go\nch := make(chan int, 10)\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**10**. The channel can hold up to 10 integers before blocking senders.\n\n\u003c/details\u003e\n\n**Question 2**: Does this work?\n\n```go\nch := make(chan int, 1)\nch \u003c- 42\nch \u003c- 43\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**No! Deadlock at second send.**\n\n```\nch \u003c- 42 // Buffer: [42] (space used: 1/1)\nch \u003c- 43 // Buffer full, BLOCKS, no receiver - deadlock!\n```\n\n\u003c/details\u003e\n\n**Question 3**: How many values can you send without blocking?\n\n```go\nch := make(chan int, 5)\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**5 values**. After sending 5, the buffer is full and the 6th send would block.\n\n\u003c/details\u003e\n\n---\n\n## Section 4.5: Buffered vs Unbuffered\n\n### Side-by-Side Comparison\n\n| Aspect | Unbuffered | Buffered |\n|--------|------------|----------|\n| **Creation** | `make(chan T)` | `make(chan T, n)` |\n| **Send blocks** | Until receive happens | Until buffer is full |\n| **Receive blocks** | Until send happens | Until buffer has data |\n| **Synchronization** | Strong (rendezvous) | Weak (async within capacity) |\n| **Use case** | Coordination, handshakes | Throughput, decoupling |\n| **Memory** | Minimal | Allocates buffer upfront |\n\n### Example: Same Task, Different Channels\n\n**Unbuffered (requires goroutine)**:\n```go\nch := make(chan int) // Unbuffered\n\ngo func() {\n    ch \u003c- 1 // Must be in goroutine\n    ch \u003c- 2 // or it deadlocks!\n}()\n\nfmt.Println(\u003c-ch) // 1\nfmt.Println(\u003c-ch) // 2\n```\n\n**Buffered (no goroutine needed)**:\n```go\nch := make(chan int, 2) // Buffered\n\nch \u003c- 1 // Doesn't block\nch \u003c- 2 // Doesn't block\n\nfmt.Println(\u003c-ch) // 1\nfmt.Println(\u003c-ch) // 2\n```\n\n### Performance Considerations\n\n**Unbuffered**:\n- More blocking → more goroutine context switches\n- Stronger synchronization guarantees\n- Simpler to reason about\n\n**Buffered**:\n- Less blocking (within capacity)\n- Higher throughput potential\n- Can hide timing bugs\n\n**Benchmark numbers** (approximate):\n- Unbuffered: ~180-200 ns/op\n- Buffered: ~50-80 ns/op\n\nBut remember: **Correctness \u003e Performance!** Start simple, optimize later.\n\n### The \"Less is More\" Principle\n\nBill Kennedy (Ardan Labs): **\"Less is more with buffers.\"**\n\n**Why?**\n- Large buffers can hide bugs\n- Unbuffered forces you to think about synchronization\n- Buffered should have a **justification**\n\n**Good reasons for buffer**:\n- \"I need to handle bursts of up to 10 requests\"\n- \"I want to decouple producer from consumer\"\n- \"I'm implementing a worker pool with 5 workers\"\n\n**Bad reasons**:\n- \"Bigger is better, right?\"\n- \"Maybe it'll be faster?\"\n- \"I don't know, let's try 1000\"\n\n### Exercise 4.4: Choose the Right Type\n\nFor each scenario, choose unbuffered or buffered (with size):\n\n**Scenario 1**: Passing a computed result from worker to main.\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Unbuffered** or **Buffered size 1**\n\nYou want to ensure the result is delivered. Unbuffered guarantees the handshake. Buffer of 1 allows send to complete without blocking, but no larger buffer needed.\n\n\u003c/details\u003e\n\n**Scenario 2**: Distributing 100 jobs to 10 workers.\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Buffered size 10-100**\n\nWorker pool pattern. Buffer size depends on:\n- Size 10: One job per worker (balanced load)\n- Size 100: All jobs queued upfront (simpler sending logic)\n\nBoth valid! 10 is more conservative.\n\n\u003c/details\u003e\n\n**Scenario 3**: Signaling \"done\" from goroutine to main.\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Unbuffered**\n\nSimple signal, no data needed. Unbuffered ensures main doesn't proceed until goroutine completes the send.\n\n\u003c/details\u003e\n\n---\n\n## Section 4.6: Channel-Based Counter Solution\n\n### Revisiting the Broken Counter\n\nFrom Parts 1-2, our broken code:\n\n```go\nvar counter int\n\nfor i := 0; i \u003c 1000; i++ {\n    go func() {\n        counter++ // RACE CONDITION!\n    }()\n}\n\n// Result: 847, 923, 891... never 1000\n```\n\n**The problem**: 1000 goroutines all touching `counter` simultaneously.\n\n### The Channel Solution: Single Owner\n\n**Key insight**: What if ONLY ONE goroutine owns the counter?\n\nAll other goroutines send requests: \"Please increment!\" or \"What's the count?\"\n\n```\nGoroutine 1 --\\\nGoroutine 2 ---\u003e [CHANNEL] ---\u003e Counter Goroutine (owns counter)\nGoroutine 3 --/ |\n... Only this goroutine touches counter!\n```\n\n**This is the \"Single Writer\" or \"Monitor\" pattern.**\n\n### The Complete Solution\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\n// Commands sent to the counter\ntype Command struct {\n    action string // \"inc\" or \"get\"\n    reply chan int // Send result back here\n}\n\nfunc counterService(commands \u003c-chan Command) {\n    count := 0 // Only THIS goroutine touches count!\n\n    for cmd := range commands {\n        switch cmd.action {\n        case \"inc\":\n            count++\n            cmd.reply \u003c- count\n        case \"get\":\n            cmd.reply \u003c- count\n        }\n    }\n}\n\nfunc main() {\n    commands := make(chan Command)\n\n    // Start the counter service\n    go counterService(commands)\n\n    // Start 1000 goroutines that increment\n    var wg sync.WaitGroup\n    for i := 0; i \u003c 1000; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n\n            reply := make(chan int)\n            commands \u003c- Command{action: \"inc\", reply: reply}\n            \u003c-reply // Wait for confirmation\n        }()\n    }\n\n    wg.Wait()\n\n    // Get final count\n    reply := make(chan int)\n    commands \u003c- Command{action: \"get\", reply: reply}\n    finalCount := \u003c-reply\n\n    fmt.Println(\"Final count:\", finalCount) // Always 1000!\n}\n```\n\n**Run it several times**:\n```\nFinal count: 1000\nFinal count: 1000\nFinal count: 1000\n```\n\n**Always correct!** No race detector warnings!\n\n### Why This Works: Serialization\n\nAll increment requests go through ONE channel:\n\n```\nTime Goroutine 1 Goroutine 2 Counter Service\n---- ----------- ----------- ---------------\nt1 Send \"inc\"\nt2 Receive \"inc\", count=1\nt3 Send \"inc\"\nt4 Receive \"inc\", count=2\nt5 Send \"inc\"\nt6 Receive \"inc\", count=3\n```\n\n**Even though sends happen concurrently**, the counter service processes them **one at a time** (serialized).\n\n### Breaking Down the Code\n\n**1. Command struct**:\n```go\ntype Command struct {\n    action string // What to do: \"inc\" or \"get\"\n    reply chan int // How to send result back\n}\n```\n\nEach request needs a **reply channel** so the goroutine can get a response.\n\n**2. Counter service**:\n```go\nfunc counterService(commands \u003c-chan Command) {\n    count := 0 // Private! Only this goroutine sees it!\n\n    for cmd := range commands {\n        // Process ONE command at a time\n        switch cmd.action {\n        case \"inc\":\n            count++\n            cmd.reply \u003c- count // Send result back\n        case \"get\":\n            cmd.reply \u003c- count // Send current value\n        }\n    }\n}\n```\n\n**3. Sending a command**:\n```go\nreply := make(chan int) // Create reply channel\ncommands \u003c- Command{\"inc\", reply} // Send command\n\u003c-reply // Wait for result\n```\n\n### Exercise 4.5: Add a Decrement\n\nModify the code to support \"dec\" (decrement) commands.\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\nfunc counterService(commands \u003c-chan Command) {\n    count := 0\n\n    for cmd := range commands {\n        switch cmd.action {\n        case \"inc\":\n            count++\n            cmd.reply \u003c- count\n        case \"dec\": // NEW!\n            count--\n            cmd.reply \u003c- count\n        case \"get\":\n            cmd.reply \u003c- count\n        }\n    }\n}\n\n// Usage:\nreply := make(chan int)\ncommands \u003c- Command{action: \"dec\", reply: reply}\nnewCount := \u003c-reply\n```\n\n\u003c/details\u003e\n\n### Simpler Version (No Reply Needed)\n\nIf you don't care about the result:\n\n```go\nfunc counterService(inc \u003c-chan bool, get \u003c-chan chan int) {\n    count := 0\n    for {\n        select {\n        case \u003c-inc:\n            count++\n        case reply := \u003c-get:\n            reply \u003c- count\n        }\n    }\n}\n\nfunc main() {\n    inc := make(chan bool)\n    get := make(chan chan int)\n\n    go counterService(inc, get)\n\n    // Increment 1000 times\n    var wg sync.WaitGroup\n    for i := 0; i \u003c 1000; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            inc \u003c- true // Just signal increment\n        }()\n    }\n\n    wg.Wait()\n\n    // Get count\n    reply := make(chan int)\n    get \u003c- reply\n    fmt.Println(\"Count:\", \u003c-reply) // 1000!\n}\n```\n\n---\n\n## Section 4.7: How Does This Prevent the Race?\n\n### The Three Conditions (Revisited)\n\nRemember from Part 3, a race needs:\n1. Multiple goroutines access same memory\n2. At least one writes\n3. No synchronization\n\n**With channels, we break condition #1!**\n\n### One Owner Rule\n\n```go\n// OLD (RACE):\nvar counter int // Multiple goroutines access this\ngo func() { counter++ }()\ngo func() { counter++ }()\ngo func() { counter++ }()\n\n// NEW (SAFE):\nfunc counterService() {\n    count := 0 // ONLY this goroutine accesses this!\n    // ...\n}\n```\n\n**The `count` variable is local** to `counterService`. It's on that goroutine's stack. No other goroutine can touch it!\n\n### Channels Provide Synchronization\n\nChannels satisfy condition #3 (synchronization) through:\n\n**1. Happens-Before Guarantee**:\n- A send *happens-before* the corresponding receive completes\n- This creates ordering: all increments happen in a defined sequence\n\n**2. Memory Visibility**:\n- Channel operations flush CPU caches\n- The receiver sees memory as the sender left it\n- No stale reads!\n\n### Why No Mutex Needed\n\nYou might think: \"But the counter service accesses `count`!\"\n\n**It's safe because**:\n- Only ONE goroutine (the service) accesses `count`\n- No concurrent access = no race!\n- Single-threaded within the service = serial execution\n\n### The Ownership Transfer Model\n\n```\nRequest: [Goroutine A] ----data----\u003e [Channel] ----data----\u003e [Goroutine B]\n            \"I give up Transfers \"I now own\n            ownership\" ownership the data\"\n```\n\nOnce A sends data into a channel, A shouldn't touch it anymore. B receives it and takes ownership.\n\n**This prevents races** because data is never accessed concurrently - only one goroutine owns it at a time.\n\n### Quiz 4.7: Understanding How It Works\n\n**Question 1**: Why is `count` safe in the counter service?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nBecause **only one goroutine** (the counter service) accesses it. There's no concurrent access, so no race condition. The variable is private to that single goroutine.\n\n\u003c/details\u003e\n\n**Question 2**: What would happen if we had TWO counter services reading the same channel?\n\n```go\ngo counterService(commands)\ngo counterService(commands) // Two services!\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**This would be wrong!** Each would have its own `count` variable. Commands would be distributed randomly between them, so neither would have the complete count. Each service has its own independent `count` variable, so neither will have the complete count. You'll get incorrect results even though there's no race condition.\n\n**Lesson**: One channel, one receiver (for the single-writer pattern).\n\n\u003c/details\u003e\n\n**Question 3**: How does the channel enforce \"one at a time\" processing?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nThe `for cmd := range commands` loop receives ONE message, processes it completely, then receives the next. It's sequential - the goroutine can't process two commands simultaneously.\n\nEven if 1000 goroutines send concurrently, the channel queues them and delivers one at a time to the receiver.\n\n\u003c/details\u003e\n\n---\n\n## Section 4.8: Closing Channels\n\n### What Is Closing?\n\n`close(ch)` signals: **\"No more values will be sent on this channel.\"**\n\n```go\nch := make(chan int)\nclose(ch) // Signal: I'm done sending\n```\n\n### Why Close?\n\n**Main reason**: To tell receivers \"no more data is coming.\"\n\nThis is especially important with `range`:\n\n```go\nch := make(chan int)\n\ngo func() {\n    for i := 0; i \u003c 5; i++ {\n        ch \u003c- i\n    }\n    close(ch) // Signal: done sending\n}()\n\nfor v := range ch { // Loop exits when closed\n    fmt.Println(v)\n}\n// Prints: 0 1 2 3 4\n```\n\nWithout `close()`, `range` would wait forever for more values!\n\n### The Sender-Closes Rule\n\n**CRITICAL RULE: Only the sender should close a channel.**\n\n**Why?**\n- Only the sender knows when all data is sent\n- Receivers can't safely close (another sender might try to send)\n- **Sending to a closed channel = PANIC!**\n\n```go\n// CORRECT\nfunc producer(ch chan\u003c- int) {\n    defer close(ch) // Producer closes\n    for i := 0; i \u003c 5; i++ {\n        ch \u003c- i\n    }\n}\n\n// WRONG\nfunc consumer(ch \u003c-chan int) {\n    for v := range ch {\n        fmt.Println(v)\n    }\n    close(ch) // WRONG! Consumer shouldn't close!\n}\n```\n\n### Receiving from Closed Channel\n\nWhat happens when you receive from a closed channel?\n\n```go\nch := make(chan int, 2)\nch \u003c- 1\nch \u003c- 2\nclose(ch)\n\nv1 := \u003c-ch // v1 = 1 (buffered value)\nv2 := \u003c-ch // v2 = 2 (buffered value)\nv3 := \u003c-ch // v3 = 0 (zero value, channel closed!)\n```\n\n**After closing**:\n- Buffered values drain first\n- Then: returns zero value immediately\n- **Never blocks** on closed channel\n\n### The Comma-OK Idiom\n\n```go\nvalue, ok := \u003c-ch\n// ok = true: value was sent\n// ok = false: channel closed and empty (zero value returned)\n```\n\n**Example**:\n```go\nch := make(chan int)\nclose(ch)\n\nv, ok := \u003c-ch\nfmt.Println(v, ok) // 0 false\n```\n\nUse this to check if a channel is closed!\n\n### Exercise 4.6: Closing Practice\n\n**Task**: Fix this code by adding proper close().\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc numbers(ch chan int) {\n    for i := 1; i \u003c= 5; i++ {\n        ch \u003c- i\n    }\n    // TODO: Close the channel here\n}\n\nfunc main() {\n    ch := make(chan int)\n    go numbers(ch)\n\n    // TODO: Use range to receive all values\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc numbers(ch chan int) {\n    for i := 1; i \u003c= 5; i++ {\n        ch \u003c- i\n    }\n    close(ch) // Close after sending all values\n}\n\nfunc main() {\n    ch := make(chan int)\n    go numbers(ch)\n\n    for v := range ch { // Range exits when channel closes\n        fmt.Println(v)\n    }\n}\n```\n\n\u003c/details\u003e\n\n### When NOT to Close\n\nYou **don't always need to close** channels!\n\n**Close when**:\n- Using `range` (receiver needs to know when to stop)\n- Signaling completion to multiple receivers\n- Coordinating shutdown\n\n**Don't bother closing when**:\n- Channel goes out of scope (garbage collected like any variable)\n- Only used for 1-2 sends\n- Used as a simple signal\n\n**Channels are not like files** - you don't always need to close them!\n\n### Quiz 4.8: Closing Channels\n\n**Question 1**: What happens here?\n\n```go\nch := make(chan int)\nclose(ch)\nch \u003c- 42\n```\n\nA) Sends 42\nB) Deadlock\nC) Panic\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**C) Panic**\n\nSending to a closed channel causes: `panic: send on closed channel`\n\n\u003c/details\u003e\n\n**Question 2**: What happens here?\n\n```go\nch := make(chan int)\nclose(ch)\nclose(ch)\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Panic: close of closed channel**\n\nClosing a channel twice panics! Use `sync.Once` if you need safe closing from multiple places.\n\n\u003c/details\u003e\n\n**Question 3**: What does this print?\n\n```go\nch := make(chan int)\nclose(ch)\nv := \u003c-ch\nfmt.Println(v)\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Prints: 0**\n\nReceiving from a closed channel returns the zero value immediately. For `int`, that's `0`.\n\nTo detect this, use: `v, ok := \u003c-ch` and check `ok`.\n\n\u003c/details\u003e\n\n---\n\n## Section 4.9: Ranging Over Channels\n\n### The Range Pattern\n\n```go\nfor value := range ch {\n    // Process value\n}\n// Loop exits when channel is closed AND empty\n```\n\nThis is equivalent to:\n\n```go\nfor {\n    value, ok := \u003c-ch\n    if !ok { // Channel closed\n        break\n    }\n    // Process value\n}\n```\n\n**Range is cleaner!**\n\n### Complete Example\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc fibonacci(n int, ch chan int) {\n    x, y := 0, 1\n    for i := 0; i \u003c n; i++ {\n        ch \u003c- x\n        x, y = y, x+y\n    }\n    close(ch) // Must close for range to exit!\n}\n\nfunc main() {\n    ch := make(chan int, 10)\n    go fibonacci(10, ch)\n\n    for v := range ch {\n        fmt.Println(v)\n    }\n}\n```\n\n**Output**:\n```\n0\n1\n1\n2\n3\n5\n8\n13\n21\n34\n```\n\n### Why Range Needs Close\n\nWithout `close()`:\n\n```go\nfunc fibonacci(n int, ch chan int) {\n    x, y := 0, 1\n    for i := 0; i \u003c n; i++ {\n        ch \u003c- x\n        x, y = y, x+y\n    }\n    // Forgot close(ch)!\n}\n\nfunc main() {\n    ch := make(chan int, 10)\n    go fibonacci(10, ch)\n\n    for v := range ch { // DEADLOCK after 10 values\n        fmt.Println(v)\n    }\n}\n```\n\n**Result**: Prints 10 numbers, then deadlock!\n\n```\n0\n1\n...\n34\nfatal error: all goroutines are asleep - deadlock!\n```\n\n**Why?** Range keeps waiting for more values. Without `close()`, it never knows to stop.\n\n### Exercise 4.7: Range Practice\n\n**Task**: Create a generator that sends squares of 1-10.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc squares(ch chan int) {\n    // TODO: Send squares of 1 through 10\n    // TODO: Close the channel\n}\n\nfunc main() {\n    ch := make(chan int)\n    go squares(ch)\n\n    // TODO: Use range to receive and print all values\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc squares(ch chan int) {\n    for i := 1; i \u003c= 10; i++ {\n        ch \u003c- i * i\n    }\n    close(ch)\n}\n\nfunc main() {\n    ch := make(chan int)\n    go squares(ch)\n\n    for v := range ch {\n        fmt.Println(v)\n    }\n}\n```\n\n**Output**: 1 4 9 16 25 36 49 64 81 100\n\n\u003c/details\u003e\n\n### Multiple Ranges (Pipeline Pattern)\n\nYou can chain ranges:\n\n```go\nfunc gen() \u003c-chan int {\n    ch := make(chan int)\n    go func() {\n        for i := 1; i \u003c= 5; i++ {\n            ch \u003c- i\n        }\n        close(ch)\n    }()\n    return ch\n}\n\nfunc square(in \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        for v := range in { // Range over input\n            out \u003c- v * v\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc main() {\n    for v := range square(gen()) { // Chain!\n        fmt.Println(v) // 1 4 9 16 25\n    }\n}\n```\n\n**This is a pipeline!** We'll explore this pattern more in Section 4.13.\n\n---\n## Section 4.10: How Channels Work (Simplified Internals)\n\n### Why Bother Learning This?\n\nYou can use channels without knowing internals. But knowing them helps you:\n- **Debug** channel issues faster\n- **Answer interview questions** confidently\n- **Make better decisions** about when to use channels vs mutexes\n- **Understand performance** trade-offs\n\nLet's pull back the curtain!\n\n---\n\n### The Big Picture\n\nWhen you write:\n```go\nch := make(chan int, 3)\n```\n\nYou think: \"I created a channel.\"\n\nWhat Go actually does: Allocates a struct on the heap called `hchan` and gives you a **pointer** to it.\n\n```\nch variable heap memory\n    │ ┌──────────────────────────┐\n    └──pointer────→ │ hchan struct │\n                    │ (the real channel object) │\n                    └──────────────────────────┘\n```\n\nEvery channel operation (`ch \u003c- value`, `\u003c-ch`, `close(ch)`) works through this struct.\n\n---\n\n### The hchan Struct: What's Inside\n\nHere is the actual struct Go uses internally (simplified):\n\n```go\ntype hchan struct {\n    // ── BUFFER (the storage) ──────────────────────────\n    qcount uint // How many elements are in the buffer RIGHT NOW\n    dataqsiz uint // Max capacity (the number you passed to make)\n    buf unsafe.Pointer // Pointer to the actual buffer array\n    elemsize uint16 // Size of each element in bytes (e.g. int = 8 bytes)\n\n    // ── INDEXES (where to read/write in buffer) ───────\n    sendx uint // Next position to WRITE into\n    recvx uint // Next position to READ from\n\n    // ── WAITING GOROUTINES ────────────────────────────\n    sendq waitq // Queue of goroutines BLOCKED waiting to SEND\n    recvq waitq // Queue of goroutines BLOCKED waiting to RECEIVE\n\n    // ── METADATA ─────────────────────────────────────\n    closed uint32 // 0 = open, 1 = closed\n    lock mutex // Protects EVERYTHING above\n}\n```\n\nLet's understand each piece:\n\n---\n\n### Piece 1: The Buffer Fields\n\n```\nqcount = how full is the buffer right now?\ndataqsiz = what's the max capacity?\nbuf = where is the actual data stored?\nelemsize = how big is each element?\n```\n\n**Visual example** - `make(chan int, 3)`:\n\n```\nhchan:\n  dataqsiz = 3 ← capacity you asked for\n  elemsize = 8 ← int is 8 bytes on 64-bit\n  qcount = 0 ← empty right now\n\n  buf ──────────────→ [ _ | _ | _ ]\n                        slot0 slot1 slot2\n```\n\nAfter `ch \u003c- 10` and `ch \u003c- 20`:\n\n```\nhchan:\n  dataqsiz = 3\n  qcount = 2 ← 2 elements in buffer\n\n  buf ──────────────→ [ 10 | 20 | _ ]\n```\n\nSimple! `qcount` tells you \"how many are in here right now.\" `dataqsiz` is the max. `buf` is where they live.\n\n---\n\n### Piece 2: The Index Fields (sendx and recvx)\n\nThe buffer is a **circular/ring buffer** - it wraps around like a clock.\n\n```\nsendx = \"next slot to write into\"\nrecvx = \"next slot to read from\"\n```\n\n**Step-by-step example** with `make(chan int, 3)`:\n\n```\nStart:\n  buf: [ _ | _ | _ ]\n          ↑\n        sendx=0\n        recvx=0\n        qcount=0\n\nAfter ch \u003c- 10:\n  buf: [ 10 | _ | _ ]\n               ↑\n             sendx=1 (moved forward)\n        recvx=0\n        qcount=1\n\nAfter ch \u003c- 20:\n  buf: [ 10 | 20 | _ ]\n                    ↑\n                  sendx=2\n        recvx=0\n        qcount=2\n\nAfter ch \u003c- 30 (buffer now FULL):\n  buf: [ 10 | 20 | 30 ]\n          ↑\n        sendx=0 ← WRAPPED BACK TO 0!\n        recvx=0\n        qcount=3\n\nAfter \u003c-ch (receive 10):\n  buf: [ _ | 20 | 30 ]\n               ↑\n        sendx=0\n             recvx=1 (moved forward)\n        qcount=2\n\nAfter ch \u003c- 40 (new send fills the gap):\n  buf: [ 40 | 20 | 30 ]\n               ↑\n             sendx=1\n        recvx=1\n        qcount=3\n```\n\n**Why circular?** So we don't waste space! Instead of shifting everything left when we read, we just move a pointer. It's like a clock hand — when it hits the end, it wraps to the beginning.\n\n**How Go knows empty vs full:**\n- Empty = `qcount == 0`\n- Full = `qcount == dataqsiz`\n\nSimple! The `qcount` field tells us, no tricks needed.\n\n---\n\n### Piece 3: The Wait Queues (sendq and recvq)\n\nThis is where it gets interesting!\n\n```\nsendq = list of goroutines BLOCKED trying to SEND (buffer full)\nrecvq = list of goroutines BLOCKED trying to RECEIVE (buffer empty)\n```\n\nEach entry in the queue is called a **sudog** (\"pseudo-goroutine\"). Think of it as a ticket that says:\n\n```\nsudog = {\n    g: *goroutine ← \"this goroutine is waiting\"\n    elem: *data ← \"this is the data it wants to send/receive\"\n    next: *sudog ← \"next person in line\"\n    prev: *sudog ← \"previous person in line\"\n}\n```\n\nThe queues are **FIFO** (First In, First Out) - whoever waited longest gets served first.\n\n**Visual: 3 goroutines blocked trying to send on a full channel:**\n\n```\nhchan:\n  buf: [ 10 | 20 | 30 ] ← FULL\n\n  sendq:\n    first ──→ [sudog: G4, elem=\u002640] ↔ [sudog: G5, elem=\u002650] ↔ [sudog: G6, elem=\u002660] ←── last\n               waiting longest newest waiter\n```\n\nWhen someone receives, G4 (waiting longest) gets served first. FIFO!\n\n---\n\n### Piece 4: The Lock\n\n```\nlock = protects everything in the hchan struct\n```\n\nBefore ANY channel operation, Go acquires this lock. After the operation, it releases it.\n\n**Why?** Multiple goroutines might operate on the same channel simultaneously. Without a lock, `qcount` and the buffer would be in a race condition!\n\n```\nch \u003c- 42 means: lock(\u0026ch.lock)\n                      ... do the operation ...\n                      unlock(\u0026ch.lock)\n```\n\nThis is why channels are safe for concurrent use - the internal lock handles it!\n\n**This is also why channels are slower than mutexes:** Channels have a mutex INSIDE them PLUS scheduler operations. A plain mutex is just the lock, nothing else.\n\n---\n\n### Visualizing the Full hchan\n\nLet's see the whole struct for `make(chan int, 3)` with 2 values in it:\n\n```\n                    hchan struct\n                 ┌─────────────────────┐\n  qcount = 2 │ ████░░ │ ← 2 of 3 slots used\n  dataqsiz = 3 │ │\n  elemsize = 8 │ element = int (8B) │\n                 ├─────────────────────┤\n  sendx = 2 │ write position ──→ │ slot 2 (next write here)\n  recvx = 0 │ read position ──→ │ slot 0 (next read here)\n                 ├─────────────────────┤\n  buf ──────────→│ [ 10 | 20 | __ ] │ circular buffer\n                 ├─────────────────────┤\n  sendq: empty │ (no blocked senders yet)\n  recvq: empty │ (no blocked receivers)\n                 ├─────────────────────┤\n  closed = 0 │ channel is open │\n  lock: unlocked │ │\n                 └─────────────────────┘\n```\n\n---\n\n### What Happens During a Send: 3 Cases\n\nWhen you write `ch \u003c- 42`, Go checks three cases in order:\n\n#### Case 1: Someone is already waiting to receive (FAST PATH!)\n\n```\nSituation: recvq has a waiting goroutine\n\nch := make(chan int)\ngo func() { v := \u003c-ch }() // G2 is waiting in recvq!\nch \u003c- 42 // G1 sends\n```\n\n**What happens:**\n\n```\nG1 sends 42:\n  1. Lock channel\n  2. Check recvq → G2 is waiting!\n  3. Copy 42 DIRECTLY to G2's variable (no buffer!)\n  4. Wake up G2 (put it back in scheduler)\n  5. Unlock and continue\n\n        G1's stack G2's stack\n      [ val: 42 ] ────────→ [ v: 42 ]\n                  1 copy!\n                (SKIPS BUFFER ENTIRELY)\n```\n\n**This is the \"fast path\"** - data goes directly from sender's memory to receiver's memory. One copy, no buffer involved!\n\n**Why skip the buffer?** Because it's faster! One copy instead of two.\n\n---\n\n#### Case 2: Buffer has space\n\n```\nSituation: buffer is not full, no waiting receiver\n\nch := make(chan int, 3) // buffer has space\nch \u003c- 42 // just store in buffer\n```\n\n**What happens:**\n\n```\nG1 sends 42:\n  1. Lock channel\n  2. Check recvq → empty\n  3. Check buffer → has space (qcount \u003c dataqsiz)!\n  4. Copy 42 into buf[sendx]\n  5. Advance sendx\n  6. Increment qcount\n  7. Unlock and continue (NO BLOCKING!)\n\n  buf: [ _ | _ | _ ] → [ 42 | _ | _ ]\n        ↑ ↑\n      sendx=0 sendx=1\n```\n\n**Sender doesn't block!** Just copies to buffer and moves on.\n\n---\n\n#### Case 3: Must block (buffer full or unbuffered with no receiver)\n\n```\nSituation: buffer is full OR unbuffered with no one receiving\n\nch := make(chan int, 2)\nch \u003c- 10\nch \u003c- 20\nch \u003c- 30 // BUFFER FULL! Must wait.\n```\n\n**What happens:**\n\n```\nG1 tries to send 30:\n  1. Lock channel\n  2. Check recvq → empty\n  3. Check buffer → FULL (qcount == dataqsiz)!\n  4. Create sudog for G1:\n        sudog = { g: G1, elem: \u002630 }\n                              ↑\n                        points to 30 on G1's stack!\n  5. Add sudog to sendq (end of queue)\n  6. PARK G1 (remove from scheduler, save state)\n  7. Unlock channel (someone else can now use the channel)\n  8. G1 is now SLEEPING...\n\n  ... later, when someone receives from ch ...\n\n  9. Receiver wakes G1 (goready)\n  10. G1 resumes and checks: was send successful?\n  11. Continue or panic if channel was closed\n```\n\n**\"Park\"** means: save G1's state (stack pointer, program counter), remove it from Go's scheduler run queue. G1 is now invisible - it doesn't consume CPU. It just exists in memory, pointed to by that sudog in the sendq.\n\n**\"Wake\"** means: put G1 back in the scheduler's run queue. The OS will eventually run it again from where it left off.\n\n```\nGoroutine states:\n\n  Running ──[channel full]──→ Waiting (parked)\n                                   │\n                          [receiver arrives]\n                                   │\n  Running ←──[scheduler picks]─── Runnable\n```\n\n---\n\n### What Happens During a Receive: 3 Cases\n\nMirror of send! `v := \u003c-ch` also has three cases:\n\n#### Case 1: Someone is already waiting to send (FAST PATH)\n\n```\nSituation: sendq has a waiting goroutine\n\nch := make(chan int)\ngo func() { ch \u003c- 42 }() // G2 is waiting in sendq with value 42!\nv := \u003c-ch // G1 receives\n```\n\n**What happens:**\n\n```\nG1 receives:\n  1. Lock channel\n  2. Check sendq → G2 is waiting with value 42!\n  3. Copy 42 DIRECTLY from G2's stored elem to v\n  4. Wake up G2 (it can continue now)\n  5. Unlock and continue\n\n  G2's sudog: { elem: \u002642 }\n                    │\n                    └──────→ G1's v = 42\n                    (direct copy!)\n```\n\n**Special case: buffered channel with full buffer AND waiting sender**\n\nThis is the trickiest case. If the buffer is full and a sender is waiting:\n\n```\nbuf: [ 10 | 20 | 30 ] ← full\nsendq: [G2 waiting with 40]\n\nReceive happens:\n  1. Take 10 from buf[recvx=0] → receiver gets 10\n  2. Copy G2's 40 into buf[0] → fill the gap G2 was waiting to fill\n  3. Wake up G2\n  4. recvx moves to 1\n\nbuf: [ 40 | 20 | 30 ] ← still full, but G2 is unblocked!\n```\n\n**Why this dance?** To maintain FIFO order! The receiver should get the OLDEST value (10), not G2's new value (40). So we take from buffer first, then move the waiting sender's value into the now-free slot.\n\n---\n\n#### Case 2: Buffer has data\n\n```\nv := \u003c-ch // channel has data in buffer\n```\n\n**What happens:**\n\n```\nG1 receives:\n  1. Lock channel\n  2. Check sendq → empty\n  3. Check buffer → has data (qcount \u003e 0)!\n  4. Copy buf[recvx] into v\n  5. Clear that slot (helps GC with pointer types)\n  6. Advance recvx\n  7. Decrement qcount\n  8. Unlock and continue (NO BLOCKING!)\n```\n\nSimple! Just read from the buffer.\n\n---\n\n#### Case 3: Must block (empty buffer, no sender)\n\n```\nv := \u003c-ch // nothing to receive from!\n```\n\n**What happens:**\n\n```\nG1 tries to receive:\n  1. Lock channel\n  2. Check sendq → empty\n  3. Check buffer → empty (qcount == 0)\n  4. Create sudog for G1:\n        sudog = { g: G1, elem: \u0026v }\n                             ↑\n                       points to v on G1's stack\n  5. Add sudog to recvq\n  6. PARK G1 (remove from scheduler)\n  7. Unlock channel\n  8. G1 is now SLEEPING...\n\n  ... later, when someone sends to ch ...\n\n  9. Sender writes 42 directly into G1's v (via elem pointer!)\n  10. Sender wakes G1\n  11. G1 resumes, v already has the value\n```\n\n**The clever part**: The sender writes DIRECTLY into G1's stack variable via the `elem` pointer. When G1 wakes up, `v` already has the value - no extra copy needed!\n\n---\n\n### The Complete Flow: Side by Side\n\n```\nSEND: ch \u003c- x RECEIVE: v := \u003c-ch\n─────────────────────────────────────────────────────\n1. Acquire lock 1. Acquire lock\n2. Channel closed? → panic 2. Closed + empty? → zero, ok=false\n3. Receiver waiting? 3. Sender waiting?\n   YES → copy to receiver YES → copy from sender\n         wake receiver wake sender\n         release lock release lock\n         return return\n4. Buffer has space? 4. Buffer has data?\n   YES → copy to buffer YES → copy from buffer\n         update sendx update recvx\n         increment qcount decrement qcount\n         release lock release lock\n         return return\n5. Must block: 5. Must block:\n   create sudog create sudog\n   add to sendq add to recvq\n   gopark (sleep) gopark (sleep)\n   ... wake up later ... ... wake up later ...\n   return return\n```\n\n---\n\n### Memory Overhead: How Big Are Channels?\n\n```\nhchan struct itself: ~96 bytes\n\nBuffer (allocated at creation):\n  make(chan int, 100) → 96 + (100 × 8) = ~896 bytes\n  make(chan int, 1000) → 96 + (1000 × 8) = ~8,096 bytes\n  make(chan struct{}, N) → 96 bytes only! (zero-size, no buffer allocated!)\n\nPer blocked goroutine (sudog):\n  ~160 bytes\n\nExample: 1000 goroutines blocked on a channel:\n  96 + (1000 × 160) = ~160,096 bytes (~160KB)\n```\n\n**Why `chan struct{}` is special:**\n\n`struct{}` has zero size. The runtime is smart enough to not allocate any buffer memory at all, even with a large capacity! This makes `chan struct{}` perfect for pure signaling:\n\n```go\ndone := make(chan struct{}) // Only ~96 bytes, regardless of capacity!\nclose(done) // Signal completion to all\n```\n\n---\n\n### Why Are Channels Slower Than Mutexes?\n\nNow you can see exactly why:\n\n```\nMutex Lock/Unlock:\n  ~12ns\n  │\n  ├─ Atomic compare-and-swap (hardware instruction)\n  └─ Done! That's it.\n\nChannel Send + Receive:\n  ~200ns\n  │\n  ├─ Acquire lock (~20ns)\n  ├─ Check queues and buffer (~10ns)\n  ├─ Copy data (~5-20ns)\n  ├─ gopark: save goroutine state, remove from scheduler (~60ns)\n  ├─ schedule(): OS picks another goroutine to run\n  ├─ goready: mark goroutine runnable, add to run queue (~80ns)\n  └─ Context switch: OS runs the woken goroutine\n```\n\n**Channels are ~5-20x slower than mutexes** for simple operations.\n\n**But** - channels are doing SO MUCH MORE:\n- Safe data transfer\n- Goroutine coordination\n- No starvation (FIFO queues)\n- Built-in blocking/waking\n\nFor simple shared state (a counter), use a mutex.\nFor coordination between goroutines, channels are worth the cost!\n\n---\n\n### Interview Quick Reference\n\n**Common interview questions and what you now know:**\n\n**Q: What is a channel internally?**\n\nA: A heap-allocated `hchan` struct containing: a circular ring buffer (`buf`, `sendx`, `recvx`, `qcount`, `dataqsiz`), two FIFO wait queues (`sendq`, `recvq`) of `sudog` structs for blocked goroutines, a `closed` flag, element type info, and a runtime mutex protecting all fields.\n\n**Q: What is the \"fast path\" for channels?**\n\nA: When a receiver is already waiting (for sends) or sender is already waiting (for receives), data copies DIRECTLY from one goroutine's stack to the other's - bypassing the buffer entirely. One copy instead of two, no buffer needed. This is called `sendDirect`/`recvDirect` internally.\n\n**Q: What does \"blocking\" on a channel mean internally?**\n\nA: The goroutine creates a `sudog` (with a pointer to its data in `elem`), enqueues it on `sendq` or `recvq`, and calls `gopark` - which saves the goroutine's state and removes it from the scheduler's run queue. The goroutine consumes no CPU while parked. When unblocked, `goready` moves it back to the run queue.\n\n**Q: Why is unbuffered faster in some cases?**\n\nA: Unbuffered always uses direct stack-to-stack copy (one `memmove`). Buffered channels go through the buffer (two `memmove` operations). But unbuffered always involves goroutine parking/waking, while buffered channels with available space can avoid it entirely.\n\n**Q: What happens when you close a channel with blocked receivers?**\n\nA: `close()` iterates through ALL goroutines in `recvq`, sets their `success = false` and `elem` to zero value, then calls `goready` on each one. They wake up and return `ok = false`. Blocked senders also get woken, but they `panic` because sending to a closed channel is invalid.\n\n---\n\n### Quiz 4.10: Understanding Internals\n\n**Question 1**: Why do channels need an internal lock?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nBecause multiple goroutines can send/receive on the same channel simultaneously. The lock protects all the internal state (`qcount`, `sendx`, `recvx`, the buffer, the queues) from becoming corrupted by concurrent access.\n\nChannels use a lock internally so **YOU** don't have to use locks externally. The channel is already thread-safe!\n\n\u003c/details\u003e\n\n**Question 2**: What is a `sudog` and what is stored in it?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nA `sudog` (pseudo-goroutine) is a struct that represents a goroutine waiting on a channel. It stores:\n\n- `g`: pointer to the waiting goroutine\n- `elem`: pointer to the data (on the goroutine's stack!) — for senders it's the value being sent, for receivers it's the variable that should receive the value\n- `next`/`prev`: for the doubly-linked wait queue\n\nThe `elem` pointer is what enables the fast path - the runtime can write directly to another goroutine's stack variable!\n\n\u003c/details\u003e\n\n**Question 3**: What's the difference between how unbuffered and buffered channels send data?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Unbuffered**: Always waits for a receiver. Data copies DIRECTLY from sender's stack to receiver's stack (one copy). Both goroutines must \"meet\" — if no receiver is waiting, sender blocks.\n\n**Buffered (with space)**: Data copies from sender's stack INTO the buffer (one copy). Sender doesn't block. Receiver later copies from buffer to their variable (second copy). Two total copies, but no goroutine blocking needed.\n\n**Buffered (fast path)**: If a receiver is already waiting, buffered channels ALSO use the direct copy path (one copy, no buffer). Same as unbuffered!\n\n\u003c/details\u003e\n\n**Question 4**: You have `make(chan struct{}, 1000000)`. How much memory does the buffer use?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\n**Zero bytes!** `struct{}` is a zero-sized type. The runtime detects this and allocates no buffer memory, regardless of capacity. The entire channel is ~96 bytes (just the `hchan` struct).\n\nThis is why `chan struct{}` is the idiomatic choice for signaling and semaphores — it's memory-efficient pure coordination.\n\n\u003c/details\u003e\n\n**Question 5**: Why does sending to a full buffered channel, when a receiver is available, have slightly different behavior than you might expect?\n\n\u003cdetails\u003e\n\u003csummary\u003eAnswer\u003c/summary\u003e\n\nWhen the buffer is full AND a sender is waiting in `sendq`, a receive does this (in order):\n\n1. Takes the OLDEST value from `buf[recvx]` → gives to receiver\n2. Copies the waiting sender's value into the now-empty buffer slot\n3. Wakes the sender\n\nIt does NOT give the receiver the sender's value directly! This maintains **FIFO ordering** — the receiver gets the oldest value first, and the sender's value goes to the back of the queue.\n\n\u003c/details\u003e\n\n## Section 4.11: Channel Performance\n\n### Benchmark Numbers\n\n**Typical latencies** (Go 1.21, modern CPU):\n\n| Operation | Time | Relative |\n|-----------|------|----------|\n| sync.Mutex Lock/Unlock | ~11 ns | 1x |\n| chan send+receive (buffered) | ~55 ns | 5x |\n| chan send+receive (unbuffered) | ~190 ns | 17x |\n\n**Memory**:\n- Mutex: ~8 bytes\n- Channel: ~96+ bytes\n- Channel with buffer: 96 + (capacity × element_size)\n\n### When Performance Matters\n\n**Channels are \"slow\" compared to mutexes**, but:\n\n**Ask yourself**:\n1. Is this a bottleneck? (Profile first!)\n2. How many operations per second?\n3. Is correctness more important?\n\n**Example calculations**:\n\nIf you do 1,000 channel operations per second:\n- Total overhead: 1,000 × 190ns = 0.19ms\n- **This is negligible!**\n\nIf you do 10,000,000 operations per second:\n- Total overhead: 10M × 190ns = 1.9 seconds\n- **Now it might matter!**\n\n### Real-World Perspective\n\nFrom production systems:\n\n**Web server** (1000 req/sec):\n- Channel overhead: \u003c 1% of request time\n- Network/DB far slower\n- **Channels are fine!**\n\n**High-frequency trading** (millions ops/sec):\n- Channel overhead: significant\n- Mutex or atomics needed\n- **Channels might be too slow**\n\n**Rule**: **Start with channels. Optimize only if profiling shows it matters.**\n\n### Buffered vs Unbuffered Performance\n\n**Buffered channels** are faster because:\n- Less blocking\n- Fewer goroutine park/unpark operations\n- Better CPU cache usage\n\n**But**: Don't choose buffered just for performance!\n\n**Choose based on semantics**:\n- Need synchronization? → Unbuffered\n- Need decoupling? → Buffered\n- Need to handle bursts? → Buffered\n\nThen, if profiling shows a problem, optimize.\n\n### Exercise 4.8: Benchmark Channels\n\n**Task**: Compare unbuffered vs buffered performance.\n\n```go\npackage main\n\nimport (\n    \"testing\"\n)\n\nfunc BenchmarkUnbuffered(b *testing.B) {\n    ch := make(chan int)\n    go func() {\n        for i := 0; i \u003c b.N; i++ {\n            \u003c-ch\n        }\n    }()\n\n    for i := 0; i \u003c b.N; i++ {\n        ch \u003c- i\n    }\n}\n\nfunc BenchmarkBuffered(b *testing.B) {\n    ch := make(chan int, 100)\n    go func() {\n        for i := 0; i \u003c b.N; i++ {\n            \u003c-ch\n        }\n    }()\n\n    for i := 0; i \u003c b.N; i++ {\n        ch \u003c- i\n    }\n}\n```\n\n**Run**: `go test -bench . -benchmem`\n\n\u003cdetails\u003e\n\u003csummary\u003eExpected Results\u003c/summary\u003e\n\n```\nBenchmarkUnbuffered-8 10000000 180 ns/op 0 B/op\nBenchmarkBuffered-8 20000000 50 ns/op 0 B/op\n```\n\nBuffered is ~3-4x faster! But both are still very fast in absolute terms.\n\n\u003c/details\u003e\n\n---\n\n## Section 4.12: The Select Statement\n\n### 4.12.1: The Problem Select Solves — Waiting on Multiple Channels\n\n**The Challenge:**\n\nYou have two goroutines sending data on two different channels. You want to receive from whichever channel has data ready first. Without `select`, you'd have to choose one channel to block on, missing data from the other.\n\n```go\n// WITHOUT select - you're stuck choosing one channel\ndata1 := \u003c-ch1  // What if ch2 has data ready but ch1 doesn't?\n// OR\ndata2 := \u003c-ch2  // What if ch1 has data ready but ch2 doesn't?\n```\n\nThe `select` statement solves this by letting you wait on multiple channel operations simultaneously.\n\n---\n\n### 4.12.2: Your First Select (Two Channels, Whoever Is Ready Wins)\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    ch1 := make(chan string)\n    ch2 := make(chan string)\n\n    // Goroutine 1: sends to ch1 after 100ms\n    go func() {\n        time.Sleep(100 * time.Millisecond)\n        ch1 \u003c- \"from channel 1\"\n    }()\n\n    // Goroutine 2: sends to ch2 after 200ms\n    go func() {\n        time.Sleep(200 * time.Millisecond)\n        ch2 \u003c- \"from channel 2\"\n    }()\n\n    // Select waits on both channels\n    select {\n    case msg1 := \u003c-ch1:\n        fmt.Println(\"Received:\", msg1)\n    case msg2 := \u003c-ch2:\n        fmt.Println(\"Received:\", msg2)\n    }\n}\n```\n\n**Output:**\n```\nReceived: from channel 1\n```\n\n**Why?** ch1 becomes ready first (100ms \u003c 200ms), so that case executes.\n\n**Key Insight:** `select` blocks until at least ONE case can proceed, then executes that case.\n\n---\n### 4.12.3 — The Critical Rule: Uniform Pseudo-Random Selection (NOT Source Order!)\n\n**What Is \"Source Order\"?**\n\nSource order just means the order in which you wrote the cases in your code — top to bottom.\n\n```go\nselect {\ncase msg := \u003c-ch1:   // ← first in source order\n    fmt.Println(msg)\ncase msg := \u003c-ch2:   // ← second in source order\n    fmt.Println(msg)\n}\n```\n\nA natural assumption is: *\"Go checks ch1 first. If ch1 has data, it picks ch1. If not, it checks ch2.\"* This is how an `if/else if` chain works, and most developers assume `select` behaves similarly.\n\n**It doesn't.**\n\n**What Actually Happens**\n\nThe Go specification says:\n\n\u003e \"If one or more of the communications can proceed, a single one that can proceed is chosen via a uniform pseudo-random selection.\"\n\nTranslation: If multiple channels are ready at the same time, Go picks one **randomly**. Not the first one. Not the one that was ready longest. Randomly.\n\n**Why Does This Matter?**\n\nBecause if you build logic assuming ch1 always wins over ch2 when both are ready, you have a latent bug. Your code will work 50% of the time and silently fail the other 50%.\n\n**Proof**\n\nThe easiest way to prove this is to make both channels ready *before* the select even runs, then run the select many times and count which case wins.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch1 := make(chan int, 1)\n    ch2 := make(chan int, 1)\n\n    // Pre-fill both so BOTH are ready before we even reach select\n    ch1 \u003c- 1\n    ch2 \u003c- 2\n\n    case1Count := 0\n    case2Count := 0\n\n    for i := 0; i \u003c 10000; i++ {\n        select {\n        case \u003c-ch1:\n            case1Count++\n            ch1 \u003c- 1 // refill for next iteration\n        case \u003c-ch2:\n            case2Count++\n            ch2 \u003c- 2 // refill for next iteration\n        }\n    }\n\n    fmt.Printf(\"Case 1 won: %d times\\n\", case1Count)\n    fmt.Printf(\"Case 2 won: %d times\\n\", case2Count)\n}\n```\n\nOutput (will vary each run, but always roughly 50/50):\n\n```\nCase 1 won: 5023 times\nCase 2 won: 4977 times\n```\n\nIf source order mattered, case 1 would win 10,000 times. It doesn't.\n\n**Why Did Go Design It This Way?**\n\n**Fairness.** If Go always picked the first ready case, then in a busy system where ch1 is almost always ready, ch2 would starve — it would never get processed. Random selection means every ready channel gets a fair share of attention over time.\n\n**Deadlock prevention.** Deterministic selection can create subtle circular waits. Randomness breaks those patterns.\n\n**CSP alignment.** Go's concurrency model is based on Communicating Sequential Processes (CSP), a mathematical model where non-determinism in channel selection is a core property.\n\n\u003e **Interview answer:** \"When multiple cases in a select are ready, Go picks one via uniform pseudo-random selection — not source order.\"\n\n---\n\n### 4.12.4 — Default Case: Non-Blocking Channel Operations\n\n**First, Understand Blocking**\n\nWithout a default case, `select` **blocks** — it parks the goroutine and waits until at least one case can proceed. Your goroutine does nothing until a channel is ready.\n\n```go\nch := make(chan int)\n\nselect {\ncase v := \u003c-ch: // ch is empty — goroutine blocks here until someone sends\n    fmt.Println(v)\n}\n```\n\nThe goroutine is frozen at this `select` until another goroutine sends to `ch`. This is often what you want. But sometimes you want to *check* a channel and move on if it's not ready. That's what `default` does.\n\n**How Default Makes It Non-Blocking**\n\nWhen you add a `default` case, the `select` no longer blocks. Instead:\n\n1. Go checks all the channel cases instantly\n2. If any case is ready → execute it\n3. If **none** are ready → execute `default` immediately\n\n```go\nch := make(chan int, 1) // empty buffered channel\n\nselect {\ncase v := \u003c-ch:\n    fmt.Println(\"Got:\", v)\ndefault:\n    fmt.Println(\"Nothing ready, moving on\")\n}\n// Output: Nothing ready, moving on\n```\n\nThe goroutine never pauses. It checks, sees nothing, runs `default`, and continues.\n\nNow fill the channel first:\n\n```go\nch := make(chan int, 1)\nch \u003c- 42 // now ch has data\n\nselect {\ncase v := \u003c-ch:\n    fmt.Println(\"Got:\", v) // ← this runs because ch is ready\ndefault:\n    fmt.Println(\"Nothing ready\")\n}\n// Output: Got: 42\n```\n\n**Non-Blocking Receive in Practice**\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch := make(chan int, 1)\n\n    // Try to receive — nothing there\n    select {\n    case v := \u003c-ch:\n        fmt.Println(\"Received:\", v)\n    default:\n        fmt.Println(\"No data available, skipping\")\n    }\n\n    // Put something in\n    ch \u003c- 99\n\n    // Try again — this time it works\n    select {\n    case v := \u003c-ch:\n        fmt.Println(\"Received:\", v)\n    default:\n        fmt.Println(\"No data available, skipping\")\n    }\n}\n```\n\nOutput:\n```\nNo data available, skipping\nReceived: 99\n```\n\n**Non-Blocking Send in Practice**\n\nThe same idea works for sending. Normally, sending to a full buffered channel blocks. With `default`, it doesn't:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch := make(chan int, 1)\n    ch \u003c- 1 // buffer is full (capacity = 1)\n\n    select {\n    case ch \u003c- 2: // try to send — buffer full, can't\n        fmt.Println(\"Sent successfully\")\n    default:\n        fmt.Println(\"Channel full, dropping message\")\n    }\n}\n// Output: Channel full, dropping message\n```\n\nThis is useful in metrics pipelines where you want to \"fire and forget\" — if the consumer is slow, drop the metric rather than blocking the producer.\n\n**The \"Try-Lock\" Pattern with Mutexes**\n\nThis is an advanced pattern, but worth knowing. A standard mutex blocks:\n\n```go\nmu.Lock()   // blocks until the lock is free\ndoWork()\nmu.Unlock()\n```\n\nSometimes you want to *try* to acquire a lock and move on if you can't. Channels can simulate this:\n\n```go\n// A channel with buffer 1 acts like a mutex token\nlock := make(chan struct{}, 1)\nlock \u003c- struct{}{} // \"token\" is available (lock is free)\n\n// Try to acquire\nselect {\ncase \u003c-lock: // take the token = acquire the lock\n    fmt.Println(\"Got lock, doing work\")\n    // ... do work ...\n    lock \u003c- struct{}{} // put token back = release\ndefault:\n    fmt.Println(\"Lock busy, skipping\")\n}\n```\n\nIf the token is in the channel, you take it (acquire). If someone else already took it (channel empty), `default` fires and you skip. This is the try-lock pattern — attempt the lock without blocking.\n\n\u003e In production Go, you'd use `sync.Mutex` for real locking. This pattern matters conceptually because it shows how channels can model synchronization primitives.\n\n---\n\n### 4.12.5 — Timeout Pattern: `select` + `time.After`\n\n**Building Up to It: What Problem Are We Solving?**\n\nImagine you call a slow service:\n\n```go\nresult := \u003c-slowService() // what if this never responds?\n```\n\nIf `slowService` hangs forever, your goroutine hangs forever too. You need a way to say: *\"Wait up to 1 second. If nothing arrives by then, give up.\"*\n\nThat's the timeout pattern.\n\n**The Simplest Timeout Example**\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    ch := make(chan string)\n\n    // This goroutine sends after 2 seconds\n    go func() {\n        time.Sleep(2 * time.Second)\n        ch \u003c- \"hello\"\n    }()\n\n    // We only wait 1 second\n    select {\n    case msg := \u003c-ch:\n        fmt.Println(\"Got:\", msg)\n    case \u003c-time.After(1 * time.Second):\n        fmt.Println(\"Timed out!\")\n    }\n}\n// Output: Timed out!\n```\n\n**What Is `time.After`?**\n\n`time.After(d)` returns a channel (`\u003c-chan time.Time`). After duration `d` elapses, the runtime sends the current time into that channel. Until then, the channel is empty.\n\nSo in the select above:\n- `\u003c-ch` blocks waiting for our goroutine to send\n- `\u003c-time.After(1 * time.Second)` blocks for 1 second, then becomes ready\n\nWhoever fires first wins. In our case, the 2-second goroutine loses to the 1-second timer.\n\n**What Happens When the Service IS Fast?**\n\n```go\ngo func() {\n    time.Sleep(100 * time.Millisecond) // fast this time\n    ch \u003c- \"hello\"\n}()\n\nselect {\ncase msg := \u003c-ch:\n    fmt.Println(\"Got:\", msg) // ← this wins\ncase \u003c-time.After(1 * time.Second):\n    fmt.Println(\"Timed out!\")\n}\n// Output: Got: hello\n```\n\nThe service responds in 100ms. The `\u003c-ch` case fires first. The timer never fires.\n\n---\n\n**⚠️ The Memory Leak Gotcha**\n\n**First, Understand What `time.After` Actually Creates**\n\nEvery call to `time.After(d)` creates a **new timer object** in the Go runtime. This timer sits in memory and waits to fire after `d`. It gets garbage collected only after it fires (not before).\n\nOne timer = fine. Millions of timers = problem.\n\n**Why Putting It in a Loop Is Dangerous**\n\n```go\n// ❌ BAD — MEMORY LEAK\nfor {\n    select {\n    case msg := \u003c-messages:\n        process(msg)\n    case \u003c-time.After(5 * time.Second): // ← new timer every iteration!\n        cleanup()\n    }\n}\n```\n\nEvery time the loop body runs, Go calls `time.After(5 * time.Second)` again and creates a **brand new** timer. The old timer from the previous iteration? It's still alive in memory, waiting to fire in 5 seconds. You never canceled it.\n\nIf your loop processes 1,000 messages/second:\n- Each second: 1,000 new timers created\n- Each timer lives for 5 seconds before firing\n- After 5 seconds: 5,000 live timers consuming memory simultaneously\n- At ~200 bytes/timer: ~1MB of timer objects at steady state\n\nIn a real high-throughput system (ArangoDB documented memory leak for wrong usage of `time.After`), could cause memory leaks.\n\n**The Fix: `time.NewTimer` Outside the Loop**\n\n```go\n// ✅ GOOD — one timer, reused\ntimer := time.NewTimer(5 * time.Second)\ndefer timer.Stop() // always clean up when done\n\nfor {\n    select {\n    case msg := \u003c-messages:\n        process(msg)\n        // Reset the timer: stop it first, drain if needed, then reset\n        if !timer.Stop() {\n            \u003c-timer.C // drain the channel if timer already fired\n        }\n        timer.Reset(5 * time.Second)\n\n    case \u003c-timer.C:\n        cleanup()\n        timer.Reset(5 * time.Second)\n    }\n}\n```\n\nOne timer object, reused every iteration. Memory stays flat no matter how many messages you process.\n\n**The `timer.Stop()` / `timer.Reset()` Dance Explained**\n\n`timer.Stop()` returns `true` if it successfully stopped the timer before it fired, and `false` if the timer already fired.\n\nIf `Stop()` returns `false`, the timer already sent its value to `timer.C`. If you call `Reset()` without draining `timer.C` first, the channel still has that old value in it — and your next `case \u003c-timer.C` will trigger immediately even though you just reset it. The drain (`\u003c-timer.C`) removes that stale value.\n\n**Go 1.23 Update**\n\nIn Go 1.23, `time.After` got smarter: when used *directly* inside a `select` (not stored in a variable), the runtime can detect that the timer will never be used if the other case wins, and cleans it up faster. But the timer is still not *canceled* — it just gets collected sooner. The recommendation remains: **always use `time.NewTimer` in loops.**\n\n---\n\n### 4.12.6 — Nil Channel Behavior: A Nil Case Is Never Selected\n\n**Start Simple: What Happens When You Receive From `nil`?**\n\n```go\nvar ch chan int // ch is nil\n\nv := \u003c-ch // this blocks forever\n```\n\nReceiving from a nil channel blocks forever. It never returns. No panic, no error — just permanent suspension.\n\nThe same is true for sends:\n\n```go\nvar ch chan int\nch \u003c- 1 // blocks forever\n```\n\n**Now Put a Nil Channel in a Select**\n\nHere's the key behavior: **a nil channel in a select case is simply ignored.** That case can never be selected.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    var ch1 chan int // nil\n    ch2 := make(chan int, 1)\n    ch2 \u003c- 42\n\n    select {\n    case v := \u003c-ch1: // ch1 is nil — this case is NEVER picked\n        fmt.Println(\"ch1:\", v)\n    case v := \u003c-ch2: // ch2 has data — this case runs\n        fmt.Println(\"ch2:\", v)\n    }\n}\n// Output: ch2: 42\n```\n\nThe nil case (`ch1`) is effectively invisible to the select. It's as if you never wrote it.\n\n**Why Is This Useful? Dynamic Case Disabling**\n\nThe real power is that you can **disable a case at runtime** by setting a channel variable to nil.\n\nHere's a small example to make this concrete:\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    ch := make(chan int, 3)\n    ch \u003c- 1\n    ch \u003c- 2\n    ch \u003c- 3\n    close(ch)\n\n    // We'll process ch until it's closed, then disable it\n    for ch != nil {\n        select {\n        case v, ok := \u003c-ch:\n            if !ok {\n                // Channel is closed\n                fmt.Println(\"channel closed, disabling case\")\n                ch = nil // ← set to nil: this case will never fire again\n                continue\n            }\n            fmt.Println(\"received:\", v)\n        }\n    }\n    fmt.Println(\"done\")\n}\n```\n\nOutput:\n```\nreceived: 1\nreceived: 2\nreceived: 3\nchannel closed, disabling case\ndone\n```\n\nWhen `ch` closes, we set it to `nil` so the case stops firing. Without this, the closed channel would fire infinitely with zero values (see 4.12.7 below).\n\n**The Full Example: Merging Two Channels**\n\nNow that you understand the primitive, here's the classic use case: merging two channels into one, handling each closing independently.\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc merge(ch1, ch2 \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n\n    go func() {\n        defer close(out)\n\n        // Keep looping as long as at least one channel is still open\n        for ch1 != nil || ch2 != nil {\n            select {\n            case v, ok := \u003c-ch1:\n                if !ok {\n                    ch1 = nil // ch1 closed → disable this case\n                    continue\n                }\n                out \u003c- v\n\n            case v, ok := \u003c-ch2:\n                if !ok {\n                    ch2 = nil // ch2 closed → disable this case\n                    continue\n                }\n                out \u003c- v\n            }\n        }\n        // Both nil → loop exits → defer close(out) fires\n    }()\n\n    return out\n}\n\nfunc main() {\n    ch1 := make(chan int, 2)\n    ch2 := make(chan int, 2)\n\n    ch1 \u003c- 1\n    ch1 \u003c- 2\n    close(ch1)\n\n    ch2 \u003c- 10\n    ch2 \u003c- 20\n    close(ch2)\n\n    for v := range merge(ch1, ch2) {\n        fmt.Println(v)\n    }\n}\n```\n\nOutput (order not guaranteed between channels, but all values appear):\n```\n1\n10\n2\n20\n```\n\n**Walk-Through of the State Machine**\n\n```\nStart:\n  ch1 = open   → case \u003c-ch1 is ACTIVE\n  ch2 = open   → case \u003c-ch2 is ACTIVE\n\nAfter ch1 closes (ok = false):\n  ch1 = nil    → case \u003c-ch1 is DISABLED forever\n  ch2 = open   → only case \u003c-ch2 runs\n\nAfter ch2 closes (ok = false):\n  ch1 = nil\n  ch2 = nil\n  → ch1 != nil || ch2 != nil is false → loop exits\n```\n\nWithout the nil trick: once ch1 closes, `case v, ok := \u003c-ch1` would fire on every iteration returning `(0, false)`. You'd have an infinite spin loop consuming CPU and flooding `out` with zeros.\n\n---\n\n### 4.12.7 — Closed Channel Behavior: Always Ready, Returns Zero Value\n\n**What Happens When You Receive From a Closed Channel?**\n\n```go\nch := make(chan int, 1)\nch \u003c- 42\nclose(ch)\n\nv, ok := \u003c-ch\nfmt.Println(v, ok) // 42 true  ← the buffered value first\n\nv, ok = \u003c-ch\nfmt.Println(v, ok) // 0 false  ← channel empty AND closed\n```\n\nTwo things to note:\n\n1. If there are buffered values, you get them first (with `ok = true`)\n2. Once all buffered values are drained, any further receive returns `(zero value, false)` immediately — it **does not block**\n\nThat last point is critical: receiving from an empty closed channel **never blocks**. It always succeeds immediately.\n\n**The Spin Bug**\n\nBecause a closed channel always returns immediately, putting it in a `for/select` loop without checking `ok` creates a CPU-burning infinite loop:\n\n```go\n// ❌ BAD — CPU SPIN LOOP\nch := make(chan int)\nclose(ch)\n\nfor {\n    select {\n    case v := \u003c-ch:\n        fmt.Println(\"Received:\", v) // prints \"Received: 0\" forever at max CPU\n    }\n}\n```\n\nThe channel is closed, so `\u003c-ch` is always ready. The select fires immediately, prints 0, loops back, fires again, prints 0... forever. This goroutine will consume 100% of a CPU core doing nothing useful.\n\n**The Fix: Always Check `ok`**\n\n```go\n// ✅ GOOD\nfor {\n    select {\n    case v, ok := \u003c-ch:\n        if !ok {\n            fmt.Println(\"Channel closed, exiting\")\n            return\n        }\n        fmt.Println(\"Received:\", v)\n    }\n}\n```\n\nWhen you detect `ok == false`, the channel is closed and drained. Exit.\n\n**Better Yet: Use `range` When You Can**\n\nWhen your entire loop purpose is to drain a channel until it closes, `range` is cleaner:\n\n```go\nfor v := range ch {\n    fmt.Println(\"Received:\", v)\n}\n// Loop exits automatically when ch is closed\n```\n\n`range` on a channel handles the `ok` check internally. When the channel closes, the range loop ends. Use `for/select` only when you need to listen to multiple channels simultaneously.\n\n---\n\n### 4.12.8 — Empty `select{}`: Blocking Forever on Purpose\n\n**What Is an Empty Select?**\n\n```go\nselect {}\n```\n\nThat's it. No cases. No default. A select statement with nothing inside it.\n\n**What Does It Do?**\n\nIt blocks the current goroutine **permanently**. Forever. The goroutine parks itself and never wakes up.\n\nThis does not panic. It does not exit. It just stops.\n\n**Why Is This Allowed? What Problem Does It Solve?**\n\nIn Go, `main()` exiting kills the entire program — including all goroutines that may still be running.\n\nConsider a program where all real work happens in background goroutines:\n\n```go\nfunc main() {\n    go webServer()        // handles HTTP requests\n    go metricsCollector() // sends metrics every 10s\n    go healthChecker()    // pings dependencies every 5s\n\n    // If main() returns here, ALL goroutines die instantly\n}\n```\n\nYou need main to stay alive forever. The naive approach is:\n\n```go\nfor {} // empty infinite loop\n```\n\nBut this burns 100% of a CPU core in a tight loop doing nothing.\n\n`select{}` solves this elegantly:\n\n```go\nfunc main() {\n    go webServer()\n    go metricsCollector()\n    go healthChecker()\n\n    select {} // ← park main forever, zero CPU cost\n}\n```\n\nThe goroutine is suspended by the scheduler. It uses no CPU. It just holds the program open.\n\n**What About the Deadlock Error?**\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    fmt.Println(\"Starting...\")\n    go func() {\n        fmt.Println(\"Goroutine running\")\n    }()\n    select {}\n}\n```\n\nOutput:\n```\nStarting...\nGoroutine running\nfatal error: all goroutines are asleep - deadlock!\n```\n\nGo's deadlock detector sees that *every* goroutine is blocked — the goroutine finished, and main is blocked on `select{}` — and panics. In a real server, your other goroutines never finish (they loop forever handling requests), so the deadlock detector won't trigger. The `select{}` in a toy program *will* trigger it once all work goroutines complete.\n\n**Why Not `time.Sleep(math.MaxInt64)`?**\n\nYou could, but `select{}` is the idiomatic Go way. It's cleaner and communicates intent: \"this goroutine intentionally parks itself forever.\"\n\n---\n\n### 4.12.9 — Priority Select: The Double-Select Trick\n\n***The Problem: Select Has No Built-In Priority***\n\nLet's say you're building a task processor. Some tasks are urgent (high priority), some can wait (low priority). You want high-priority tasks processed first whenever both queues have items.\n\nYour first instinct:\n\n```go\nselect {\ncase job := \u003c-highPri:\n    process(job)\ncase job := \u003c-lowPri:\n    process(job)\n}\n```\n\nBut as we learned in 4.12.3, when both channels are ready, Go picks randomly. Half the time, a low-priority job beats a high-priority one. That's not what you want.\n\n***Step 1: The Simple Non-Blocking Priority Check***\n\nWhat if you check high-priority first using `default`?\n\n```go\n// Try high priority first — don't block\nselect {\ncase job := \u003c-highPri:\n    process(job)\n    continue // ← handled, go to next iteration\ndefault:\n    // Nothing in highPri right now\n}\n\n// Only check lowPri if highPri was empty\nselect {\ncase job := \u003c-lowPri:\n    process(job)\n}\n```\n\nThis works, but there's a subtle problem: after the first select determines highPri is empty and falls to `default`, a high-priority item might arrive *before* the second select runs. The second select would then pick lowPri when a highPri item is waiting. You've introduced a race condition.\n\n***Step 2: The Correct Double-Select Pattern***\n\nThe real pattern uses a nested select:\n\n```go\n// Outer select: check highPri non-blockingly\nselect {\ncase job := \u003c-highPri:\n    process(job) // highPri had something → great, handle it\n\ndefault:\n    // highPri was empty at this instant.\n    // Now block on BOTH channels, but still prefer highPri\n    select {\n    case job := \u003c-highPri:  // check highPri again in case it got data\n        process(job)\n    case job := \u003c-lowPri:\n        process(job)\n    }\n}\n```\n\nWalk through the logic:\n\n**Case A: highPri has data**\n→ Outer select picks `case \u003c-highPri` immediately. Done. lowPri never considered.\n\n**Case B: highPri is empty**\n→ Outer select hits `default`. We fall into the inner select.\n→ Inner select blocks on both channels. Whoever sends next wins.\n→ If highPri gets data first, it wins. If lowPri gets data first, it wins.\n\nThe key win: in Case A, high-priority tasks are *always* processed before low-priority tasks when both are available. The outer `default` makes the highPri check instant with no blocking.\n\n***Small Working Example to Make It Concrete***\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n    highPri := make(chan string, 1)\n    lowPri := make(chan string, 1)\n\n    // Both channels have data\n    highPri \u003c- \"urgent task\"\n    lowPri \u003c- \"normal task\"\n\n    // Without double-select: random 50/50\n    // With double-select: highPri always wins when both are ready\n    select {\n    case job := \u003c-highPri:\n        fmt.Println(\"Processing:\", job)\n    default:\n        select {\n        case job := \u003c-highPri:\n            fmt.Println(\"Processing:\", job)\n        case job := \u003c-lowPri:\n            fmt.Println(\"Processing:\", job)\n        }\n    }\n}\n// Output: Processing: urgent task  ← always, not random\n```\n\nRun this 100 times — it always picks \"urgent task\" when highPri has data. That's the guarantee.\n\n***Full Example: Draining Both Queues with Priority***\n\nNow take the full example: 5 high-priority and 5 low-priority jobs, both queues pre-filled:\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc main() {\n    highPri := make(chan string, 10)\n    lowPri := make(chan string, 10)\n\n    for i := 0; i \u003c 5; i++ {\n        highPri \u003c- fmt.Sprintf(\"HIGH-%d\", i)\n        lowPri \u003c- fmt.Sprintf(\"LOW-%d\", i)\n    }\n\n    for i := 0; i \u003c 10; i++ {\n        select {\n        case job := \u003c-highPri:\n            fmt.Println(\"Processing:\", job)\n        default:\n            select {\n            case job := \u003c-highPri:\n                fmt.Println(\"Processing:\", job)\n            case job := \u003c-lowPri:\n                fmt.Println(\"Processing:\", job)\n            }\n        }\n        time.Sleep(10 * time.Millisecond)\n    }\n}\n```\n\nOutput:\n```\nProcessing: HIGH-0\nProcessing: HIGH-1\nProcessing: HIGH-2\nProcessing: HIGH-3\nProcessing: HIGH-4\nProcessing: LOW-0\nProcessing: LOW-1\nProcessing: LOW-2\nProcessing: LOW-3\nProcessing: LOW-4\n```\n\nAll 5 HIGH jobs drain first, even though LOW was also ready from the start.\n\n***Why Is It Not a Perfect Guarantee?***\n\nThe caveat: there's a tiny window between the outer `select` deciding highPri is empty and the inner `select` starting. In that window, highPri could get a new item — and lowPri might win the inner select by luck. For strict priority, you'd need a single priority queue (one channel where messages carry a priority field). The double-select pattern is a strong heuristic, not an absolute guarantee.\n\n---\n\n### 4.12.10 — The Canonical Cancellation Pattern (Done Channel)\n\n***What Does \"Canonical\" Mean Here?***\n\n\"Canonical\" means: this is the *standard, widely agreed-upon way* to do something in Go. It's the pattern you'll see in open-source Go code, the standard library, and production systems. When a Go developer sees a `done \u003c-chan struct{}` parameter, they immediately understand: \"this goroutine can be told to stop.\"\n\n***The Problem: Goroutines Run Forever Without a Kill Switch***\n\nA goroutine starts and runs until its function returns. If it's in an infinite loop waiting for work, it never returns on its own. You need a way to signal it from outside: \"please stop now.\"\n\n```go\nfunc worker(jobs \u003c-chan int) {\n    for {\n        job := \u003c-jobs // blocks forever waiting for jobs\n        process(job)\n    }\n    // How does this ever return? It doesn't, unless jobs closes.\n}\n```\n\nIf you just close the `jobs` channel, the worker stops getting work — but it's a blunt instrument that mixes two concerns: \"no more jobs\" and \"please shut down.\" What if you want to shut down mid-stream, even with jobs still in the queue?\n\n***The Done Channel***\n\nThe solution: pass a second channel, called `done`, whose sole purpose is to signal shutdown. The worker listens to *both* channels simultaneously using `select`:\n\n```go\nfunc worker(done \u003c-chan struct{}, jobs \u003c-chan int) {\n    for {\n        select {\n        case \u003c-done:\n            fmt.Println(\"Shutdown signal received, stopping\")\n            return // ← clean exit\n        case job := \u003c-jobs:\n            fmt.Println(\"Processing job:\", job)\n        }\n    }\n}\n```\n\nEvery iteration, the worker asks: \"Is there a shutdown signal? Or is there a job?\" Whichever arrives first gets handled. If shutdown arrives, it returns. If a job arrives, it processes it and loops back to ask again.\n\n***Why `chan struct{}`?***\n\n`struct{}` is an empty struct — it has zero size, so it allocates no memory. The channel carries no meaningful data; it's just a signal. You never care about *what* was sent, only *that* something was sent (or that the channel was closed).\n\n***Why `close(done)` Instead of `done \u003c- struct{}{}`?***\n\nThis is the key insight. Suppose you have 10 worker goroutines all listening to `done`:\n\n```go\ndone \u003c- struct{}{} // sends to ONE goroutine only\n```\n\nOnly one worker wakes up. The other 9 keep running.\n\n```go\nclose(done) // every goroutine blocked on \u003c-done wakes up simultaneously\n```\n\nClosing a channel broadcasts to all listeners. One `close()` shuts down all 10 workers at once. This is the broadcast mechanism Go provides.\n\n***Full Example Walk-Through***\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc worker(done \u003c-chan struct{}, jobs \u003c-chan int) {\n    for {\n        select {\n        case \u003c-done:\n            fmt.Println(\"Worker: shutdown signal received\")\n            return\n        case job := \u003c-jobs:\n            fmt.Printf(\"Worker: processing job %d\\n\", job)\n            time.Sleep(100 * time.Millisecond)\n        }\n    }\n}\n\nfunc main() {\n    done := make(chan struct{})\n    jobs := make(chan int, 5)\n\n    go worker(done, jobs) // start one worker\n\n    // Send 3 jobs\n    jobs \u003c- 1\n    jobs \u003c- 2\n    jobs \u003c- 3\n\n    time.Sleep(500 * time.Millisecond) // let worker process them\n\n    fmt.Println(\"Main: sending shutdown signal\")\n    close(done) // ← broadcast to all workers\n\n    time.Sleep(100 * time.Millisecond) // let worker print its goodbye\n    fmt.Println(\"Main: exiting\")\n}\n```\n\nOutput:\n```\nWorker: processing job 1\nWorker: processing job 2\nWorker: processing job 3\nMain: sending shutdown signal\nWorker: shutdown signal received\nMain: exiting\n```\n\nStep by step:\n1. Worker starts, blocks in `select` waiting for jobs or done\n2. Main sends 3 jobs into the buffered channel\n3. Worker processes each job (taking ~100ms each), looping back to select each time\n4. After 500ms, main closes `done`\n5. Worker's next `select` iteration sees `\u003c-done` is ready, returns\n6. Main waits 100ms and exits\n\n***The Production Version: `context.Context`***\n\nIn real Go services, you'd use `context.Context` instead of a raw done channel:\n\n```go\nfunc worker(ctx context.Context, jobs \u003c-chan int) {\n    for {\n        select {\n        case \u003c-ctx.Done():\n            fmt.Println(\"Context canceled:\", ctx.Err())\n            return\n        case job := \u003c-jobs:\n            process(job)\n        }\n    }\n}\n```\n\n`ctx.Done()` is just a channel under the hood — it returns `\u003c-chan struct{}`. It closes when the context is canceled (via timeout, deadline, or explicit cancel). `context` adds useful extras like cancellation reasons (`ctx.Err()`) and propagation through a call chain. But the select pattern is identical — it's the same done-channel idiom, just with more infrastructure around it.\n\n\u003e **Summary of the \"canonical\" part:** Every long-running goroutine in production Go takes either a `done \u003c-chan struct{}` or a `ctx context.Context`. It uses select to listen for that shutdown signal alongside its actual work. It returns cleanly when signaled. This is the canonical pattern because it's safe, composable, and follows Go's design philosophy of explicit, channel-based coordination.\n\n### 4.12.11: Select Gotchas Cheat Sheet (6 Common Mistakes with Fixes)\n\n#### Gotcha 1: `time.After` in Loop (Memory Leak)\n\n```go\n// ❌ BAD\nfor {\n    select {\n    case \u003c-messages:\n        process()\n    case \u003c-time.After(1 * time.Second):\n        cleanup()\n    }\n}\n```\n\n**Fix:** Use `time.NewTimer` outside the loop.\n\n```go\n// ✅ GOOD\ntimer := time.NewTimer(1 * time.Second)\ndefer timer.Stop()\nfor {\n    select {\n    case \u003c-messages:\n        process()\n        timer.Reset(1 * time.Second)\n    case \u003c-timer.C:\n        cleanup()\n        timer.Reset(1 * time.Second)\n    }\n}\n```\n\n---\n\n#### Gotcha 2: Assuming Case Order Matters\n\n```go\n// ❌ Developer thinks: \"ch1 is checked first, then ch2\"\nselect {\ncase v := \u003c-ch1:\n    fmt.Println(\"ch1:\", v)\ncase v := \u003c-ch2:\n    fmt.Println(\"ch2:\", v)\n}\n```\n\n**Reality:** If both are ready, selection is **random**.\n\n**Fix:** If order matters, don't use `select`. Use explicit sequencing or the double-select priority pattern.\n\n---\n\n#### Gotcha 3: Closed Channel Spin in `for/select`\n\n```go\n// ❌ BAD\nfor {\n    select {\n    case v := \u003c-ch:\n        fmt.Println(v) // After ch closes, prints 0 forever!\n    }\n}\n```\n\n**Fix:** Check `ok`:\n\n```go\n// ✅ GOOD\nfor {\n    select {\n    case v, ok := \u003c-ch:\n        if !ok {\n            return\n        }\n        fmt.Println(v)\n    }\n}\n```\n\n---\n\n#### Gotcha 4: Default Case Creating Busy Loop\n\n```go\n// ❌ BAD — 100% CPU!\nfor {\n    select {\n    case v := \u003c-ch:\n        process(v)\n    default:\n        // Empty default = tight loop\n    }\n}\n```\n\n**Fix:** Remove `default` or do actual work in it:\n\n```go\n// ✅ GOOD\nfor {\n    select {\n    case v := \u003c-ch:\n        process(v)\n    default:\n        time.Sleep(10 * time.Millisecond) // Throttle\n        // Or do other useful work\n    }\n}\n```\n\n---\n\n#### Gotcha 5: Forgetting `ok` Check on Receive\n\n```go\n// ❌ BAD\nselect {\ncase v := \u003c-ch:\n    // If ch is closed, v is zero value — might be valid data!\n    process(v)\n}\n```\n\n**Fix:**\n\n```go\n// ✅ GOOD\nselect {\ncase v, ok := \u003c-ch:\n    if !ok {\n        // Channel closed\n        return\n    }\n    process(v)\n}\n```\n\n---\n\n#### Gotcha 6: Empty `select{}` in Wrong Context\n\n```go\n// ❌ Thinking this \"yields\" to other goroutines\nfunc worker() {\n    for {\n        doWork()\n        select {} // WRONG: This blocks forever!\n    }\n}\n```\n\n**Fix:** Use `runtime.Gosched()` if you want to yield (rarely needed), or just don't do anything — Go's scheduler preempts automatically since Go 1.14.\n\n---\n\n### 4.12.12: Exercises — 5 Select Problems\n\n#### Exercise 1: Basic Fan-In (Beginner)\n\n**Problem:** Merge two input channels into one output channel using `select`.\n\n**Signature:**\n\n```go\nfunc merge(ch1, ch2 \u003c-chan int) \u003c-chan int\n```\n\n**Expected Behavior:**\n\n```go\nc1 := make(chan int, 2)\nc2 := make(chan int, 2)\n\nc1 \u003c- 1\nc1 \u003c- 2\nclose(c1)\n\nc2 \u003c- 10\nc2 \u003c- 20\nclose(c2)\n\nfor v := range merge(c1, c2) {\n    fmt.Println(v) // Prints: 1, 2, 10, 20 (order not guaranteed)\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nUse `select` to receive from both channels. Set channels to `nil` when they close to disable those cases.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\nfunc merge(ch1, ch2 \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n\n    go func() {\n        defer close(out)\n\n        for ch1 != nil || ch2 != nil {\n            select {\n            case v, ok := \u003c-ch1:\n                if !ok {\n                    ch1 = nil\n                    continue\n                }\n                out \u003c- v\n            case v, ok := \u003c-ch2:\n                if !ok {\n                    ch2 = nil\n                    continue\n                }\n                out \u003c- v\n            }\n        }\n    }()\n\n    return out\n}\n```\n\n**How It Works:**\n\n```\nLoop continues while at least one channel is non-nil.\n\nselect waits on both ch1 and ch2.\n  - Whichever is ready first, we receive from it.\n  - If ok=false (channel closed), set that channel variable to nil.\n  - Setting to nil disables that case in future iterations.\n\nOnce both channels are nil, the loop exits and we close(out).\n```\n\n\u003c/details\u003e\n\n---\n\n#### Exercise 2: Timeout Wrapper (Intermediate)\n\n**Problem:** Wrap a slow function with a 2-second timeout. Must prevent goroutine leak if timeout fires.\n\n**Signature:**\n\n```go\nfunc fetchWithTimeout(url string) (string, error)\n```\n\n**Simulate a slow fetch:**\n\n```go\nfunc simulateFetch(url string) string {\n    time.Sleep(3 * time.Second) // Always slow\n    return \"data from \" + url\n}\n```\n\n**Expected:**\n\n```go\nresult, err := fetchWithTimeout(\"http://example.com\")\nif err != nil {\n    fmt.Println(\"Error:\", err) // Should print \"timeout\"\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nUse a **buffered channel of size 1** for the result. If the timeout case wins, the goroutine can still send without blocking (preventing leak).\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\nfunc fetchWithTimeout(url string) (string, error) {\n    resultCh := make(chan string, 1) // ← Buffer prevents leak!\n\n    go func() {\n        result := simulateFetch(url)\n        resultCh \u003c- result // If timeout already fired, this sends to buffer and goroutine exits\n    }()\n\n    select {\n    case result := \u003c-resultCh:\n        return result, nil\n    case \u003c-time.After(2 * time.Second):\n        return \"\", errors.New(\"timeout\")\n    }\n}\n```\n\n**How It Works:**\n\n```\nScenario A: Fetch completes in 1s (\u003c 2s timeout)\n  ─ Goroutine sends to resultCh at 1s\n  ─ select receives from resultCh\n  ─ Returns result, nil\n\nScenario B: Fetch completes in 3s (\u003e 2s timeout)\n  ─ At 2s: time.After fires, select returns \"\", error(\"timeout\")\n  ─ At 3s: Goroutine finishes, sends to resultCh → buffer absorbs it\n  ─ Goroutine exits cleanly ✅\n\nWithout buffer: goroutine blocks forever on send (nobody receiving) → LEAK ❌\n```\n\n\u003c/details\u003e\n\n---\n\n#### Exercise 3: Non-Blocking Operations (Beginner)\n\n**Problem:** Implement `TryReceive` and `TrySend` using `select` with `default`.\n\n**Signatures:**\n\n```go\nfunc TryReceive(ch \u003c-chan int) (int, bool) // Returns (value, ok)\nfunc TrySend(ch chan\u003c- int, value int) bool // Returns true if sent\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\nfunc TryReceive(ch \u003c-chan int) (int, bool) {\n    select {\n    case v := \u003c-ch:\n        return v, true\n    default:\n        return 0, false\n    }\n}\n\nfunc TrySend(ch chan\u003c- int, value int) bool {\n    select {\n    case ch \u003c- value:\n        return true\n    default:\n        return false\n    }\n}\n```\n\n**Usage:**\n\n```go\nch := make(chan int, 1)\n\n// TrySend\nif TrySend(ch, 42) {\n    fmt.Println(\"Sent 42\")\n} else {\n    fmt.Println(\"Channel full\")\n}\n\n// TryReceive\nif v, ok := TryReceive(ch); ok {\n    fmt.Println(\"Received:\", v)\n} else {\n    fmt.Println(\"Channel empty\")\n}\n```\n\n\u003c/details\u003e\n\n---\n\n#### Exercise 4: Cancellable Worker (Intermediate)\n\n**Problem:** A worker that processes jobs and stops when `done` is closed.\n\n```go\nfunc worker(done \u003c-chan struct{}, jobs \u003c-chan int)\n```\n\n**Expected:**\n\n```go\ndone := make(chan struct{})\njobs := make(chan int, 10)\n\ngo worker(done, jobs)\n\njobs \u003c- 1\njobs \u003c- 2\nclose(done) // Worker should exit gracefully\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\nfunc worker(done \u003c-chan struct{}, jobs \u003c-chan int) {\n    for {\n        select {\n        case \u003c-done:\n            fmt.Println(\"Worker: shutting down\")\n            return\n        case job := \u003c-jobs:\n            fmt.Printf(\"Worker: processing job %d\\n\", job)\n            time.Sleep(100 * time.Millisecond)\n        }\n    }\n}\n```\n\n**How It Works:**\n\n```\nEach iteration, select waits on:\n  - done channel (for shutdown signal)\n  - jobs channel (for work)\n\nWhichever is ready first, that case executes.\n\nWhen done is closed:\n  - \u003c-done becomes immediately ready\n  - Worker prints shutdown message and returns\n  - Goroutine exits cleanly\n```\n\n\u003c/details\u003e\n\n---\n\n#### Exercise 5: Priority Select (Advanced)\n\n**Problem:** Process high-priority jobs before low-priority jobs using the double-select trick.\n\n**Signatures:**\n\n```go\nfunc priorityProcessor(highPri, lowPri \u003c-chan string)\n```\n\n**Expected:**\n\n```go\nhighPri := make(chan string, 5)\nlowPri := make(chan string, 5)\n\nhighPri \u003c- \"HIGH-1\"\nhighPri \u003c- \"HIGH-2\"\nlowPri \u003c- \"LOW-1\"\nlowPri \u003c- \"LOW-2\"\n\ngo priorityProcessor(highPri, lowPri)\n\n// Should process HIGH-1, HIGH-2 before LOW-1, LOW-2\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\nfunc priorityProcessor(highPri, lowPri \u003c-chan string) {\n    for {\n        select {\n        case job := \u003c-highPri:\n            fmt.Println(\"Processing:\", job)\n        default:\n            select {\n            case job := \u003c-highPri:\n                fmt.Println(\"Processing:\", job)\n            case job := \u003c-lowPri:\n                fmt.Println(\"Processing:\", job)\n            }\n        }\n    }\n}\n```\n\n**How It Works:**\n\n```\nOuter select with default:\n  - If highPri is ready → process immediately (priority respected)\n  - If highPri is NOT ready → fall to default\n\nInner select (no default):\n  - Blocks on BOTH highPri and lowPri\n  - If highPri becomes ready first → process highPri\n  - If lowPri becomes ready first → process lowPri\n\nThis ensures highPri is ALWAYS checked before blocking on lowPri.\n```\n\n\u003c/details\u003e\n\n---\n\n## Section 4.13: sync.Once — One-Time Initialization\n\n### 4.13.1: The Problem — Multiple Goroutines Racing to Initialize a Singleton\n\n**Scenario:** You have a database connection pool that's expensive to initialize. Multiple goroutines call `GetDB()` at startup. You want the pool initialized exactly once.\n\n**Broken Approach #1 — No Synchronization:**\n\n```go\nvar db *sql.DB\n\nfunc GetDB() *sql.DB {\n    if db == nil {\n        db = initDB() // ❌ RACE CONDITION!\n    }\n    return db\n}\n```\n\n**Race Detector Output:**\n\n```\nWARNING: DATA RACE\nWrite at 0x... by goroutine 7:\n  main.GetDB()\nPrevious write at 0x... by goroutine 6:\n  main.GetDB()\n```\n\nMultiple goroutines all see `db == nil` and **all** call `initDB()`. The database connects multiple times, and the race detector screams.\n\n---\n\n### 4.13.2: Broken Approaches (Mutex + Bool Flag, Double-Check Without Atomic)\n\n**Broken Approach #2 — Mutex Every Time (Slow):**\n\n```go\nvar (\n    db *sql.DB\n    mu sync.Mutex\n)\n\nfunc GetDB() *sql.DB {\n    mu.Lock()\n    defer mu.Unlock()\n    if db == nil {\n        db = initDB()\n    }\n    return db\n}\n```\n\n**This works**, but every call to `GetDB()` (even after initialization) acquires the mutex. At 100,000 calls/second, that's 100,000 mutex acquisitions for no reason.\n\n---\n\n**Broken Approach #3 — Double-Checked Locking (Wrong in Go):**\n\n```go\nvar (\n    db *sql.DB\n    mu sync.Mutex\n)\n\nfunc GetDB() *sql.DB {\n    if db == nil { // ❌ First check without lock\n        mu.Lock()\n        if db == nil {\n            db = initDB()\n        }\n        mu.Unlock()\n    }\n    return db\n}\n```\n\n**This is broken under the Go memory model.** The outer `if db == nil` is a **non-synchronized read**. Even after `initDB()` writes to `db`, other goroutines may not see the updated value due to CPU caching and reordering. This is the classic \"double-checked locking is broken\" bug.\n\nThe fix requires `atomic.LoadPointer` for the first check, at which point you're reimplementing `sync.Once`.\n\n---\n\n### 4.13.3: sync.Once to the Rescue (5 Lines of Code)\n\n```go\nvar (\n    db   *sql.DB\n    once sync.Once\n)\n\nfunc GetDB() *sql.DB {\n    once.Do(func() {\n        db = initDB()\n    })\n    return db\n}\n```\n\n**That's it.** Five lines. Thread-safe, fast, correct.\n\n**Guarantees:**\n- `initDB()` is called **exactly once**, even if 1,000 goroutines call `GetDB()` simultaneously\n- All goroutines see the effects of `initDB()` (memory barrier)\n- After first call, overhead is a single atomic load (fast)\n\n---\n\n### 4.13.4: How It Works Internally (Atomic Fast-Path + Mutex Slow-Path, Why CAS Alone Is Wrong)\n\nHere's the **actual** `sync.Once` implementation from `go/src/sync/once.go`:\n\n```go\ntype Once struct {\n    done uint32\n    m    Mutex\n}\n\nfunc (o *Once) Do(f func()) {\n    if atomic.LoadUint32(\u0026o.done) == 0 { // ← Fast path\n        o.doSlow(f)\n    }\n}\n\nfunc (o *Once) doSlow(f func()) {\n    o.m.Lock()\n    defer o.m.Unlock()\n    if o.done == 0 {\n        defer atomic.StoreUint32(\u0026o.done, 1)\n        f()\n    }\n}\n```\n\n**The Two-Phase Design:**\n\n**Phase 1 — Fast Path (After First Call):**\n```\nif atomic.LoadUint32(\u0026o.done) == 0 → false, return immediately\n```\n\nThis is an **inlined atomic load**, typically 1-2 CPU cycles. Near-zero overhead.\n\n**Phase 2 — Slow Path (First Call Only):**\n```\n1. Acquire mutex (serializes all first callers)\n2. Double-check o.done == 0 (in case another goroutine won the race)\n3. defer atomic.StoreUint32(\u0026o.done, 1) ← Mark done AFTER f() completes\n4. Call f()\n```\n\n**Why `defer` for `atomic.StoreUint32`?**\n\nEnsures `done=1` is set **after** `f()` completes, even if `f()` panics. Otherwise, if `f()` panics and `done` is already set, subsequent calls would see `done=1` and skip initialization entirely.\n\n**Why CAS (Compare-And-Swap) Alone Is Wrong:**\n\nSomeone might think: \"Just use `atomic.CompareAndSwapUint32(\u0026o.done, 0, 1)` and skip the mutex!\"\n\n```go\n// ❌ BROKEN\nfunc (o *Once) Do(f func()) {\n    if atomic.CompareAndSwapUint32(\u0026o.done, 0, 1) {\n        f()\n    }\n}\n```\n\n**The Bug:**\n\n```\nTimeline:\n  T=0: Goroutine A: CAS succeeds, starts f()\n  T=1: Goroutine B: CAS fails (done=1), returns immediately\n  T=2: Goroutine A: f() is still running...\n  T=3: Goroutine B: uses db ← db IS NOT INITIALIZED YET!\n```\n\nGoroutine B sees `done=1` and assumes initialization is complete, but it's not. The CAS happens when `f()` **starts**, not when it **finishes**.\n\nThe mutex + defer pattern ensures `done=1` is set only **after** `f()` completes, and the mutex ensures all goroutines see the completed initialization before the first goroutine releases the lock.\n\n---\n\n### 4.13.5: sync.OnceValue and sync.OnceFunc (Go 1.21+)\n\nGo 1.21 added three convenience wrappers to reduce boilerplate.\n\n#### `sync.OnceFunc`\n\nWraps a function so it runs exactly once:\n\n```go\nfunc expensiveSetup() {\n    fmt.Println(\"Setting up...\")\n    time.Sleep(1 * time.Second)\n}\n\nfunc main() {\n    setupOnce := sync.OnceFunc(expensiveSetup)\n\n    for i := 0; i \u003c 5; i++ {\n        go setupOnce() // Only one goroutine actually runs expensiveSetup()\n    }\n\n    time.Sleep(2 * time.Second)\n}\n```\n\n**Output:**\n```\nSetting up...\n```\n\nOnly prints once, despite 5 calls.\n\n---\n\n#### `sync.OnceValue`\n\nCaches a return value:\n\n```go\nfunc loadConfig() string {\n    fmt.Println(\"Loading config...\")\n    time.Sleep(1 * time.Second)\n    return \"config-data\"\n}\n\nfunc main() {\n    getConfig := sync.OnceValue(loadConfig)\n\n    for i := 0; i \u003c 5; i++ {\n        go func() {\n            config := getConfig() // All goroutines get the same cached result\n            fmt.Println(\"Got config:\", config)\n        }()\n    }\n\n    time.Sleep(2 * time.Second)\n}\n```\n\n**Output:**\n```\nLoading config...\nGot config: config-data\nGot config: config-data\nGot config: config-data\nGot config: config-data\nGot config: config-data\n```\n\n`loadConfig()` runs once, the result is cached, all callers get the cached value.\n\n---\n\n#### `sync.OnceValues`\n\nCaches two return values (useful for the `(T, error)` pattern):\n\n```go\nfunc connectDB() (*sql.DB, error) {\n    fmt.Println(\"Connecting to DB...\")\n    time.Sleep(1 * time.Second)\n    return \u0026sql.DB{}, nil\n}\n\nfunc main() {\n    getDB := sync.OnceValues(connectDB)\n\n    for i := 0; i \u003c 5; i++ {\n        go func() {\n            db, err := getDB()\n            if err != nil {\n                fmt.Println(\"Error:\", err)\n            } else {\n                fmt.Println(\"Got DB:\", db)\n            }\n        }()\n    }\n\n    time.Sleep(2 * time.Second)\n}\n```\n\nBoth `db` and `err` are cached.\n\n**When to Use Which:**\n\n| Pattern | Use |\n|---------|-----|\n| `sync.Once` | Need full control, side effects in `f()` |\n| `sync.OnceFunc` | Void function, no return value |\n| `sync.OnceValue[T]` | Cache single return value |\n| `sync.OnceValues[T, U]` | Cache `(result, error)` pair |\n\n---\n\n### 4.13.6: Key Gotchas\n\n#### Gotcha 1: Recursive Do Deadlocks\n\n```go\n// ❌ DEADLOCK!\nvar once sync.Once\n\nfunc recursive() {\n    once.Do(func() {\n        fmt.Println(\"First call\")\n        recursive() // ← Deadlock here\n    })\n}\n```\n\n**What Happens:**\n\n```\n1. First call: once.Do acquires mutex, starts f()\n2. f() calls recursive() again\n3. Second call: once.Do sees done=0, tries to acquire mutex\n4. Mutex is already held by the SAME goroutine → deadlock\n```\n\nGo's mutexes are **not reentrant**. Calling `Do()` from within `Do()` deadlocks.\n\n**Fix:** Don't call `Do()` recursively.\n\n---\n\n#### Gotcha 2: No Retry on Error\n\n```go\nvar (\n    db   *sql.DB\n    once sync.Once\n)\n\nfunc GetDB() (*sql.DB, error) {\n    var err error\n    once.Do(func() {\n        db, err = sql.Open(\"postgres\", \"...\")\n        if err != nil {\n            fmt.Println(\"DB init failed:\", err)\n            // ← init is still marked \"done\" even though it failed!\n        }\n    })\n    return db, err\n}\n```\n\n**The Problem:**\n\nIf `sql.Open()` fails, `once.Do()` still marks initialization as complete. Future calls to `GetDB()` skip initialization entirely and return `nil, nil` (or whatever `db` and `err` were left as).\n\n**Fix — Use `sync.OnceValues` and Panic:**\n\n```go\ngetDB := sync.OnceValues(func() (*sql.DB, error) {\n    db, err := sql.Open(\"postgres\", \"...\")\n    if err != nil {\n        panic(\"DB init failed: \" + err.Error())\n    }\n    return db, nil\n})\n```\n\nOr handle the error at a higher level and don't use `Once` for fallible initialization.\n\n---\n\n#### Gotcha 3: Don't Copy Once\n\n```go\nfunc setup(o sync.Once) { // ❌ Passed by value!\n    o.Do(func() {\n        fmt.Println(\"Setting up\")\n    })\n}\n\nfunc main() {\n    var once sync.Once\n    setup(once) // Copies once\n    setup(once) // Copies once again\n}\n```\n\n**Output:**\n```\nSetting up\nSetting up\n```\n\nEach `setup()` call gets a **copy** of `once` with `done=0`. Both copies independently call `f()`.\n\n**Fix:** Always pass `sync.Once` by pointer:\n\n```go\nfunc setup(o *sync.Once) { // ✅ Pointer\n    o.Do(func() {\n        fmt.Println(\"Setting up\")\n    })\n}\n\nfunc main() {\n    var once sync.Once\n    setup(\u0026once)\n    setup(\u0026once)\n}\n```\n\n**Output:**\n```\nSetting up\n```\n\nThe `go vet` tool catches this:\n\n```\ngo vet: call of setup copies lock value: sync.Once contains sync.Mutex\n```\n\n---\n\n#### Gotcha 4: Different Functions on Same Once\n\n```go\nvar once sync.Once\n\nfunc main() {\n    once.Do(func() { fmt.Println(\"First\") })\n    once.Do(func() { fmt.Println(\"Second\") })\n}\n```\n\n**Output:**\n```\nFirst\n```\n\n**Only** the first function runs. The second `Do()` sees `done=1` and returns immediately without calling `f()`.\n\n`sync.Once` is bound to the **instance**, not the function. Once `done=1`, that instance never runs any function again.\n\n---\n\n### 4.13.7: When to Use sync.Once vs init() vs Package-Level Vars\n\n| Pattern | Use When | Example |\n|---------|----------|---------|\n| **Package-level var** | Initialization is cheap and always needed | `var logger = log.New(...)` |\n| **`init()` function** | Must run before `main()`, no parameters needed | `func init() { flag.Parse() }` |\n| **`sync.Once`** | Expensive or conditional initialization, deferred until first use | Lazy DB connection, config loading on first request |\n\n**Decision Tree:**\n\n```\nIs initialization always needed at startup?\n  └─ YES → Package-level var or init()\n  └─ NO → sync.Once\n\nIs initialization cheap (\u003c1ms)?\n  └─ YES → Package-level var\n  └─ NO → sync.Once\n\nDo you need parameters for initialization?\n  └─ YES → sync.Once (wrap in closure)\n  └─ NO → init() or sync.Once\n```\n\n**Example — Lazy Logger:**\n\n```go\n// ❌ BAD: Initialized even if never used\nvar logger = createLogger(\"/tmp/app.log\")\n\n// ✅ GOOD: Initialized only when first needed\nvar (\n    logger     *Logger\n    loggerOnce sync.Once\n)\n\nfunc GetLogger() *Logger {\n    loggerOnce.Do(func() {\n        logger = createLogger(\"/tmp/app.log\")\n    })\n    return logger\n}\n```\n\n---\n\n## Section 4.14: When to Use Channels\n\n### The Decision Framework\n\n```\nIs it about COORDINATION between goroutines?\n    YES → Channels\n    NO → Is it about protecting SHARED STATE?\n          YES → Mutex\n          NO → Is it a simple counter/flag?\n                YES → Atomic\n                NO → Maybe you don't need concurrency!\n```\n\n### Use Channels When...\n\n **Passing ownership** of data\n```go\n// Worker owns the data after receiving\nfunc worker(jobs \u003c-chan Job) {\n    for job := range jobs {\n        // I own job now, safe to modify\n        job.Process()\n    }\n}\n```\n\n **Distributing work** to multiple goroutines\n```go\n// Fan-out: multiple workers\nfor i := 0; i \u003c numWorkers; i++ {\n    go worker(jobs)\n}\n```\n\n **Signaling events**\n```go\ndone := make(chan struct{})\ngo func() {\n    doWork()\n    close(done) // Signal completion\n}()\n\u003c-done // Wait for signal\n```\n\n **Building pipelines**\n```go\nstage1 := generate()\nstage2 := process(stage1)\nstage3 := aggregate(stage2)\n```\n\n **Implementing timeouts**\n```go\nselect {\ncase result := \u003c-ch:\n    // Got result\ncase \u003c-time.After(5 * time.Second):\n    // Timeout!\n}\n```\n\n### Use Mutex When...\n\n **Protecting shared state** that multiple goroutines access\n```go\n// Shared cache\ntype Cache struct {\n    mu sync.RWMutex\n    items map[string]Item\n}\n\nfunc (c *Cache) Get(key string) Item {\n    c.mu.RLock()\n    defer c.mu.RUnlock()\n    return c.items[key]\n}\n```\n\n **Short critical sections**\n```go\nmu.Lock()\ncounter++\nmu.Unlock()\n```\n\n **High-frequency operations**\n```go\n// Updating metrics thousands of times per second\nmu.Lock()\nmetrics[key]++\nmu.Unlock()\n```\n\n### The Go Proverb\n\n\u003e \"Don't communicate by sharing memory; share memory by communicating.\"\n\n**What this means**:\n\n**Sharing memory** (mutex approach):\n```go\nvar shared int\nvar mu sync.Mutex\n\ngo func() {\n    mu.Lock()\n    shared++\n    mu.Unlock()\n}()\n```\n\n**Communicating** (channel approach):\n```go\nch := make(chan int)\n\ngo func() {\n    ch \u003c- 1 // \"Here's a value for you\"\n}()\n\nvalue := \u003c-ch // \"Thanks, I'll take it\"\n```\n\n**But don't be dogmatic!** Sometimes mutexes are simpler and faster.\n\n### Real-World Examples\n\n**Use channels**:\n- HTTP request router distributing to worker goroutines\n- Log aggregation pipeline\n- Task queue with multiple consumers\n- Event notification system\n\n**Use mutexes**:\n- Shared cache (frequent reads, occasional writes)\n- Connection pool\n- Metrics counters\n- In-memory database index\n\n### Dave Cheney's Wisdom\n\n\u003e \"I tried to use channels for everything—if you want to talk about worst code, that's my worst code.\"\n\n**Lesson**: Channels are powerful, but not a hammer for every nail!\n\n**Choose the right tool**:\n- Complex coordination → Channels\n- Simple shared state → Mutex\n- Just counting → Atomic\n\n---\n\n## Section 4.15: Common Channel Patterns\n\n### Pattern 1: Producer-Consumer\n\n**One producer, one consumer**:\n\n```go\nfunc producer(out chan\u003c- int) {\n    defer close(out)\n    for i := 0; i \u003c 10; i++ {\n        out \u003c- i\n    }\n}\n\nfunc consumer(in \u003c-chan int) {\n    for v := range in {\n        fmt.Println(\"Consumed:\", v)\n    }\n}\n\nfunc main() {\n    ch := make(chan int, 5)\n    go producer(ch)\n    consumer(ch)\n}\n```\n\n**When to use**: Single data source, single processor.\n\n### Pattern 2: Pipeline\n\n**Chain of processing stages**:\n\n```go\nfunc gen(nums ...int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for _, n := range nums {\n            out \u003c- n\n        }\n    }()\n    return out\n}\n\nfunc square(in \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for n := range in {\n            out \u003c- n * n\n        }\n    }()\n    return out\n}\n\nfunc main() {\n    // Pipeline: gen → square → square\n    for n := range square(square(gen(2, 3))) {\n        fmt.Println(n) // 16, 81\n    }\n}\n```\n\n**When to use**: Sequential transformations, each step can run concurrently.\n\n### Pattern 3: Fan-Out (Multiple Workers)\n\n**Distribute work to multiple goroutines**:\n\n```go\nfunc worker(id int, jobs \u003c-chan int, results chan\u003c- int) {\n    for j := range jobs {\n        fmt.Printf(\"Worker %d processing %d\\n\", id, j)\n        results \u003c- j * 2\n    }\n}\n\nfunc main() {\n    jobs := make(chan int, 100)\n    results := make(chan int, 100)\n\n    // Start 3 workers\n    for w := 1; w \u003c= 3; w++ {\n        go worker(w, jobs, results)\n    }\n\n    // Send 9 jobs\n    for j := 1; j \u003c= 9; j++ {\n        jobs \u003c- j\n    }\n    close(jobs)\n\n    // Collect results\n    for a := 1; a \u003c= 9; a++ {\n        \u003c-results\n    }\n}\n```\n\n**When to use**: Parallelize I/O or CPU work across multiple cores.\n\n### Pattern 4: Fan-In (Merge Multiple Channels)\n\n**Combine multiple channels into one**:\n\n```go\nfunc merge(cs ...\u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    var wg sync.WaitGroup\n\n    output := func(c \u003c-chan int) {\n        defer wg.Done()\n        for n := range c {\n            out \u003c- n\n        }\n    }\n\n    wg.Add(len(cs))\n    for _, c := range cs {\n        go output(c)\n    }\n\n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n\n    return out\n}\n\n// Usage:\nch1 := gen(2, 3)\nch2 := gen(4, 5)\nfor v := range merge(ch1, ch2) {\n    fmt.Println(v) // 2, 3, 4, 5 (order varies)\n}\n```\n\n**When to use**: Collecting results from multiple sources.\n\n### Pattern 5: Worker Pool\n\n**Fixed number of workers, bounded concurrency**:\n\n```go\nfunc worker(id int, jobs \u003c-chan int, results chan\u003c- int) {\n    for j := range jobs {\n        fmt.Printf(\"Worker %d started job %d\\n\", id, j)\n        time.Sleep(time.Second) // Simulate work\n        fmt.Printf(\"Worker %d finished job %d\\n\", id, j)\n        results \u003c- j * 2\n    }\n}\n\nfunc main() {\n    const numJobs = 5\n    jobs := make(chan int, numJobs)\n    results := make(chan int, numJobs)\n\n    // Start 3 workers (controls max concurrency)\n    for w := 1; w \u003c= 3; w++ {\n        go worker(w, jobs, results)\n    }\n\n    // Send jobs\n    for j := 1; j \u003c= numJobs; j++ {\n        jobs \u003c- j\n    }\n    close(jobs)\n\n    // Collect results\n    for a := 1; a \u003c= numJobs; a++ {\n        \u003c-results\n    }\n}\n```\n\n**When to use**: Need to limit concurrency (database connections, API rate limits).\n\n### Pattern 6: Done Channel\n\n**Broadcast termination to multiple goroutines**:\n\n```go\nfunc worker(done \u003c-chan struct{}, id int) {\n    for {\n        select {\n        case \u003c-done:\n            fmt.Printf(\"Worker %d: shutting down\\n\", id)\n            return\n        default:\n            fmt.Printf(\"Worker %d: working...\\n\", id)\n            time.Sleep(500 * time.Millisecond)\n        }\n    }\n}\n\nfunc main() {\n    done := make(chan struct{})\n\n    // Start workers\n    for i := 1; i \u003c= 3; i++ {\n        go worker(done, i)\n    }\n\n    time.Sleep(2 * time.Second)\n\n    // Signal all workers to stop\n    close(done) // Broadcast!\n\n    time.Sleep(1 * time.Second)\n}\n```\n\n**When to use**: Graceful shutdown, cancellation.\n\n### Exercise 4.9: Implement a Pattern\n\n**Task**: Create a pipeline that:\n1. Generates numbers 1-10\n2. Doubles them\n3. Filters out numbers \u003c 10\n4. Prints the results\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc generate() \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for i := 1; i \u003c= 10; i++ {\n            out \u003c- i\n        }\n    }()\n    return out\n}\n\nfunc double(in \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for v := range in {\n            out \u003c- v * 2\n        }\n    }()\n    return out\n}\n\nfunc filter(in \u003c-chan int, threshold int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for v := range in {\n            if v \u003e= threshold {\n                out \u003c- v\n            }\n        }\n    }()\n    return out\n}\n\nfunc main() {\n    // Pipeline: gen → double → filter\n    pipeline := filter(double(generate()), 10)\n\n    for v := range pipeline {\n        fmt.Println(v) // 10, 12, 14, 16, 18, 20\n    }\n}\n```\n\n\u003c/details\u003e\n\n---\n\n## Section 4.16: Common Mistakes\n\n### Mistake 1: Sending on Unbuffered with No Receiver\n\n```go\n// BUG\nfunc main() {\n    ch := make(chan int)\n    ch \u003c- 42 // DEADLOCK! No one receiving\n}\n\n// FIX\nfunc main() {\n    ch := make(chan int)\n    go func() { ch \u003c- 42 }() // Send in goroutine\n    fmt.Println(\u003c-ch)\n}\n```\n\n### Mistake 2: Forgetting to Close When Using Range\n\n```go\n// BUG\nfunc generate(ch chan int) {\n    for i := 0; i \u003c 5; i++ {\n        ch \u003c- i\n    }\n    // Forgot: close(ch)\n}\n\nfunc main() {\n    ch := make(chan int)\n    go generate(ch)\n\n    for v := range ch { // DEADLOCK after 5 values\n        fmt.Println(v)\n    }\n}\n\n// FIX\nfunc generate(ch chan int) {\n    defer close(ch) // Always close!\n    for i := 0; i \u003c 5; i++ {\n        ch \u003c- i\n    }\n}\n```\n\n### Mistake 3: Closing Channel Multiple Times\n\n```go\n// BUG\nch := make(chan int)\nclose(ch)\nclose(ch) // PANIC: close of closed channel\n\n// FIX: Use sync.Once\nvar once sync.Once\nonce.Do(func() { close(ch) })\nonce.Do(func() { close(ch) }) // Safe, does nothing\n```\n\n### Mistake 4: Sending to Closed Channel\n\n```go\n// BUG\nch := make(chan int)\nclose(ch)\nch \u003c- 42 // PANIC: send on closed channel\n\n// FIX: Don't send after close. Sender should own closing.\n```\n\n### Mistake 5: Wrong Goroutine Closes\n\n```go\n// BUG\nfunc receiver(ch chan int) {\n    for v := range ch {\n        fmt.Println(v)\n    }\n    close(ch) // WRONG! Receiver shouldn't close\n}\n\n// FIX: Use channel direction to prevent\nfunc receiver(ch \u003c-chan int) { // Receive-only\n    for v := range ch {\n        fmt.Println(v)\n    }\n    // Can't close receive-only channel - compile error!\n}\n```\n\n### Mistake 6: Goroutine Leak from Blocked Channel\n\n```go\n// BUG\nfunc leaky() {\n    ch := make(chan int)\n    go func() {\n        val := \u003c-ch // Blocks forever - no sender!\n        fmt.Println(val)\n    }()\n    // Function returns, goroutine leaked!\n}\n\n// FIX: Use context or timeout\nfunc safe(ctx context.Context) {\n    ch := make(chan int)\n    go func() {\n        select {\n        case val := \u003c-ch:\n            fmt.Println(val)\n        case \u003c-ctx.Done():\n            return // Clean exit\n        }\n    }()\n}\n```\n\n### Mistake 7: Using Wrong Buffer Size\n\n```go\n// BAD: Random buffer size\nch := make(chan int, 1000) // Why 1000?\n\n// GOOD: Justified buffer size\nch := make(chan int, numWorkers) // One job per worker\n```\n\n**Rule**: Start unbuffered. Add buffer only with justification!\n\n### Quick Reference: What Panics?\n\n| Operation | nil channel | closed channel | open channel |\n|-----------|-------------|----------------|--------------|\n| close | **panic** | **panic** | succeeds |\n| send | blocks forever | **panic** | blocks/succeeds |\n| receive | blocks forever | returns zero | blocks/succeeds |\n\n---\n\n## Section 4.17: Exercises, Problems, Solutions, and Explanations\n\n\u003e **How to use this section**: Try each problem yourself first. When you're stuck, read the **Hint** only. If you're still stuck, read the solution — but make sure you understand the **\"How It Works\"** explanation before moving on. The explanation is where the real learning happens.\n\n### Problems in this section\n\n- **Beginner (1–5)**: Ping Pong, Number Generator, Done Signal, Parallel Sum, Buffer Experiment\n- **Intermediate (6–10)**: Worker Pool, Timeout Handler, Three-Stage Pipeline, Rate Limiter, Fan-Out / Fan-In\n- **Advanced (11–17)**: Fix the Race with Channels, Bounded Downloader, Graceful Shutdown, Equivalent Binary Trees, Log Pipeline\n\n---\n\n***Beginner (1–5)***\n\n---\n\n#### Exercise 1: Ping Pong\n\n**Problem**: Create two goroutines that pass an integer back and forth 10 times.\n\n```\n// Expected output:\n// Goroutine 1 sent: 0\n// Goroutine 2 received: 0\n// Goroutine 2 sent: 1\n// Goroutine 1 received: 1\n// ...\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nCreate two channels, one for each direction: `ping` carries values from goroutine 1 → goroutine 2, and `pong` carries them back. Each goroutine alternates sending and receiving.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc goroutine1(ping chan\u003c- int, pong \u003c-chan int, wg *sync.WaitGroup) {\n    defer wg.Done()\n    for i := 0; i \u003c 10; i += 2 {\n        ping \u003c- i\n        fmt.Printf(\"Goroutine 1 sent: %d\\n\", i)\n\n        v := \u003c-pong\n        fmt.Printf(\"Goroutine 1 received: %d\\n\", v)\n    }\n}\n\nfunc goroutine2(ping \u003c-chan int, pong chan\u003c- int, wg *sync.WaitGroup) {\n    defer wg.Done()\n    for i := 0; i \u003c 10; i += 2 {\n        v := \u003c-ping\n        fmt.Printf(\"Goroutine 2 received: %d\\n\", v)\n\n        pong \u003c- i + 1\n        fmt.Printf(\"Goroutine 2 sent: %d\\n\", i+1)\n    }\n}\n\nfunc main() {\n    ping := make(chan int)\n    pong := make(chan int)\n    var wg sync.WaitGroup\n\n    wg.Add(2)\n    go goroutine1(ping, pong, \u0026wg)\n    go goroutine2(ping, pong, \u0026wg)\n\n    wg.Wait()\n}\n```\n\n**How It Works:**\n\n```\nTwo channels, two directions:\n\n    ping channel: G1 ─────sends────→ G2\n    pong channel: G1 ←────receives── G2\n\nTimeline:\n    G1: sends 0 on ping ──────────────────────→ G2 receives 0\n                                                G2 sends 1 on pong ──→ G1 receives 1\n    G1: sends 2 on ping ──────────────────────→ G2 receives 2\n    ...\n```\n\nThis works because both channels are **unbuffered**. When G1 sends on `ping`, it blocks until G2 receives. When G2 sends on `pong`, it blocks until G1 receives. The two goroutines take turns — you can't get out of order.\n\nNotice the **directional channel types** in the signatures:\n- `goroutine1(ping chan\u003c- int, pong \u003c-chan int)` — G1 sends on ping, receives on pong\n- `goroutine2(ping \u003c-chan int, pong chan\u003c- int)` — G2 receives on ping, sends on pong\n\nThe compiler enforces that G1 can't accidentally receive on `ping` or send on `pong`. That's compile-time safety!\n\nThe `sync.WaitGroup` ensures `main` doesn't exit before both goroutines finish their 10 exchanges.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 2: Number Generator\n\n**Problem**: Write a function that generates numbers 1–100 on a channel, and a consumer that prints them.\n\n```go\nfunc generate(ch chan\u003c- int) {\n    // TODO: Send 1-100, close channel\n}\n\nfunc main() {\n    ch := make(chan int)\n    go generate(ch)\n    // TODO: Receive and print\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nAfter the generator sends all values, it must `close(ch)`. The consumer can then use `for v := range ch` — the range will automatically stop when the channel is closed.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc generate(ch chan\u003c- int) {\n    for i := 1; i \u003c= 100; i++ {\n        ch \u003c- i\n    }\n    close(ch) // Signal: no more values coming\n}\n\nfunc main() {\n    ch := make(chan int)\n    go generate(ch)\n\n    for v := range ch {\n        fmt.Println(v)\n    }\n\n    fmt.Println(\"Done!\")\n}\n```\n\n**How It Works:**\n\n```\ngenerate goroutine:\n    sends 1 ──→ main receives 1 ──→ prints 1\n    sends 2 ──→ main receives 2 ──→ prints 2\n    ...\n    sends 100 → main receives 100 → prints 100\n    close(ch) ← tells range to stop!\n\nmain goroutine:\n    for v := range ch ← exits when ch is closed\n    prints \"Done!\"\n```\n\nTwo things working together:\n\n**`close(ch)`** signals \"no more data.\" Without this, `for v := range ch` would block forever after receiving 100, waiting for a 101st value that never comes. That's a goroutine leak!\n\n**`for v := range ch`** is syntactic sugar for:\n```go\nfor {\n    v, ok := \u003c-ch\n    if !ok {\n        break // channel closed, exit loop\n    }\n    fmt.Println(v)\n}\n```\n\nThe `range` loop handles the `ok` check automatically. This is why it's the idiomatic way to consume a channel.\n\n**Why is `generate` launched as a goroutine?**\n\nBecause `ch` is unbuffered. If you called `generate(ch)` directly (not as a goroutine), the first `ch \u003c- 1` would block forever — nobody is receiving yet! The goroutine lets both sides run concurrently.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 3: Done Signal\n\n**Problem**: Replace `time.Sleep()` with a done channel.\n\n```go\n// BEFORE — brittle, hardcoded timing\nfunc worker() {\n    doWork()\n}\n\nfunc main() {\n    go worker()\n    time.Sleep(2 * time.Second) // hope the worker finishes in time!\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nThe worker should send on a `done` channel (or close it) when it finishes. `main` blocks on `\u003c-done` instead of sleeping.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc doWork() {\n    fmt.Println(\"Worker: starting...\")\n    time.Sleep(500 * time.Millisecond) // simulate actual work\n    fmt.Println(\"Worker: finished!\")\n}\n\nfunc worker(done chan\u003c- struct{}) {\n    doWork()\n    done \u003c- struct{}{} // signal completion\n}\n\nfunc main() {\n    done := make(chan struct{})\n\n    go worker(done)\n\n    \u003c-done // block here until worker signals done\n\n    fmt.Println(\"Main: worker has finished, exiting\")\n}\n```\n\n**How It Works:**\n\n```\nBEFORE (bad): AFTER (correct):\n\nmain: go worker() main: go worker()\nmain: sleep 2s ─────────────────→ main: \u003c-done ─────────────────────────┐\n                                                                           │ blocks\n      [worker might finish] worker: doing work... │\n      [worker might not finish] worker: done! │\n                                          worker: done \u003c- struct{}{} ────┘\nmain: exits (maybe too early!) main: resumes\n                                    main: \"worker has finished\"\n```\n\n**Why `struct{}{}`?**\n\n`chan struct{}` uses zero bytes of memory per message. We're not communicating a VALUE — we're communicating an EVENT. The signal itself is the message. Using `int` or `bool` would work but would imply the value matters (what does `true` mean vs `false`?). `struct{}` is unambiguous: \"this happened.\"\n\n**Why not `close(done)` instead of `done \u003c- struct{}{}`?**\n\nBoth work for a single waiter. But `close` is better when MULTIPLE goroutines are waiting on the same `done` channel — `close` wakes ALL of them simultaneously, while a send only wakes ONE. For a single worker → single waiter, either is fine.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 4: Parallel Sum\n\n**Problem**: Sum two halves of an array concurrently, combine results.\n\n```go\nnums := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n// Expected: 55\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nCreate a `results` channel with buffer size 2. Launch two goroutines, each summing half the slice and sending their partial sum to the channel. Main adds the two partial sums.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc sumSlice(nums []int, result chan\u003c- int) {\n    total := 0\n    for _, n := range nums {\n        total += n\n    }\n    result \u003c- total\n}\n\nfunc main() {\n    nums := []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}\n    mid := len(nums) / 2\n\n    results := make(chan int, 2) // buffered: both goroutines can send without waiting\n\n    go sumSlice(nums[:mid], results) // sum first half: 1+2+3+4+5 = 15\n    go sumSlice(nums[mid:], results) // sum second half: 6+7+8+9+10 = 40\n\n    a := \u003c-results\n    b := \u003c-results\n\n    fmt.Println(\"Total:\", a+b) // 55\n}\n```\n\n**How It Works:**\n\n```\nnums = [1, 2, 3, 4, 5, | 6, 7, 8, 9, 10]\n                    mid = 5\n\nGoroutine A: sums [1,2,3,4,5] = 15 ─→ results channel\nGoroutine B: sums [6,7,8,9,10] = 40 ─→ results channel\n\nmain: a := \u003c-results (gets 15 or 40 — order not guaranteed!)\nmain: b := \u003c-results (gets the other one)\nmain: a + b = 55 (correct regardless of order!)\n```\n\n**Why buffer size 2?**\n\nWith buffer=2, both goroutines can send their result without waiting for each other or for `main` to be ready. If the buffer were 0 (unbuffered), the second goroutine to finish would block until `main` reads the first result. With buffer=2, both goroutines send immediately and exit cleanly.\n\n**Why is the order of `a` and `b` not guaranteed?**\n\nThe two goroutines run independently. Whichever finishes first puts their result in the channel first. So `a` might be 15 or 40 depending on scheduling. That's fine because we're just adding them — addition is commutative.\n\n**Key insight**: This is the fundamental pattern for **map-reduce** — split work across goroutines, collect partial results via channel, combine. The channel handles the synchronization so you don't need a mutex.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 5: Buffer Experiment\n\n**Problem**: Run the same code with different buffer sizes and observe the behavior.\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nWatch when the sender blocks vs. continues. An unbuffered channel forces synchronous handoff. A buffered channel lets the sender run ahead up to the buffer capacity.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc experiment(bufferSize int) {\n    fmt.Printf(\"\\n--- Buffer size: %d ---\\n\", bufferSize)\n    ch := make(chan int, bufferSize)\n\n    go func() {\n        for i := 1; i \u003c= 5; i++ {\n            fmt.Printf(\" Sender: about to send %d\\n\", i)\n            ch \u003c- i\n            fmt.Printf(\" Sender: sent %d (didn't block)\\n\", i)\n        }\n        close(ch)\n        fmt.Println(\" Sender: closed channel, goroutine exiting\")\n    }()\n\n    time.Sleep(100 * time.Millisecond) // let sender run first\n\n    fmt.Println(\" Receiver: starting to receive...\")\n    for v := range ch {\n        fmt.Printf(\" Receiver: got %d\\n\", v)\n        time.Sleep(50 * time.Millisecond) // slow receiver\n    }\n}\n\nfunc main() {\n    experiment(0) // Unbuffered\n    experiment(1) // Buffer of 1\n    experiment(10) // Buffer of 10\n}\n```\n\n**How It Works and What You'll See:**\n\n**Buffer size 0 (unbuffered):**\n```\nSender: about to send 1\n[SENDER BLOCKS — waiting for receiver]\n  ... 100ms later, receiver starts ...\nReceiver: starting to receive...\nSender: sent 1 (didn't block) ← receiver read it, sender unblocks\nReceiver: got 1\nSender: about to send 2\n[SENDER BLOCKS AGAIN]\n```\n\nThe sender can only proceed when the receiver is ready. They're in lockstep.\n\n**Buffer size 1:**\n```\nSender: about to send 1\nSender: sent 1 ← fits in buffer, no block\nSender: about to send 2\n[SENDER BLOCKS on 2 — buffer full!]\n  ... 100ms later ...\nReceiver: starting to receive...\nReceiver: got 1 ← freed one slot\nSender: sent 2 ← sender unblocks\n```\n\nSender gets one step ahead, then has to wait.\n\n**Buffer size 10:**\n```\nSender: about to send 1\nSender: sent 1\nSender: about to send 2\nSender: sent 2\nSender: about to send 3\nSender: sent 3\nSender: about to send 4\nSender: sent 4\nSender: about to send 5\nSender: sent 5\nSender: closed channel, goroutine exiting\n  ← ALL 5 values sent without blocking!\n  ... 100ms later ...\nReceiver: starting to receive...\nReceiver: got 1\nReceiver: got 2\n... etc\n```\n\nBuffer of 10 \u003e 5 messages = sender never blocks at all.\n\n**The key mental model:**\n\n```\nBuffer size 0: sender blocks until receiver is ready (synchronous)\nBuffer size N: sender blocks only when buffer has N items already\nBuffer size ∞: sender never blocks (not available in Go — use a slice + mutex for unbounded)\n```\n\n\n\u003c/details\u003e\n\n---\n\n***Intermediate (6–10)***\n\n---\n\n### Exercise 6: Worker Pool\n\n**Problem**: Build a pool of 3 workers processing 10 jobs.\n\n```go\ntype Job struct {\n    id int\n}\n\nfunc worker(id int, jobs \u003c-chan Job, results chan\u003c- int) {\n    // TODO: Process jobs\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nWorkers use `for job := range jobs` — they keep reading until `jobs` is closed. Main sends all jobs, then closes `jobs`. Use a `sync.WaitGroup` to know when all workers finish, then close `results`.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \"math/rand\"\n)\n\ntype Job struct {\n    id int\n}\n\nfunc worker(id int, jobs \u003c-chan Job, results chan\u003c- int, wg *sync.WaitGroup) {\n    defer wg.Done() // signal we're done when this function returns\n    for job := range jobs {\n        // Simulate variable processing time\n        duration := time.Duration(rand.Intn(200)) * time.Millisecond\n        time.Sleep(duration)\n\n        result := job.id * job.id // job result = id squared\n        fmt.Printf(\" Worker %d processed job %d → %d (took %v)\\n\",\n            id, job.id, result, duration)\n        results \u003c- result\n    }\n    fmt.Printf(\"Worker %d: jobs channel closed, exiting\\n\", id)\n}\n\nfunc main() {\n    const numJobs = 10\n    const numWorkers = 3\n\n    jobs := make(chan Job, numJobs)\n    results := make(chan int, numJobs)\n    var wg sync.WaitGroup\n\n    // Start 3 workers\n    for i := 1; i \u003c= numWorkers; i++ {\n        wg.Add(1)\n        go worker(i, jobs, results, \u0026wg)\n    }\n\n    // Send 10 jobs\n    for i := 1; i \u003c= numJobs; i++ {\n        jobs \u003c- Job{id: i}\n    }\n    close(jobs) // tell workers: no more jobs\n\n    // Wait for all workers to finish, then close results\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    // Collect all results\n    total := 0\n    for r := range results {\n        total += r\n    }\n    fmt.Printf(\"\\nAll jobs done. Sum of results: %d\\n\", total)\n}\n```\n\n**How It Works:**\n\n```\nSETUP:\n    jobs ──────────────────────────────────────────────→ [buffer: job1..job10]\n    results ←──────────────────────────────────────────── [buffer: capacity 10]\n\n         ┌── Worker 1 ──┐\njobs ───→├── Worker 2 ──┤──→ results ──→ main (collecting)\n         └── Worker 3 ──┘\n\nLIFECYCLE:\n    1. main fills jobs channel (buffered, so main doesn't block)\n    2. main closes jobs ← \"no more work\"\n    3. Workers are ranging over jobs, picking up whatever is free\n    4. When jobs is closed, workers' for-range loops exit\n    5. Each worker calls wg.Done() via defer\n    6. Separate goroutine waits on wg.Wait(), then closes results\n    7. main's for-range over results exits\n    8. main prints total\n```\n\n**The two-goroutine sync trick:**\n\n```go\ngo func() {\n    wg.Wait() // blocks until all 3 workers call Done()\n    close(results) // THEN close results so main's range exits\n}()\n```\n\nThis pattern appears constantly in real Go code. You need a goroutine here because `wg.Wait()` blocks, and if main called it directly, main would block before reading from `results` — creating a deadlock (results is only capacity 10, would fill up, workers would block).\n\n**Why buffer `jobs` with `numJobs` capacity?**\n\nSo main can send all 10 jobs without waiting for workers. Workers are started first, but they might not have picked anything up yet. With a buffer, main loads all jobs and moves on immediately.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 7: Timeout Handler\n\n**Problem**: Implement a function that times out after 2 seconds.\n\n```go\nfunc fetchWithTimeout(url string) (string, error) {\n    // TODO: Use select with time.After\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nLaunch a goroutine to do the actual work, send result to a **buffered** channel (capacity 1), then `select` between that channel and `time.After(2*time.Second)`. The buffer prevents a goroutine leak if the timeout fires first.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"time\"\n    \"math/rand\"\n)\n\nfunc simulateFetch(url string) string {\n    // Random delay: sometimes fast, sometimes slow\n    delay := time.Duration(rand.Intn(4000)) * time.Millisecond\n    time.Sleep(delay)\n    return fmt.Sprintf(\"response from %s\", url)\n}\n\nfunc fetchWithTimeout(url string, timeout time.Duration) (string, error) {\n    // CRITICAL: buffer=1 prevents goroutine leak!\n    resultCh := make(chan string, 1)\n\n    go func() {\n        result := simulateFetch(url)\n        resultCh \u003c- result // if timeout already fired, this still completes (buffer absorbs it)\n    }()\n\n    select {\n    case result := \u003c-resultCh:\n        return result, nil\n    case \u003c-time.After(timeout):\n        return \"\", errors.New(\"timeout: request took too long\")\n    }\n}\n\nfunc main() {\n    urls := []string{\n        \"https://fast-api.example.com\",\n        \"https://slow-api.example.com\",\n        \"https://medium-api.example.com\",\n    }\n\n    for _, url := range urls {\n        fmt.Printf(\"Fetching %s...\\n\", url)\n        result, err := fetchWithTimeout(url, 2*time.Second)\n        if err != nil {\n            fmt.Printf(\" Error: %v\\n\", err)\n        } else {\n            fmt.Printf(\" Got: %s\\n\", result)\n        }\n    }\n}\n```\n\n**How It Works:**\n\n```\nfetchWithTimeout(\"...\", 2s):\n\n    goroutine: starts simulateFetch (takes 0–4 seconds)\n\n    select races:\n        case \u003c-resultCh: ← fires if fetch completes within 2s\n        case \u003c-time.After(2s): ← fires if 2 seconds pass first\n\n    SCENARIO A: fetch takes 1.2s (fast)\n        ─ 1.2s: goroutine sends to resultCh\n        ─ select picks resultCh case\n        ─ returns \"response from ...\", nil\n\n    SCENARIO B: fetch takes 3.5s (slow)\n        ─ 2.0s: time.After fires\n        ─ select picks timeout case\n        ─ returns \"\", error(\"timeout...\")\n        ─ goroutine is still running but will complete at 3.5s\n        ─ goroutine sends to resultCh (buffer=1 absorbs it!)\n        ─ goroutine exits cleanly\n```\n\n**The buffer=1 detail — why it matters:**\n\n```\nWITHOUT BUFFER:\n  resultCh := make(chan string) // ← unbuffered\n\n  If timeout fires:\n    → fetchWithTimeout returns the error\n    → select is gone, nobody is receiving from resultCh\n    → goroutine finishes fetch at 3.5s\n    → goroutine tries: resultCh \u003c- result\n    → BLOCKS FOREVER — nobody is receiving!\n    → GOROUTINE LEAK\n\nWITH BUFFER of 1:\n  resultCh := make(chan string, 1) // ← buffered\n\n  If timeout fires:\n    → fetchWithTimeout returns the error\n    → goroutine finishes fetch at 3.5s\n    → goroutine: resultCh \u003c- result → goes into buffer\n    → goroutine exits\n    → resultCh eventually GC'd\n```\n\nThis is the **\"forgotten sender\"** goroutine leak pattern from Ardan Labs. Always buffer result channels with capacity 1 in fire-and-forget timeout patterns.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 8: Three-Stage Pipeline\n\n**Problem**: Create: generate → double → filter(\u003e10)\n\n```\n// Input: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n// After double: 2, 4, 6, 8, 10, 12, 14, 16, 18, 20\n// After filter: 12, 14, 16, 18, 20\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nEach stage is a function that takes `\u003c-chan int` and returns `\u003c-chan int`. It starts a goroutine internally, uses `defer close(out)`, and ranges over input. Chain them: `filter(double(generate(1, 10)))`.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport \"fmt\"\n\n// Stage 1: generates numbers from start to end (inclusive)\nfunc generate(start, end int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for i := start; i \u003c= end; i++ {\n            out \u003c- i\n        }\n    }()\n    return out\n}\n\n// Stage 2: doubles each incoming value\nfunc double(in \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for v := range in {\n            out \u003c- v * 2\n        }\n    }()\n    return out\n}\n\n// Stage 3: passes only values greater than threshold\nfunc filterGreaterThan(in \u003c-chan int, threshold int) \u003c-chan int {\n    out := make(chan int)\n    go func() {\n        defer close(out)\n        for v := range in {\n            if v \u003e threshold {\n                out \u003c- v\n            }\n        }\n    }()\n    return out\n}\n\nfunc main() {\n    // Build and connect the pipeline\n    nums := generate(1, 10)\n    doubled := double(nums)\n    filtered := filterGreaterThan(doubled, 10)\n\n    // Consume — range exits when filtered channel closes\n    fmt.Print(\"Output: \")\n    for v := range filtered {\n        fmt.Printf(\"%d \", v) // 12 14 16 18 20\n    }\n    fmt.Println()\n}\n```\n\n**How It Works:**\n\n```\ngenerate(1,10) ──ch1──→ double() ──ch2──→ filterGreaterThan(,10) ──ch3──→ main\n    goroutine A goroutine B goroutine C\n\nFlow of value 6:\n  A: sends 6 to ch1\n  B: receives 6 from ch1, sends 12 to ch2\n  C: receives 12 from ch2, 12 \u003e 10 → sends 12 to ch3\n  main: receives 12, prints it\n\nFlow of value 3:\n  A: sends 3 to ch1\n  B: receives 3 from ch1, sends 6 to ch2\n  C: receives 6 from ch2, 6 \u003e 10? No → drops it\n\nClose propagation:\n  A finishes → close(ch1)\n  B sees ch1 closed → loop exits → close(ch2)\n  C sees ch2 closed → loop exits → close(ch3)\n  main sees ch3 closed → range exits → prints newline\n```\n\n**Why `defer close(out)` is in every stage:**\n\nWhen a stage's input channel closes, its `for v := range in` loop exits. The `defer close(out)` then fires, automatically propagating the \"I'm done\" signal to the NEXT stage. This is the **close cascade** — closing the first channel triggers a chain reaction all the way to `main`.\n\nWithout the defer, you'd have to manually close each stage's output, and forgetting one would cause the next stage to hang forever.\n\nThis pattern is from Sameer Ajmani's 2014 Go Blog post \"Go Concurrency Patterns: Pipelines and Cancellation\" (`go.dev/blog/pipelines`).\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 9: Rate Limiter\n\n**Problem**: Allow max 5 requests per second.\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nUse `time.NewTicker(200ms)` — a tick every 200ms gives exactly 5 ticks per second. Block each request until a tick is available.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n)\n\ntype RateLimiter struct {\n    ticker *time.Ticker\n    quit chan struct{}\n}\n\nfunc NewRateLimiter(requestsPerSecond int) *RateLimiter {\n    interval := time.Second / time.Duration(requestsPerSecond)\n    rl := \u0026RateLimiter{\n        ticker: time.NewTicker(interval),\n        quit: make(chan struct{}),\n    }\n    return rl\n}\n\n// Wait blocks until the next rate-limited slot is available\nfunc (rl *RateLimiter) Wait() bool {\n    select {\n    case \u003c-rl.ticker.C:\n        return true // got a slot\n    case \u003c-rl.quit:\n        return false // limiter stopped\n    }\n}\n\nfunc (rl *RateLimiter) Stop() {\n    rl.ticker.Stop()\n    close(rl.quit)\n}\n\nfunc main() {\n    limiter := NewRateLimiter(5) // 5 requests per second\n    defer limiter.Stop()\n\n    var wg sync.WaitGroup\n    start := time.Now()\n\n    for i := 1; i \u003c= 15; i++ {\n        limiter.Wait() // blocks until our turn — at most 5 per second\n\n        wg.Add(1)\n        i := i\n        go func() {\n            defer wg.Done()\n            elapsed := time.Since(start).Seconds()\n            fmt.Printf(\"Request %2d at t=%.2fs\\n\", i, elapsed)\n        }()\n    }\n\n    wg.Wait()\n    fmt.Printf(\"\\nTotal time: %.2fs (expected ~3s for 15 requests at 5/s)\\n\",\n        time.Since(start).Seconds())\n}\n```\n\n**How It Works:**\n\n```\nNewRateLimiter(5):\n    interval = 1s / 5 = 200ms\n    ticker fires every 200ms\n\n    Tick timeline:\n    t=0ms: tick! → request 1 allowed\n    t=200ms: tick! → request 2 allowed\n    t=400ms: tick! → request 3 allowed\n    t=600ms: tick! → request 4 allowed\n    t=800ms: tick! → request 5 allowed\n    t=1000ms: tick! → request 6 allowed\n    ...\n\nlimiter.Wait() blocks on \u003c-ticker.C until the next tick arrives.\nOne request per tick = max 5 per second.\n```\n\n**Why `time.Ticker` instead of `time.After`?**\n\n`time.After(200ms)` creates a NEW timer each call. After 15 requests, that's 15 timer allocations. `time.Ticker` creates ONE ticker that fires repeatedly. Much more efficient.\n\nAlso, `time.After` measures from the moment you call it, so there could be drift. A Ticker maintains a consistent rhythm from the moment it's created.\n\n**Adding burst support (bonus):**\n\n```go\n// Pre-fill bucket with N tokens = allow burst of N requests immediately\ntype BurstLimiter struct {\n    tokens chan struct{}\n    ticker *time.Ticker\n}\n\nfunc NewBurstLimiter(rps, burst int) *BurstLimiter {\n    bl := \u0026BurstLimiter{\n        tokens: make(chan struct{}, burst),\n        ticker: time.NewTicker(time.Second / time.Duration(rps)),\n    }\n    // Pre-fill burst tokens\n    for i := 0; i \u003c burst; i++ {\n        bl.tokens \u003c- struct{}{}\n    }\n    // Refill one token per tick\n    go func() {\n        for range bl.ticker.C {\n            select {\n            case bl.tokens \u003c- struct{}{}:\n            default: // full, discard\n            }\n        }\n    }()\n    return bl\n}\n\nfunc (bl *BurstLimiter) Wait() { \u003c-bl.tokens }\n```\n\nWith `burst=3`, the first 3 requests are instant. Then it's back to 5/sec.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 10: Fan-Out / Fan-In\n\n**Problem**: Fetch 5 URLs with 3 workers, merge results into one channel.\n\n```go\nurls := []string{\"url1\", \"url2\", \"url3\", \"url4\", \"url5\"}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nFan-out: create a `jobs` channel, send all URLs into it, start 3 workers that read from `jobs`. Fan-in: each worker sends to a shared `results` channel. Use `sync.WaitGroup` to detect when all workers finish and close `results`.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \"math/rand\"\n)\n\ntype FetchResult struct {\n    URL string\n    Response string\n    Duration time.Duration\n}\n\n// Simulates an HTTP fetch\nfunc fetch(url string) FetchResult {\n    start := time.Now()\n    delay := time.Duration(rand.Intn(300)) * time.Millisecond\n    time.Sleep(delay)\n    return FetchResult{\n        URL: url,\n        Response: fmt.Sprintf(\"200 OK from %s\", url),\n        Duration: time.Since(start),\n    }\n}\n\n// Worker reads URLs from jobs, sends results to results\nfunc fetchWorker(id int, jobs \u003c-chan string, results chan\u003c- FetchResult, wg *sync.WaitGroup) {\n    defer wg.Done()\n    for url := range jobs {\n        fmt.Printf(\" Worker %d fetching %s\\n\", id, url)\n        results \u003c- fetch(url)\n    }\n}\n\nfunc main() {\n    urls := []string{\n        \"https://api.service1.com\",\n        \"https://api.service2.com\",\n        \"https://api.service3.com\",\n        \"https://api.service4.com\",\n        \"https://api.service5.com\",\n    }\n\n    const numWorkers = 3\n\n    jobs := make(chan string, len(urls))\n    results := make(chan FetchResult, len(urls))\n    var wg sync.WaitGroup\n\n    // Fan-out: start 3 workers\n    for i := 1; i \u003c= numWorkers; i++ {\n        wg.Add(1)\n        go fetchWorker(i, jobs, results, \u0026wg)\n    }\n\n    // Load all jobs\n    for _, url := range urls {\n        jobs \u003c- url\n    }\n    close(jobs) // signal workers: no more URLs\n\n    // Fan-in: close results when all workers done\n    go func() {\n        wg.Wait()\n        close(results)\n    }()\n\n    // Collect and display results (fan-in point)\n    fmt.Println(\"\\nResults:\")\n    for r := range results {\n        fmt.Printf(\" %s → %s (took %v)\\n\", r.URL, r.Response, r.Duration)\n    }\n}\n```\n\n**How It Works:**\n\n```\n5 URLs, 3 workers\n\n         ┌── Worker 1 ──────────────────────────┐\njobs ───→├── Worker 2 ──────────────────────────┤──→ results ──→ main\n         └── Worker 3 ──────────────────────────┘\n\nStep 1: jobs ← [url1, url2, url3, url4, url5] then close(jobs)\n\nStep 2: Workers race to pick up jobs:\n  Worker 1 picks url1\n  Worker 2 picks url2\n  Worker 3 picks url3\n  Worker 1 finishes url1, picks url4\n  Worker 3 finishes url3, picks url5\n  Worker 2 finishes url2\n\nStep 3: All 5 fetches complete, results sent to results channel\n\nStep 4: wg.Wait() unblocks → close(results)\n\nStep 5: main's range exits, prints summary\n```\n\n**With 5 URLs and 3 workers, the time savings:**\n\nSequential: ~5 × avg_delay. With 3 workers, at most `ceil(5/3) × avg_delay` in theory (limited by the slowest batch), but since workers pick up as soon as free, it's much better.\n\n\n\u003c/details\u003e\n\n---\n\n***Advanced (11–17)***\n\n---\n\n### Exercise 11: Fix the Race — Channels Instead of Mutex\n\n**Problem**: Fix the race condition using channels (not mutex). Verify with `-race` flag.\n\n```go\n// BROKEN: data race\nvar counter int\nfor i := 0; i \u003c 1000; i++ {\n    go func() { counter++ }()\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nUse a \"counter manager\" goroutine that owns the counter exclusively. Other goroutines don't touch counter directly — they send increment requests on a channel. The manager is the only one reading/writing counter.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc counterManager(increments \u003c-chan struct{}, queries \u003c-chan chan int, done \u003c-chan struct{}) {\n    counter := 0 // ONLY this goroutine touches counter!\n    for {\n        select {\n        case \u003c-increments:\n            counter++\n        case responseCh := \u003c-queries:\n            responseCh \u003c- counter // send current value to requester\n        case \u003c-done:\n            return\n        }\n    }\n}\n\nfunc main() {\n    increments := make(chan struct{}, 1000) // buffered to avoid blocking goroutines\n    queries := make(chan chan int, 1)\n    done := make(chan struct{})\n\n    go counterManager(increments, queries, done)\n\n    // Launch 1000 goroutines, each incrementing counter\n    var wg sync.WaitGroup\n    for i := 0; i \u003c 1000; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            increments \u003c- struct{}{} // request an increment\n        }()\n    }\n\n    wg.Wait() // wait for all increment requests to be sent\n\n    // Query the final value\n    responseCh := make(chan int, 1)\n    queries \u003c- responseCh\n    finalValue := \u003c-responseCh\n\n    fmt.Println(\"Final counter:\", finalValue) // 1000\n\n    close(done)\n}\n```\n\n**How It Works:**\n\n```\nBROKEN VERSION (race):\n  Goroutine A reads counter=5\n  Goroutine B reads counter=5 (same value!)\n  Goroutine A writes counter=6\n  Goroutine B writes counter=6 (lost increment!)\n  Expected 7, got 6. Data race!\n\nFIXED VERSION (channel-based):\n  counterManager goroutine OWNS counter entirely\n\n  All 1000 goroutines just send a signal: increments \u003c- struct{}{}\n  Only counterManager receives and does counter++\n\n  There's only ONE goroutine doing reads/writes → no race possible!\n```\n\n**Run with the race detector to confirm:**\n\n```bash\ngo run -race main.go\n# Should output: Final counter: 1000 (with no race warning)\n```\n\n**The \"counter manager\" is a pattern from the Go Blog's \"Share Memory by Communicating\"** — instead of protecting shared memory with a lock, you give ownership of the data to one goroutine and communicate with it via channels.\n\n**Channel of channels for queries:**\n\n```go\nqueries \u003c- responseCh // send a response channel TO the manager\nfinalValue := \u003c-responseCh // receive the answer FROM the manager\n```\n\nThe manager receives a channel, writes the current counter to it, and the requester reads it back. This serializes all state access through the single-goroutine manager. This is the same pattern etcd's raft node uses for status queries!\n\n**Honest note — when to use mutex instead:**\n\nFor a simple counter, a mutex (`var mu sync.Mutex; mu.Lock(); counter++; mu.Unlock()`) or `atomic.AddInt64` is simpler and faster. The channel-based approach shines for MORE COMPLEX state management where you need multiple operations to appear atomic (e.g., increment AND read AND conditionally reset).\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 12: Bounded Downloader\n\n**Problem**: Download 100 URLs, max 10 concurrent at any time.\n\n```go\nurls := make([]string, 100)\n// TODO: Use semaphore pattern\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nA buffered channel of capacity 10 acts as a semaphore. Before starting a download, send a token (`sem \u003c- struct{}{}`). After the download, receive a token (`\u003c-sem`). If 10 downloads are running, the 11th send blocks.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n    \"time\"\n    \"math/rand\"\n)\n\ntype DownloadResult struct {\n    URL string\n    Success bool\n    Index int\n}\n\nfunc downloadURL(url string, index int) DownloadResult {\n    duration := time.Duration(rand.Intn(200)) * time.Millisecond\n    time.Sleep(duration)\n    return DownloadResult{URL: url, Success: true, Index: index}\n}\n\nfunc boundedDownload(urls []string, maxConcurrent int) []DownloadResult {\n    sem := make(chan struct{}, maxConcurrent) // semaphore\n    results := make([]DownloadResult, len(urls))\n    var wg sync.WaitGroup\n\n    for i, url := range urls {\n        i, url := i, url\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n\n            sem \u003c- struct{}{} // acquire slot (blocks if 10 already running)\n            defer func() { \u003c-sem }() // release slot when done\n\n            results[i] = downloadURL(url, i)\n            fmt.Printf(\" Downloaded %s (%d/%d)\\n\", url, i+1, len(urls))\n        }()\n    }\n\n    wg.Wait()\n    return results\n}\n\nfunc main() {\n    // Generate 20 fake URLs (using 20 instead of 100 for readable output)\n    urls := make([]string, 20)\n    for i := range urls {\n        urls[i] = fmt.Sprintf(\"https://example.com/resource/%d\", i+1)\n    }\n\n    fmt.Printf(\"Downloading %d URLs with max %d concurrent...\\n\", len(urls), 10)\n    start := time.Now()\n\n    results := boundedDownload(urls, 10)\n\n    fmt.Printf(\"\\nFinished %d downloads in %v\\n\", len(results), time.Since(start))\n}\n```\n\n**How It Works:**\n\n```\nsem := make(chan struct{}, 10)\n         ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┐\n         │ │ │ │ │ │ │ │ │ │ │ ← 10 slots\n         └───┴───┴───┴───┴───┴───┴───┴───┴───┴───┘\n\nGoroutine starts:\n  sem \u003c- struct{}{} ← fill one slot\n\n  If slots available: runs immediately\n  If slots all full: BLOCKS until another goroutine releases\n\nGoroutine finishes:\n  \u003c-sem ← free one slot (via defer)\n  → one waiting goroutine unblocks and starts\n```\n\n**Timeline with 20 URLs, max 10:**\n\n```\nt=0: goroutines 1-10 all acquire sem → all running (sem is full)\n        goroutines 11-20 try sem \u003c- ... → BLOCK (sem full)\n\nt=~50ms: some downloads finish, release sem\n         goroutines 11-20 start acquiring slots and running\n\nt=~150ms: most done\nt=~200ms: all done\n```\n\n**Without semaphore**: All 100 goroutines start at once. Your machine runs 100 simultaneous network connections — wastes resources, potentially rate-limited by the server.\n\n**With semaphore**: Max 10 active at any moment — polite, controlled, efficient.\n\n**The `defer` placement matters:**\n\n```go\nsem \u003c- struct{}{} // acquire\ndefer func() { \u003c-sem }() // release WHEN FUNCTION RETURNS\n\n// Important: NOT defer \u003c-sem (that would defer the receive itself,\n// not a function containing the receive)\n```\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 13: Graceful Shutdown\n\n**Problem**: Service with workers. Implement proper shutdown on SIGINT.\n\n```go\nfunc worker(done \u003c-chan struct{}) {\n    // TODO: Check done, cleanup\n}\n\nfunc main() {\n    done := make(chan struct{})\n    // TODO: Start workers, shutdown gracefully\n}\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nUse `os/signal` to catch SIGINT. When received, `close(done)` — this broadcasts to ALL workers simultaneously. Workers use `select` to check for the done signal between tasks. Use `sync.WaitGroup` to wait for all workers to finish cleanup before `main` exits.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"os\"\n    \"os/signal\"\n    \"sync\"\n    \"syscall\"\n    \"time\"\n    \"math/rand\"\n)\n\nfunc worker(id int, done \u003c-chan struct{}, wg *sync.WaitGroup) {\n    defer wg.Done()\n    defer fmt.Printf(\"Worker %d: cleanup complete\\n\", id)\n\n    fmt.Printf(\"Worker %d: started\\n\", id)\n\n    for {\n        // Check shutdown signal between tasks (non-blocking!)\n        select {\n        case \u003c-done:\n            fmt.Printf(\"Worker %d: shutdown signal received, stopping\\n\", id)\n            return\n        default:\n            // Not shutting down, do work\n        }\n\n        // Simulate doing a unit of work\n        workDuration := time.Duration(rand.Intn(500)) * time.Millisecond\n        fmt.Printf(\"Worker %d: working for %v...\\n\", id, workDuration)\n\n        // Use select here too so we can be interrupted mid-sleep\n        select {\n        case \u003c-done:\n            fmt.Printf(\"Worker %d: interrupted mid-task, stopping\\n\", id)\n            return\n        case \u003c-time.After(workDuration):\n            fmt.Printf(\"Worker %d: task complete\\n\", id)\n        }\n    }\n}\n\nfunc main() {\n    done := make(chan struct{})\n    var wg sync.WaitGroup\n\n    // Start 3 workers\n    for i := 1; i \u003c= 3; i++ {\n        wg.Add(1)\n        go worker(i, done, \u0026wg)\n    }\n\n    // Listen for OS signals\n    sigCh := make(chan os.Signal, 1)\n    signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)\n\n    // Wait for signal\n    sig := \u003c-sigCh\n    fmt.Printf(\"\\nReceived signal: %v. Initiating graceful shutdown...\\n\", sig)\n\n    // Broadcast shutdown to ALL workers simultaneously\n    close(done)\n\n    // Wait for all workers to finish current task and clean up\n    wg.Wait()\n\n    fmt.Println(\"All workers stopped. Goodbye!\")\n}\n```\n\n**How It Works:**\n\n```\nSTARTUP:\n  3 workers start, all receive \u003c-chan struct{} (receive-only done channel)\n  Each worker loops: check done → do work → check done → do work → ...\n\nNORMAL OPERATION:\n  select { case \u003c-done: ... default: ... }\n\n  \"done\" is open → \u003c-done would block → default fires → worker continues\n\nCTRL+C PRESSED:\n  signal package sends SIGINT to sigCh\n  main receives it\n  main: close(done) ← broadcast to ALL workers simultaneously!\n\nIN EACH WORKER:\n  Next iteration's select: \u003c-done is now READY (closed channel)\n  → worker exits loop\n  → defer wg.Done() fires\n  → defer fmt.Printf(\"cleanup\") fires\n\nMAIN:\n  wg.Wait() — blocks until all 3 workers call Done()\n  \"All workers stopped. Goodbye!\"\n  Process exits cleanly\n```\n\n**Why `close(done)` instead of `done \u003c- struct{}{}`?**\n\n`done \u003c- struct{}{}` would wake exactly ONE worker. With 3 workers, you'd need 3 sends. `close(done)` wakes ALL workers simultaneously — a broadcast.\n\n**The non-blocking done check pattern:**\n\n```go\nselect {\ncase \u003c-done:\n    return\ndefault:\n    // continue working\n}\n```\n\nThis is \"check without blocking.\" If `done` is closed, the first case fires. If it's still open, `\u003c-done` would block, but `default` prevents that. The worker checks for shutdown, then proceeds to do work.\n\nThis is different from:\n```go\nselect {\ncase \u003c-done: // blocking check — worker would PAUSE until shutdown\ncase \u003c-time.After: // or timeout\n}\n```\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 14: Equivalent Binary Trees\n\n**Problem**: (From Tour of Go) Walk two binary trees concurrently, compare values.\n\nTwo trees have the same values if walking them in-order produces the same sequence of numbers.\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nWrite a `Walk(t *tree.Tree, ch chan int)` function that sends tree values in-order onto the channel. Write a `Same(t1, t2 *tree.Tree) bool` that creates two channels, walks both trees concurrently, and compares the streams.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\n// Simple binary tree implementation (replaces golang.org/x/tour/tree)\ntype Tree struct {\n    Left *Tree\n    Value int\n    Right *Tree\n}\n\n// insert creates a BST from a sorted sequence\nfunc NewTree(values []int) *Tree {\n    if len(values) == 0 {\n        return nil\n    }\n    mid := len(values) / 2\n    return \u0026Tree{\n        Left: NewTree(values[:mid]),\n        Value: values[mid],\n        Right: NewTree(values[mid+1:]),\n    }\n}\n\n// Walk traverses t sending all values in order to ch, then closes ch\nfunc Walk(t *Tree, ch chan int) {\n    defer close(ch) // crucial: close when walk is complete\n    walkRecursive(t, ch)\n}\n\nfunc walkRecursive(t *Tree, ch chan int) {\n    if t == nil {\n        return\n    }\n    walkRecursive(t.Left, ch) // left subtree\n    ch \u003c- t.Value // current node\n    walkRecursive(t.Right, ch) // right subtree\n}\n\n// Same checks whether trees t1 and t2 contain the same values\nfunc Same(t1, t2 *Tree) bool {\n    ch1 := make(chan int)\n    ch2 := make(chan int)\n\n    go Walk(t1, ch1) // walk t1 in a goroutine\n    go Walk(t2, ch2) // walk t2 in a goroutine\n\n    for {\n        v1, ok1 := \u003c-ch1\n        v2, ok2 := \u003c-ch2\n\n        // Both should finish at the same time (same number of elements)\n        if ok1 != ok2 {\n            return false // different number of elements\n        }\n\n        // Both channels closed = walked the whole tree\n        if !ok1 {\n            return true\n        }\n\n        // Check current values match\n        if v1 != v2 {\n            return false\n        }\n    }\n}\n\nfunc main() {\n    tree1 := NewTree([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\n    tree2 := NewTree([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10})\n    tree3 := NewTree([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 11}) // different!\n\n    fmt.Println(\"tree1 == tree2:\", Same(tree1, tree2)) // true\n    fmt.Println(\"tree1 == tree3:\", Same(tree1, tree3)) // false\n\n    // Test single-value trees\n    a := \u0026Tree{Value: 5}\n    b := \u0026Tree{Value: 5}\n    c := \u0026Tree{Value: 7}\n    fmt.Println(\"a == b:\", Same(a, b)) // true\n    fmt.Println(\"a == c:\", Same(a, c)) // false\n}\n```\n\n**How It Works:**\n\n```\nTree 1 (in-order): 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\nTree 2 (in-order): 1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n\nTwo goroutines walk in parallel:\n  ch1: 1 → 2 → 3 → 4 → ... → 10 → close\n  ch2: 1 → 2 → 3 → 4 → ... → 10 → close\n\nSame() reads from both simultaneously:\n  v1=1, ok1=true | v2=1, ok2=true → equal, continue\n  v1=2, ok1=true | v2=2, ok2=true → equal, continue\n  ...\n  v1=10, ok1=true | v2=10, ok2=true → equal, continue\n  v1=0, ok1=false | v2=0, ok2=false → both closed → return true!\n\nWith tree3 (last value = 11):\n  v1=9, ok1=true | v2=9, ok2=true → equal, continue\n  v1=10, ok1=true | v2=11, ok2=true → NOT EQUAL → return false!\n```\n\n**The subtle concurrent comparison:**\n\n```go\nv1, ok1 := \u003c-ch1 // blocks until Walk(t1) sends next value\nv2, ok2 := \u003c-ch2 // blocks until Walk(t2) sends next value\n```\n\nBoth block until their goroutine sends. This naturally synchronizes the two walks step-by-step, even though they run in separate goroutines.\n\n**The close propagation:** `Walk` defers `close(ch)`, so when the recursive walk finishes, the channel closes. `Same` detects this via `ok=false` and knows the tree is fully walked.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 15: Log Pipeline\n\n**Problem**: Build a complete log processing pipeline with proper close handling and error management.\n\n```\nread → parse → filter → aggregate → output\n```\n\n\u003cdetails\u003e\n\u003csummary\u003eHint\u003c/summary\u003e\n\nEach stage is a function returning `(\u003c-chan T, \u003c-chan error)` — a results channel AND an error channel. Use `errgroup` or collect errors via a separate goroutine. Always defer close on output channels. Propagate close signals from stage to stage.\n\n\u003c/details\u003e\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n\n```go\npackage main\n\nimport (\n    \"errors\"\n    \"fmt\"\n    \"strconv\"\n    \"strings\"\n    \"sync\"\n    \"time\"\n)\n\n// LogEntry represents a parsed log line\ntype LogEntry struct {\n    Timestamp time.Time\n    Level string\n    Message string\n    RawLine string\n}\n\n// AggregatedStats tracks counts per log level\ntype AggregatedStats struct {\n    Counts map[string]int\n    Total int\n}\n\n// Stage 1: Read — simulates reading lines from a log file\nfunc readLines(done \u003c-chan struct{}) (\u003c-chan string, \u003c-chan error) {\n    out := make(chan string, 10)\n    errCh := make(chan error, 1)\n\n    // Simulate log lines (some malformed)\n    lines := []string{\n        \"2024-01-15T10:00:01Z INFO Server started\",\n        \"2024-01-15T10:00:02Z DEBUG Request received\",\n        \"MALFORMED LINE WITHOUT TIMESTAMP\", // will cause parse error\n        \"2024-01-15T10:00:03Z ERROR Database timeout\",\n        \"2024-01-15T10:00:04Z WARN Memory usage high\",\n        \"2024-01-15T10:00:05Z INFO Request completed\",\n        \"2024-01-15T10:00:06Z ERROR Connection refused\",\n        \"ANOTHER BAD LINE\",\n        \"2024-01-15T10:00:07Z INFO Shutting down\",\n    }\n\n    go func() {\n        defer close(out)\n        defer close(errCh)\n        for _, line := range lines {\n            select {\n            case \u003c-done:\n                return\n            case out \u003c- line:\n                time.Sleep(50 * time.Millisecond) // simulate IO\n            }\n        }\n    }()\n    return out, errCh\n}\n\n// Stage 2: Parse — converts raw strings to LogEntry structs\nfunc parseLines(done \u003c-chan struct{}, lines \u003c-chan string) (\u003c-chan LogEntry, \u003c-chan error) {\n    out := make(chan LogEntry, 10)\n    errCh := make(chan error, 10)\n\n    go func() {\n        defer close(out)\n        defer close(errCh)\n        for line := range lines {\n            select {\n            case \u003c-done:\n                return\n            default:\n            }\n\n            entry, err := parseLine(line)\n            if err != nil {\n                select {\n                case errCh \u003c- fmt.Errorf(\"parse error: %w (line: %q)\", err, line):\n                case \u003c-done:\n                    return\n                }\n                continue // skip bad lines, don't stop the pipeline!\n            }\n\n            select {\n            case out \u003c- entry:\n            case \u003c-done:\n                return\n            }\n        }\n    }()\n    return out, errCh\n}\n\nfunc parseLine(line string) (LogEntry, error) {\n    parts := strings.SplitN(line, \" \", 3)\n    if len(parts) \u003c 3 {\n        return LogEntry{}, errors.New(\"insufficient fields\")\n    }\n\n    ts, err := time.Parse(time.RFC3339, parts[0])\n    if err != nil {\n        return LogEntry{}, fmt.Errorf(\"invalid timestamp %q: %w\", parts[0], err)\n    }\n\n    level := strings.TrimSpace(parts[1])\n    if level != \"INFO\" \u0026\u0026 level != \"DEBUG\" \u0026\u0026 level != \"WARN\" \u0026\u0026 level != \"ERROR\" {\n        return LogEntry{}, fmt.Errorf(\"unknown level %q\", level)\n    }\n\n    return LogEntry{\n        Timestamp: ts,\n        Level: level,\n        Message: strings.TrimSpace(parts[2]),\n        RawLine: line,\n    }, nil\n}\n\n// Stage 3: Filter — only passes entries at or above a minimum level\nfunc filterByLevel(done \u003c-chan struct{}, entries \u003c-chan LogEntry, minLevel string) \u003c-chan LogEntry {\n    out := make(chan LogEntry, 10)\n    priority := map[string]int{\"DEBUG\": 0, \"INFO\": 1, \"WARN\": 2, \"ERROR\": 3}\n    minPrio := priority[minLevel]\n\n    go func() {\n        defer close(out)\n        for entry := range entries {\n            select {\n            case \u003c-done:\n                return\n            default:\n            }\n            if priority[entry.Level] \u003e= minPrio {\n                select {\n                case out \u003c- entry:\n                case \u003c-done:\n                    return\n                }\n            }\n        }\n    }()\n    return out\n}\n\n// Stage 4: Aggregate — counts entries by level\nfunc aggregate(done \u003c-chan struct{}, entries \u003c-chan LogEntry) \u003c-chan AggregatedStats {\n    out := make(chan AggregatedStats, 1)\n\n    go func() {\n        defer close(out)\n        stats := AggregatedStats{Counts: make(map[string]int)}\n\n        for entry := range entries {\n            select {\n            case \u003c-done:\n                break\n            default:\n                stats.Counts[entry.Level]++\n                stats.Total++\n            }\n        }\n\n        select {\n        case out \u003c- stats: // send final stats\n        case \u003c-done:\n        }\n    }()\n    return out\n}\n\n// Error collector — drains error channels concurrently\nfunc collectErrors(errChannels ...\u003c-chan error) []error {\n    var mu sync.Mutex\n    var errors []error\n    var wg sync.WaitGroup\n\n    for _, errCh := range errChannels {\n        errCh := errCh\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for err := range errCh {\n                mu.Lock()\n                errors = append(errors, err)\n                mu.Unlock()\n            }\n        }()\n    }\n\n    wg.Wait()\n    return errors\n}\n\nfunc main() {\n    done := make(chan struct{})\n    defer close(done) // ensure cleanup on any exit\n\n    fmt.Println(\"=== Log Pipeline ===\\n\")\n\n    // Build pipeline\n    rawLines, readErrs := readLines(done)\n    entries, parseErrs := parseLines(done, rawLines)\n    filtered := filterByLevel(done, entries, \"INFO\") // drop DEBUG\n    stats := aggregate(done, filtered)\n\n    // Collect errors in background (non-blocking relative to pipeline)\n    errsDone := make(chan []error, 1)\n    go func() {\n        errs := collectErrors(readErrs, parseErrs)\n        errsDone \u003c- errs\n    }()\n\n    // Consume final output\n    finalStats := \u003c-stats\n\n    // Wait for error collection to finish\n    allErrors := \u003c-errsDone\n\n    // Output results\n    fmt.Println(\"=== Results ===\")\n    fmt.Printf(\"Total processed: %d entries\\n\", finalStats.Total)\n    fmt.Println(\"\\nCounts by level:\")\n    for level, count := range finalStats.Counts {\n        bar := strings.Repeat(\"█\", count)\n        fmt.Printf(\" %-6s %s (%d)\\n\", level, bar, count)\n    }\n\n    if len(allErrors) \u003e 0 {\n        fmt.Printf(\"\\n=== Errors (%d) ===\\n\", len(allErrors))\n        for i, err := range allErrors {\n            fmt.Printf(\" %d. %v\\n\", i+1, err)\n        }\n    }\n\n    fmt.Printf(\"\\nPipeline complete. %d errors encountered.\\n\", len(allErrors))\n    _ = strconv.Itoa(0) // suppress import warning\n}\n```\n\n**How It Works:**\n\n```\nreadLines ──rawLines──→ parseLines ──entries──→ filterByLevel ──filtered──→ aggregate ──stats──→ main\n              └─readErrs─→ collectErrors ←─parseErrs─┘\n\nData flow:\n  \"2024-01-15... INFO Server started\" ──→ LogEntry{INFO, \"Server started\"} ──→ passes filter ──→ count++\n  \"MALFORMED LINE\" ──→ parse error ──────────────────────────────────────────→ collectErrors\n  \"2024-01-15... DEBUG Request received\" ──→ LogEntry{DEBUG, ...} ──→ FILTERED OUT (below INFO)\n  \"2024-01-15... ERROR Database timeout\" ──→ LogEntry{ERROR, ...} ──→ passes filter ──→ count++\n\nClose cascade:\n  readLines goroutine finishes all lines → close(rawLines)\n  parseLines sees rawLines closed → loop exits → close(entries)\n  filterByLevel sees entries closed → loop exits → close(filtered)\n  aggregate sees filtered closed → sends final stats → close(stats)\n  main receives final stats, done!\n```\n\n**Key design decisions and why:**\n\n**Separate error channels** per stage: Each stage has its own `\u003c-chan error`. Errors don't kill the pipeline — parse errors are reported but the pipeline continues with valid entries. This is a \"best effort\" pipeline.\n\n**`done` channel propagation**: Every goroutine in every stage checks `\u003c-done`. If main signals done (e.g., via timeout or Ctrl+C), the entire pipeline shuts down cleanly top-to-bottom.\n\n**Buffered channels between stages** (size 10): Stages run at different speeds. Buffers absorb the speed differences so faster stages don't stall waiting for slower ones.\n\n**Aggregate sends ONE final value**: The aggregate channel has buffer=1 and sends stats only when all entries are processed. Main blocks on `\u003c-stats` waiting for the final answer.\n\n\n\u003c/details\u003e\n\n---\n\n### Exercise 16: Merge N Channels\n\n**Problem:** Dynamically merge N channels using select + nil channel trick.\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"sync\"\n)\n\nfunc merge(channels ...\u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n\n    var wg sync.WaitGroup\n    wg.Add(len(channels))\n\n    for _, ch := range channels {\n        ch := ch\n        go func() {\n            defer wg.Done()\n            for v := range ch {\n                out \u003c- v\n            }\n        }()\n    }\n\n    go func() {\n        wg.Wait()\n        close(out)\n    }()\n\n    return out\n}\n\nfunc main() {\n    ch1 := make(chan int, 3)\n    ch2 := make(chan int, 3)\n    ch3 := make(chan int, 3)\n\n    ch1 \u003c- 1\n    ch1 \u003c- 2\n    ch1 \u003c- 3\n    close(ch1)\n\n    ch2 \u003c- 10\n    ch2 \u003c- 20\n    close(ch2)\n\n    ch3 \u003c- 100\n    ch3 \u003c- 200\n    ch3 \u003c- 300\n    close(ch3)\n\n    for v := range merge(ch1, ch2, ch3) {\n        fmt.Println(v)\n    }\n}\n```\n\n**Alternative with Select + Nil Trick:**\n\n```go\nfunc mergeWithSelect(ch1, ch2, ch3 \u003c-chan int) \u003c-chan int {\n    out := make(chan int)\n\n    go func() {\n        defer close(out)\n\n        for ch1 != nil || ch2 != nil || ch3 != nil {\n            select {\n            case v, ok := \u003c-ch1:\n                if !ok {\n                    ch1 = nil\n                    continue\n                }\n                out \u003c- v\n            case v, ok := \u003c-ch2:\n                if !ok {\n                    ch2 = nil\n                    continue\n                }\n                out \u003c- v\n            case v, ok := \u003c-ch3:\n                if !ok {\n                    ch3 = nil\n                    continue\n                }\n                out \u003c- v\n            }\n        }\n    }()\n\n    return out\n}\n```\n\n\u003c/details\u003e\n\n---\n\n### Exercise 17: Priority Job Processor\n\n**Problem:** High and low priority job channels. Ensure high priority processed first using double-select.\n\n\u003cdetails\u003e\n\u003csummary\u003eSolution\u003c/summary\u003e\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n    \"time\"\n)\n\nfunc priorityProcessor(highPri, lowPri \u003c-chan string, done \u003c-chan struct{}) {\n    for {\n        select {\n        case \u003c-done:\n            fmt.Println(\"Processor: shutting down\")\n            return\n        case job := \u003c-highPri:\n            fmt.Println(\"Processing HIGH:\", job)\n            time.Sleep(50 * time.Millisecond)\n        default:\n            select {\n            case \u003c-done:\n                fmt.Println(\"Processor: shutting down\")\n                return\n            case job := \u003c-highPri:\n                fmt.Println(\"Processing HIGH:\", job)\n                time.Sleep(50 * time.Millisecond)\n            case job := \u003c-lowPri:\n                fmt.Println(\"Processing LOW:\", job)\n                time.Sleep(50 * time.Millisecond)\n            }\n        }\n    }\n}\n\nfunc main() {\n    highPri := make(chan string, 10)\n    lowPri := make(chan string, 10)\n    done := make(chan struct{})\n\n    // Fill both channels\n    for i := 1; i \u003c= 5; i++ {\n        highPri \u003c- fmt.Sprintf(\"HIGH-%d\", i)\n        lowPri \u003c- fmt.Sprintf(\"LOW-%d\", i)\n    }\n\n    go priorityProcessor(highPri, lowPri, done)\n\n    time.Sleep(2 * time.Second)\n    close(done)\n    time.Sleep(100 * time.Millisecond)\n}\n```\n\n**Expected Output:**\n```\nProcessing HIGH: HIGH-1\nProcessing HIGH: HIGH-2\nProcessing HIGH: HIGH-3\nProcessing HIGH: HIGH-4\nProcessing HIGH: HIGH-5\nProcessing LOW: LOW-1\nProcessing LOW: LOW-2\n...\n```\n\n\u003c/details\u003e\n\n## Summary: Exercise Patterns by Problem Type\n\n**The three most important things from these exercises:**\n\n1. **Always close input channels** when you're done sending — it's how `range` knows to stop.\n2. **Buffer result channels with capacity 1** in timeout patterns — it prevents goroutine leaks.\n3. **`close(done)` broadcasts to all goroutines** at once — it's the correct way to shut down multiple workers.\n\n**What you learned**:\n\n **Channels are signaling mechanisms** (not just data structures)\n **Unbuffered channels block** until handshake completes\n **Buffered channels** decouple sender/receiver (within capacity)\n **close()** signals \"no more data\"\n **range** iterates until channel closes\n **Single-writer pattern** fixes races (ownership transfer)\n **Common patterns**: producer-consumer, pipeline, fan-out, fan-in, worker pool\n **Common mistakes**: forgetting close, wrong goroutine closes, goroutine leaks\n\n**Key insights**:\n\n Channels transfer ownership - one goroutine at a time\n Sender closes, receiver ranges\n Use channels for coordination, mutexes for state\n Start unbuffered, justify buffers\n Channels provide correctness \u003e speed\n\n**What's next**:\n\n**Part 5: Solution #2 - Mutexes**\n- When channels are overkill\n- Protecting shared state directly\n- Read-write locks\n- Performance comparison\n\n**Part 6: Solution #3 - Atomics**\n- Zero-overhead synchronization\n- When to use atomic operations\n- Building lock-free data structures\n\n**You now have THREE tools in your concurrency toolbox!**\n";
var __STRUCTURE__ = {"title":"Go Concurrency Mastery","overview":[{"id":"COMPLETE_COURSE_CURRICULUM","title":"Go Concurrency Mastery: Complete Course Curriculum","filename":"COMPLETE_COURSE_CURRICULUM.md"}],"chapters":[{"id":"chapter-01","title":"Chapter 01: The Race Condition Crisis","dir":"chapter-01","parts":[{"id":"PART0_INTRODUCTION","title":"Chapter 1, Part 0: Introduction and Setup","filename":"PART0_INTRODUCTION.md"},{"id":"PART1_SEQUENTIAL_BASELINE","title":"Chapter 1, Part 1: The Sequential Baseline","filename":"PART1_SEQUENTIAL_BASELINE.md"},{"id":"PART3_RACE_CONDITIONS_DEEP_DIVE","title":"Chapter 1, Part 3: What IS a Race Condition? - Deep Dive","filename":"PART3_RACE_CONDITIONS_DEEP_DIVE.md"},{"id":"PART4_SOLUTION_CHANNELS","title":"Chapter 1, Part 4: Solution #1 - Channels","filename":"PART4_SOLUTION_CHANNELS.md"},{"id":"PART4-1CHANNELS_PRACTICE","title":"Channels Practice","filename":"PART4-1CHANNELS_PRACTICE.md"}]}]};
</script>
<script src="../app.js"></script>
</body>
</html>